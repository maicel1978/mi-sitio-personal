---
title: "Las trampas de la correlaci√≥n disfrazada de causalidad"
subtitle: "cuando los n√∫meros cuentan historias falsas"
author: "admin"
date: '2025-01-13'
categories: ["Estad√≠stica en Salud"]
tags:
  - "detectar trampas correlaci√≥n vs. causalidad en investigaci√≥n"
  - "checklist para rigor en pruebas estad√≠sticas m√©dicas"
  - "ejemplos pr√°cticos de falacias causales en salud"
  - "herramientas para validar causalidad real"
slug: trampas-correlacion
languages:
  es: "/es/trampas-correlacion"
  en: "/en/trampas-correlacion-en"
summary:  "Ejemplos curiosos, c√°psulas de rigor y un checklist pr√°ctico para no confundir correlaci√≥n con causalidad en investigaci√≥n cient√≠fica."
featured: false  # Destacar en la p√°gina principal
draft: false 
commentable: true
type: post
---

*Por Maicel Monzon*

## Introducci√≥n

El ojo humano est√° entrenado para detectar patrones.  
Cuando dos fen√≥menos se mueven juntos, tendemos a asumir que uno provoca al otro.

La estad√≠stica, mal interpretada, refuerza esa intuici√≥n peligrosa.  
La **correlaci√≥n** describe coexistencia; **no establece causalidad**.  
Sin embargo, titulares, pol√≠ticas p√∫blicas y decisiones cl√≠nicas se apoyan a menudo en esta confusi√≥n.

Este art√≠culo no busca ridiculizar errores obvios, sino **mostrar c√≥mo incluso an√°lisis t√©cnicamente correctos pueden sostener conclusiones falsas** si el razonamiento causal es d√©bil.

---

## 1) Correlaciones llamativas (y por qu√© enga√±an)

Algunas correlaciones resultan tan evidentes que parecen absurdas. Precisamente por eso son √∫tiles como punto de partida.

- **Helados y ahogamientos.** Ambos aumentan en verano. El factor com√∫n es el calor, no el helado.
- **Cig√ºe√±as y natalidad.** En zonas rurales europeas, ambas son m√°s frecuentes. La explicaci√≥n est√° en el contexto demogr√°fico, no en las aves.
- **Pel√≠culas de Nicolas Cage y ahogamientos en piscinas.** Ejemplo cl√°sico de correlaciones espurias recopiladas por Tyler Vigen.

Estos casos no son interesantes por s√≠ mismos, sino porque **revelan un mecanismo general**:  
una tercera variable no observada puede generar asociaciones enga√±osas.

---

## 2) Cuando la confusi√≥n tiene consecuencias reales

En investigaci√≥n en salud, confundir correlaci√≥n con causalidad **no es anecd√≥tico**.

**Ejemplo en pol√≠tica p√∫blica:**  
Pa√≠ses con mayor densidad de m√©dicos reportan m√°s diagn√≥sticos de c√°ncer.  
Conclusi√≥n err√≥nea: ‚Äúlos m√©dicos causan c√°ncer‚Äù.  
Realidad: mayor acceso sanitario implica mejor detecci√≥n.

### Causalidad inversa (no bidireccional)

Un error frecuente es invertir el sentido de la relaci√≥n:

> Ni√±os con bajo rendimiento escolar pasan m√°s horas frente a la televisi√≥n.

La pregunta relevante no es ret√≥rica:
- ¬øLa televisi√≥n empeora el rendimiento?
- ¬øO los ni√±os con dificultades acad√©micas recurren m√°s a ella?

Aqu√≠ no hablamos de retroalimentaci√≥n compleja, sino de **una inversi√≥n plausible del sentido causal**.

{{% callout note %}}
### ¬øQu√© es una variable de confusi√≥n?

Una **variable de confusi√≥n** es una tercera variable que:
1. Est√° asociada con la exposici√≥n  
2. Est√° asociada con el desenlace  
3. No forma parte del mecanismo causal entre ambos  

Su efecto es generar una asociaci√≥n aparente o distorsionar una real.

**Ejemplo:** la edad puede confundir la relaci√≥n entre consumo de medicamentos y mortalidad.
{{% /callout %}}

---

## 3) Qu√© mide realmente la correlaci√≥n

El coeficiente de correlaci√≥n de Pearson (**r**) mide **la intensidad y direcci√≥n de una relaci√≥n lineal** entre dos variables continuas.

- r = +1 ‚Üí relaci√≥n positiva perfecta  
- r = ‚àí1 ‚Üí relaci√≥n negativa perfecta  
- r ‚âà 0 ‚Üí ausencia de relaci√≥n lineal  

{{% callout warning %}}
Un coeficiente alto **no implica causalidad**.  
Puede deberse a confusi√≥n, azar o causalidad inversa.  
Un coeficiente cercano a cero **no descarta relaciones no lineales**.
{{% /callout %}}

La correlaci√≥n es descriptiva. **No responde preguntas causales.**

---

## 4) Elegir el coeficiente adecuado no salva una mala pregunta

Existen m√∫ltiples coeficientes de correlaci√≥n porque los datos y las relaciones var√≠an.  
Elegir el coeficiente correcto **evita errores t√©cnicos**, pero **no convierte una asociaci√≥n en causal**.

![](correlacion.png)

{{% callout warning %}}
Aplicar Pearson a datos ordinales o relaciones curvil√≠neas produce resultados enga√±osos, aunque sean ‚Äúsignificativos‚Äù.
{{% /callout %}}

El problema central no suele ser el coeficiente, sino **la interpretaci√≥n posterior**.

---

## 5) Causalidad: un problema de razonamiento, no de software

Establecer causalidad exige dise√±o, contexto y juicio cr√≠tico.  
Una gu√≠a cl√°sica son los **criterios de Bradford Hill**, propuestos en 1965.

### Los criterios de Bradford Hill

| Criterio | Pregunta clave |
|--------|----------------|
| Fuerza | ¬øQu√© tan grande es la asociaci√≥n? |
| Consistencia | ¬øSe replica en distintos contextos? |
| Especificidad | ¬øLa exposici√≥n produce un efecto concreto? |
| Temporalidad | ¬øLa causa precede al efecto? *(obligatorio)* |
| Gradiente | ¬øExiste relaci√≥n dosis‚Äìrespuesta? |
| Plausibilidad | ¬øTiene sentido biol√≥gico? |
| Coherencia | ¬øContradice el conocimiento previo? |
| Evidencia experimental | ¬øHay respaldo experimental? |
| Analog√≠a | ¬øExisten fen√≥menos similares conocidos? |

{{% callout note %}}
Estos criterios **no son un checklist mec√°nico**.  
Sirven para estructurar el razonamiento, no para automatizar conclusiones.
{{% /callout %}}

---

### Diagramas causales (DAGs): pensar antes de ajustar

Los **diagramas causales dirigidos (DAGs)** permiten representar hip√≥tesis causales antes del an√°lisis.

**Ejemplo conceptual:**  
El tabaquismo aumenta el consumo de caf√© y el riesgo cardiovascular.  
Si no se ajusta por tabaquismo, el caf√© parecer√° causalmente da√±ino.

El DAG no ‚Äúdemuestra‚Äù nada.  
**Obliga a explicitar supuestos.**

---

## 6) Cuando una correlaci√≥n s√≠ condujo a causalidad

En los a√±os 50, los estudios de Doll y Hill mostraron una fuerte asociaci√≥n entre tabaco y c√°ncer de pulm√≥n.  
La objeci√≥n fue conocida: ‚Äúcorrelaci√≥n no es causalidad‚Äù.

La diferencia fue el **razonamiento acumulativo**:
- efectos grandes
- temporalidad clara
- dosis‚Äìrespuesta
- plausibilidad biol√≥gica
- consistencia internacional

Aqu√≠, la frase correcta no era descartar la correlaci√≥n, sino **investigarla con rigor**.

---

## 7) Una met√°fora √∫til

Ver dos hojas caer juntas no implica que una arrastre a la otra.  
Ignorar el viento es ignorar la causa com√∫n.

---

## 8) Checklist m√≠nimo de rigor causal

Antes de afirmar causalidad, preg√∫ntate:

1. ¬øExiste una variable no considerada que explique la asociaci√≥n?
2. ¬øEl efecto podr√≠a preceder a la supuesta causa?
3. ¬øEl dise√±o permite inferencia causal o solo asociaci√≥n?
4. ¬øEl tama√±o del efecto es cl√≠nicamente relevante?
5. ¬øLa conclusi√≥n depende de supuestos no explicitados?

Si no puedes responderlas, la correlaci√≥n no basta.

---

## 9) P-hacking: correlaciones fabricadas

El **p-hacking** consiste en explorar m√∫ltiples an√°lisis hasta encontrar un resultado ‚Äúsignificativo‚Äù.

Con suficientes pruebas, el azar garantiza falsos positivos.

**Se√±ales de alerta:**
- muchas variables, pocas hip√≥tesis previas
- resultados sorprendentes sin plausibilidad
- ausencia de preregistro
- efectos peque√±os presentados como hallazgos mayores

{{% callout warning %}}
Un p-valor bajo no valida una hip√≥tesis causal.  
Solo indica compatibilidad estad√≠stica bajo supuestos espec√≠ficos.
{{% /callout %}}

---

## Conclusi√≥n

La correlaci√≥n es un punto de partida, no una conclusi√≥n.  
Sin razonamiento causal expl√≠cito, incluso an√°lisis impecables pueden inducir a error.

La pr√≥xima vez que leas que ‚ÄúX causa Y‚Äù, haz una pausa cr√≠tica.  
La estad√≠stica describe. **El pensamiento decide.**

---

## Para cerrar (y abrir la conversaci√≥n)

Si trabajas con datos reales ‚Äîen salud, investigaci√≥n o pol√≠ticas p√∫blicas‚Äî, es muy probable que ya te hayas enfrentado a una correlaci√≥n tentadora.

**La pregunta no es si existe una correlaci√≥n, sino si te atreviste a interrogarla.**

üëâ **Pregunta para la caja de comentarios:**

> ¬øHas visto alguna vez una decisi√≥n importante (cl√≠nica, regulatoria o cient√≠fica) apoyarse en una correlaci√≥n que no resist√≠a un an√°lisis causal serio?  
> ¬øD√≥nde fall√≥ el razonamiento: en el dise√±o, en el an√°lisis o en la interpretaci√≥n?

Si quieres, descr√≠belo de forma general (sin datos sensibles). Responder√© se√±alando **qu√© tipo de trampa causal est√° en juego** y c√≥mo habr√≠a que replantearla.

"Si te gusta cuestionar los datos y la IA con rigor, suscr√≠bete a mi bolet√≠n en LinkedIn para no perderte estos an√°lisis semanalmente."

<div style="background-color: #f3f6f8; padding: 20px; border-radius: 10px; text-align: center; margin-top: 30px; border: 1px solid #e0e0e0;">
    <p style="color: #000; font-weight: bold; margin-bottom: 15px;">¬øTe interesa pensar m√°s all√° de los n√∫meros?</p>
    <a href="https://www.linkedin.com/newsletters/7415401669913706496/" 
       target="_blank" 
       style="background-color: #0077b5; color: white; padding: 10px 20px; text-decoration: none; border-radius: 25px; font-weight: bold; display: inline-block;">
       Suscribirse al Bolet√≠n en LinkedIn
    </a>
</div>

---


## Bibliograf√≠a

Hill, A. B. (1965). *The environment and disease: association or causation?*  

Hern√°n, M. A., & Robins, J. M. (2020). *Causal Inference: What If*.  

Pearl, J. (2009). *Causality*.  

Silva Aycaguer, L. C. (1998). *Cultura estad√≠stica e investigaci√≥n cient√≠fica*. 

Vigen, T. (2015). *Spurious Correlations*.




