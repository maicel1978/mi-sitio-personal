---
title: "C√≥mo entrenar y validar un modelo de predicci√≥n cl√≠nica"
summary: "Gu√≠a pr√°ctica con R para desarrollar modelos predictivos robustos en entornos cl√≠nicos. Aprende la metodolog√≠a Steyerberg y evita el sobreajuste en Machine Learning." 
authors: ["admin"] # ‚úÖ CORREGIDO: Mantiene 'admin' ya que es el SLUG de la carpeta del autor.
date: "2024-02-08"
categories: ["C√≥digo Pr√°ctico en R o Python"]# ‚úÖ CORREGIDO: Categor√≠a exacta del prompt_maestro
tags: 
  - "predicci√≥n cl√≠nica"
  - "modelo predictivo"
  - "R"
  - "machine learning"
  - "bioestad√≠stica" 
slug: como-entrenar-y-validar-modelo-prediccion-clinica 
languages:
  es: "/es/posts/como-entrenar-y-validar-modelo-prediccion-clinica "
  en: "/en/posts/how-to-train-and-validate-clinical-prediction-model" 
# üìë Control visual y funcional del post
# commentable: yes
featured: true # Cambia a true si quieres destacarlo en la p√°gina principal
# type: post
commentable: yes
draft: false
show_author_profile: true
---




```{r setup, include=FALSE}
# Opciones globales para los chunks de c√≥digo
knitr::opts_chunk$set(
  echo = TRUE,       # Muestra el c√≥digo
  message = FALSE,   # Oculta mensajes de paquetes
  warning = FALSE,   # Oculta advertencias
  results = FALSE,
  fig.align = 'center', # Centra las figuras
  fig.retina = 2     # Mejora la resoluci√≥n de las figuras
)
```



Si usted es Investigador en Salud o, peor a√∫n, estudiante de posgrado, maestr√≠a o doctorado en el campo de las ciencias biom√©dicas... **¬°bienvenido al club del estr√©s!**

Seguro que usted est√° enfocado en desarrollar esos geniales **modelos de predicci√≥n cl√≠nica** para el **diagn√≥stico** o el **pron√≥stico**. Y es casi seguro que ha llegado a esa fase donde la metodolog√≠a se siente como un muro de ladrillos. Un d√≠a est√°s bien, y al siguiente te das cuenta de que no sabes qu√© pasos seguir, qu√© software usar, o lo peor: si tu modelo servir√° para algo m√°s all√° de llenar un repositorio de tesis.

Lo digo sin tapujos: esa frase lapidaria de **'Ese valor tan alto de la Curva Roc y la ausencia de m√©tricas de calibraci√≥n'** puede significar que tu modelo tiene el famoso **s√≠ndrome del "sobreajuste"**. En otras palabras, funciona espectacularmente bien... solo para la muestra que lo cre√≥.

Es una locura, ¬øverdad? Mientras las tesis de alto nivel giran en torno a crear estos modelos de predicci√≥n cl√≠nica, los cursos de Bioestad√≠stica (¬°incluida la especialidad!) pasan de puntillas por el tema. Hay una brecha gigantesca, y la ansiedad de tener que aprenderlo todo YA es real. Pero respira. Este post es tu chaleco salvavidas: tu Traductor Metodol√≥gico no oficial y (casi) libre de l√°grimas. Yo mismo pas√© por ese infierno metodol√≥gico en mi tesis de doctorado, as√≠ que no solo doy consejos: comparto la experiencia de quien ya quem√≥ sus pesta√±as por ti.

Olvida el c√≥digo complejo y enrevesado. Aqu√≠ nos enfocamos en la l√≥gica esencial para construir un modelo predictivo robusto y fiable. Desglosaremos el proceso paso a paso, quit√°ndole el miedo a la estad√≠stica con un **C√≥digo Pr√°ctico en R**. Empezaremos con la **Estrategia de Modelado**; el c√≥digo vendr√° despu√©s. **¬°Empecemos!**

# Estrategia de modelado

Contar con una estrategia de modelado adecuada es esencial para desarrollar y validar modelos de predicci√≥n. En este art√≠culo exploraremos las siete etapas clave propuestas por Ewout Steyerberg en su trabajo (1).

## 1. Definici√≥n del problema e inspecci√≥n de datos

El primer paso en cualquier proyecto de modelado es **definir claramente el problema de investigaci√≥n** y seleccionar la **variable de resultado** adecuada.

{{% callout note %}}

La **variable de resultado** debe definirse con precisi√≥n: especifica **qu√© evento se predice**, **c√≥mo y cu√°ndo se mide**, y el **horizonte temporal de predicci√≥n** (por ejemplo, mortalidad a 30 d√≠as). Indica adem√°s el m√©todo de evaluaci√≥n y si hubo **cegamiento** respecto a los predictores, para garantizar coherencia y validez del modelo.

{{% /callout %}}

Durante esta fase, tambi√©n realizamos un an√°lisis exploratorio de datos (EDA) para comprender las caracter√≠sticas de las variables y detectar posibles problemas, como **datos at√≠picos** o **valores faltantes**.

```{r paso_1}
# bibliotecas
library(rms)    # El alma de la metodolog√≠a 
library(pROC)   # ROC confiable
library(ggplot2)# Gr√°ficos publicaci√≥n
library(missRanger)
library(mlbench)
library(dplyr)
library(conflicted)
set.seed(123)   # para reproducibilidad
# DATOS: 
data("PimaIndiansDiabetes")
datos <- PimaIndiansDiabetes
# predictores
vars_clinicas <- c("glucose", "pressure", "triceps", "insulin", "mass")
# PASO CR√çTICO: Transformacion de datos
datos <- datos %>%
  # Reemplaza 0 por NA solo en las columnas especificadas en vars_clinicas
  mutate(across(all_of(vars_clinicas), ~ ifelse(.x == 0, NA, .x))) %>%
  # Luego aplica missRanger al dataset completo (o se puede focalizar si se desea)
  missRanger()
# CONFIGURACI√ìN RMS (NO OMITIR)
dd <- datadist(datos)
options(datadist = "dd")
```

## 2. Codificaci√≥n de las variables predictoras

La **codificaci√≥n** adecuada de las **variables predictoras** es fundamental para construir modelos robustos.

Es probable que debas utilizar t√©cnicas como la agrupaci√≥n de categor√≠as poco frecuentes y la creaci√≥n de predictores res√∫menes para simplificar informaci√≥n correlacionada. Si el algoritmo seleccionado es la **regresi√≥n log√≠stica**, es posible que le haga falta aplicar t√©cnicas como los **splines c√∫bicos restringidos** para relajar el supuesto de linealidad entre la variable dependiente y el resultado.

{{% callout note %}} Cada variable predictora debe definirse con su m√©todo de medici√≥n y momento. Las variables continuas deben reportarse con sus unidades; si se categorizan, debe justificarse los puntos de corte. Las variables categ√≥ricas deben listar todas sus categor√≠as y especificar la categor√≠a de referencia. El modelo final debe presentar la codificaci√≥n completa utilizada para cada predictor. {{% /callout %}}

üí° **Tip:** Dicotomizar predictores cuantitativos (por ejemplo, transformar una variable continua como la edad o la presi√≥n arterial en una variable binaria, como ‚Äú‚â•65 a√±os = 1‚Äù y ‚Äú\<65 = 0‚Äù) es considerada una mala pr√°ctica metodol√≥gica por p√©rdida de informaci√≥n, menos poder estad√≠stico, puntos de corte arbitrarios y riesgo de sobreajuste.

## 3 .Especificaci√≥n del tipo de modelo

En esta etapa se define la estructura formal del modelo, lo que incluye el tipo de relaci√≥n entre variables (p. ej., lineal, no lineal) y, de manera crucial, la selecci√≥n de los predictores finales que lo integrar√°n.

![](modelos_elecion.png)

La elecci√≥n de predictores no debe basarse en la aplicaci√≥n mec√°nica de m√©todos algor√≠tmicos como la **Regresi√≥n Paso a Paso (RPP)**, ya que suelen producir modelos inestables y sobreajustados, especialmente en contextos biom√©dicos y sociales. En su lugar, se recomienda:

-   Priorizar el **juicio cl√≠nico, la revisi√≥n sistem√°tica de la literatura y la experiencia previa.**

-   Evitar la preselecci√≥n de variables basada √∫nicamente en valores *p* de an√°lisis bivariados.

-   Optar por un conjunto reducido de predictores cl√≠nicamente relevantes definidos a priori, o incluir todos los candidatos en el modelo multivariable inicial sin filtrado estad√≠stico previo.

## 4. Estimaci√≥n del Modelo

Una vez especificado el modelo (es decir, definidos los predictores y la estructura funcional), el paso de estimaci√≥n tiene como objetivo calcular los coeficientes o par√°metros que mejor se ajusten a los datos de entrenamiento.

```{r paso_4}
#MODELO: PREDICTORES POR FISIOPATOLOG√çA, NO p-valores
modelo <- lrm(diabetes ~ rcs(glucose, 3) + rcs(mass, 3) + age + pregnant + pedigree, 
              data = datos, 
              x = TRUE,
              y = TRUE)
```

En modelos de regresi√≥n, esto implica t√≠picamente el uso de m√©todos como la **m√°xima verosimilitud**. Sin embargo, cuando el n√∫mero de eventos es limitado o el de predictores es alto, el riesgo de sobreajuste es elevado, lo que genera predicciones extremas y poco generalizables. Para mitigarlo, se emplean t√©cnicas de **regularizaci√≥n, penalizaci√≥n o shrinkage**, que ajustan los coeficientes hacia cero para mejorar la estabilidad y la calibraci√≥n en nuevas poblaciones.

El objetivo final no es maximizar el rendimiento aparente en la muestra de desarrollo, sino obtener un modelo con **predicciones estables, bien calibradas y cl√≠nicamente √∫tiles**.

{{% callout note %}} Es recomendable aplicar siempre una validaci√≥n interna (como bootstrapping o cross-validation) para cuantificar y corregir el optimismo en las m√©tricas de rendimiento. La ecuaci√≥n final del modelo debe presentarse de forma completa ‚Äîincluyendo todos los coeficientes, el intercepto y, si corresponde, la supervivencia basal‚Äî, reportando m√©tricas de calibraci√≥n y discriminaci√≥n con sus intervalos de confianza. {{% /callout %}}

## 5. Evaluaci√≥n del Rendimiento del Modelo

Una vez desarrollado el modelo, es esencial cuantificar su capacidad predictiva antes de su validaci√≥n. Esta evaluaci√≥n se centra en tres aspectos clave:

-   **Calibraci√≥n:** Mide la concordancia entre las probabilidades predichas y las observadas. Por ejemplo, ¬øun 10% de riesgo predicho se corresponde con un 10% de eventos observados? Se eval√∫a visualmente con curvas de calibraci√≥n y cuantitativamente con par√°metros como el intercepto (A, calibraci√≥n-in-the-large) y la pendiente de calibraci√≥n (B).

```{r calibracion}
# calibrate(): Bootstrap para evaluar y corregir la calibraci√≥n
cal_boot <- calibrate(modelo, method = "boot", B = 200)

# GR√ÅFICOS DE SUPERVIVENCIA 
plot(cal_boot, main = "Probabilidasde predichas vs observadas")
abline(0, 1, lty = 2, col = "red")
```

-   **Discriminaci√≥n:** Eval√∫a la capacidad del modelo para distinguir entre pacientes que experimentan el evento y aquellos que no. La m√©trica m√°s com√∫n es el estad√≠stico C (o AUC-ROC), que representa la probabilidad de que un paciente con el evento tenga una puntuaci√≥n de riesgo m√°s alta que uno sin √©l.

```{r discriminacion}
# validate(): Bootstrap para estimar el optimismo y corregir m√©tricas de discriminaci√≥n
val_boot <- validate(modelo, method = "boot", B = 200)

roc_obj <- roc(datos$diabetes, predict(modelo, type = "fitted"))
plot(roc_obj, 
     main = paste("AUC =", round(auc(roc_obj), 3)),
     col = "blue", 
     legacy.axes = TRUE)
```

-   **Utilidad Cl√≠nica:** Determina si el modelo es √∫til para la toma de decisiones. El an√°lisis de curvas de decisi√≥n y el Beneficio Neto (NB) permiten evaluar si el uso del modelo conduce a mejores resultados cl√≠nicos netos en comparaci√≥n con estrategias alternativas (como tratar a todos o a ninguno).

## 6. Evaluaci√≥n de la Validez del Modelo

La evaluaci√≥n del rendimiento en los datos de desarrollo suele ser optimista. Por ello, es crucial evaluar la validez del modelo en datos no utilizados para su construcci√≥n, un proceso que se divide en:

**Validaci√≥n Interna:** Eval√∫a la reproducibilidad del modelo, es decir, su rendimiento en m√∫ltiples muestras de la misma poblaci√≥n subyacente. T√©cnicas como el bootstrapping o la validaci√≥n cruzada son superiores a la divisi√≥n simple de la muestra, ya que cuantifican y corrigen el optimismo en las m√©tricas de rendimiento sin reducir el tama√±o de la muestra de desarrollo.

**Validaci√≥n Externa:** Es la prueba definitiva de la generalizabilidad o transportabilidad del modelo. Consiste en aplicar el modelo a una poblaci√≥n completamente independiente, lo que puede incluir:

-   **Validaci√≥n Temporal:** Usar pacientes reclutados en un per√≠odo posterior.

-   **Validaci√≥n Geogr√°fica:** Aplicar el modelo en pacientes de otros centros u hospitales.

-   **Validaci√≥n Fuerte:** Probar el modelo en un entorno cl√≠nico o una poblaci√≥n con caracter√≠sticas diferentes a las originales.

Este paso es fundamental para confirmar que el modelo mantiene su calibraci√≥n, discriminaci√≥n y utilidad cl√≠nica en la pr√°ctica real.

## 7. Presentaci√≥n del modelo

La presentaci√≥n efectiva es crucial para la adopci√≥n cl√≠nica. Un modelo perfecto es in√∫til si los m√©dicos no pueden interpretarlo f√°cilmente. Considera:

-   **Nomogramas**: Ideales para uso r√°pido en consulta
-   **Aplicaciones web/m√≥viles**: Para integraci√≥n en flujos de trabajo cl√≠nicos
-   **Puntuaciones de riesgo**: Simplificadas para triaje r√°pido
-   **Documentaci√≥n clara**: Incluyendo limitaciones y casos de uso

Recuerda: la transparencia en la presentaci√≥n favorece la confianza cl√≠nica.

```{r prersentacion}
# NOMOGRAMA: EL TEST DE USABILIDAD CL√çNICA  
nom <- nomogram(modelo, fun = plogis, funlabel = "Riesgo Diabetes")
plot(nom)
```

<!-- ## üõ†Ô∏è EL KIT DE SUPERVIVENCIA (Tu Script) -->

<!-- [Descarga el script completo] -->

¬øHas aplicado estas t√©cnicas en tus proyectos de Machine Learning? ¬øQu√© estrategias usas para entrenar y validar tus modelos? D√©jame tus comentarios üí¨: comparte tus experiencias, dificultades o tips contigo. ¬°Juntos podemos enriquecer este conocimiento!

# Bibliograf√≠a

1.  Steyerberg EW, Vergouwe Y. Towards better clinical prediction models: seven steps for development and an ABCD for validation. European Heart Journal [Internet]. 1 de agosto de 2014 [citado 9 de mayo de 2021];35(29):1925-31. Disponible en: <https://academic.oup.com/eurheartj/article-lookup/doi/10.1093/eurheartj/ehu207>
