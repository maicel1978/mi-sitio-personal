---
title: "An치lisis Exploratorio de Datos: Desentra침ando la Verdad de tus Datos"
subtitle: "Tutorial sobre An치lisis Exploratorio de Datos"
authors:
  - "admin"
date: '2025-02-11'
slug: "eda"
categories:
  - "C칩digo Pr치ctico en R/Python"
tags:
  - "tutorial en r para An치lisis Exploratorio de Datos"
  - "Limpieza de datos"
summary: El An치lisis Exploratorio de Datos (EDA) es la fase cr칤tica de inspecci칩n inicial, limpieza y preparaci칩n de datos que sienta las bases para modelos robustos y conocimientos profundos, garantizando que solo los datos de la m치s alta calidad alimenten nuestros algoritmos.
related_posts: [como-entrenar-y-validar-un-modelo-de-machine-learnig]  # Slug de tu post sobre EDA
commentable: yes
---

游꿚 **Escucha el podcast de esta publicaci칩n**
{{< audio src="/mp3/eda.mp3" controls="yes" >}}



El **An치lisis Exploratorio de Datos (EDA)** es una disciplina fundamental en el campo de la ciencia de datos, popularizada por el matem치tico John Tukey. M치s que una simple serie de pasos, el EDA es una filosof칤a que nos invita a interactuar con nuestros datos, visualizarlos, resumirlos y "hablar" con ellos antes de saltar a modelados complejos. Implica el an치lisis de datos centrado en comprender a fondo su estructura, identificar patrones ocultos, detectar anomal칤as (valores at칤picos), gestionar datos ausentes y, en 칰ltima instancia, proporcionar una base s칩lida para la formulaci칩n de modelos predictivos o inferenciales. Adem치s, es crucial para descubrir c칩mo se relacionan las variables entre s칤.

## La Regla de Oro: GIGO (Garbage In, Garbage Out)

Un concepto popular y vital en el campo de la ciencia de datos es **GIGO** (Garbage In, Garbage Out, o "Basura entra, basura sale"). Este concepto subraya que la calidad de los resultados de cualquier an치lisis o modelo es directamente proporcional a la calidad de los datos de entrada. No importa cu치n sofisticado sea tu algoritmo o cu치n potente sea tu infraestructura computacional, los datos de mala calidad siempre producir치n resultados deficientes, enga침osos o in칰tiles. El EDA es nuestra primera l칤nea de defensa contra el GIGO, asegurando que trabajamos con datos limpios y comprensibles.

## Un Flujo de Trabajo Pr치ctico de EDA

Aunque el EDA es un proceso iterativo y no una "camisa de fuerza" r칤gida, es 칰til seguir un flujo de trabajo estructurado para garantizar que cubrimos los aspectos m치s importantes. El orden de las etapas y el 칠nfasis en cada una depender치n en gran medida del problema espec칤fico, el tipo de datos y los objetivos del an치lisis.

Este proceso general incluye:

![](fig01.png)


A continuaci칩n, profundicemos en cada una de estas etapas, utilizando ejemplos pr치cticos con el paquete `dlookr` en R.

```{r setup, include=FALSE}
library(dlookr)
library(dplyr)
# Simulamos un dataset con NAs para el ejemplo
data(mtcars)
mtcars_df <- mtcars %>% as_tibble()
# Introducimos algunos NAs para demostraci칩n
mtcars_na <- mtcars_df
mtcars_na[1, "mpg"] <- NA
mtcars_na[5, "hp"] <- NA
mtcars_na[10, "qsec"] <- NA
```


### 1. Comprensi칩n General de los Datos y Evaluaci칩n de su Calidad

Antes de sumergirnos en an치lisis profundos, es fundamental tener una visi칩n panor치mica de nuestro conjunto de datos. Esta etapa implica:

-   **Dimensiones del dataset:** 쮺u치ntas filas (observaciones) y columnas (variables) tenemos?

-   **Tipos de datos:** 쯃as variables son num칠ricas (enteros, flotantes), categ칩ricas (factores, caracteres), l칩gicas o de fecha/hora? Es crucial que los tipos de datos sean correctos para las operaciones que deseamos realizar.

-   **Inspecci칩n inicial:** Revisar las primeras y 칰ltimas filas del dataset para obtener una idea general del formato y contenido.

-   **Estad칤sticas descriptivas b치sicas:** Para variables num칠ricas: media, mediana, desviaci칩n est치ndar, m칤nimo, m치ximo, cuartiles. Para variables categ칩ricas: conteo de ocurrencias, proporciones. Esto nos da una primera impresi칩n de la dispersi칩n y centralidad de los datos.

Con `dlookr`, la funci칩n `diagnose()` es ideal para una revisi칩n r치pida de la calidad de los datos, mostrando el tipo de variable, el n칰mero de valores 칰nicos, valores faltantes, valores cero y valores negativos.

```{r diagnose-example, eval=FALSE}
# Para obtener un resumen r치pido de las caracter칤sticas de los datos
diagnose(mtcars_na)
```



Esta fase nos ayuda a formar una primera hip칩tesis sobre la calidad y estructura de los datos, identificando posibles problemas desde el principio.

#### 2. Identificaci칩n y Tratamiento de Valores Faltantes y At칤picos

Los valores faltantes (NA, NaN, null) y los valores at칤picos (outliers) son dos de los desaf칤os m치s comunes en cualquier conjunto de datos y pueden distorsionar significativamente los resultados de nuestros an치lisis y modelos.

**Valores Faltantes:**

-   **Identificaci칩n:** Cuantificar la cantidad y proporci칩n de valores faltantes por variable. Visualizar patrones de ausencia (쯟os valores faltantes ocurren aleatoriamente o hay un patr칩n?).

-   **Tratamiento:**

  - **Eliminaci칩n:** Si la cantidad de valores faltantes es peque침a o si una variable tiene un porcentaje muy alto de NAs, se pueden eliminar filas o columnas.

  - **Imputaci칩n:** Rellenar los valores faltantes. M칠todos comunes incluyen la media, mediana o moda (para datos num칠ricos y categ칩ricos, respectivamente), o m칠todos m치s avanzados basados en modelos (regresi칩n, k-NN, etc.). La elecci칩n depende de la naturaleza de los datos y el problema.

**Valores At칤picos:**

-   **Identificaci칩n:** Observaciones que se desv칤an significativamente del resto de los datos. Se pueden detectar mediante gr치ficos de caja (boxplots), diagramas de dispersi칩n, puntuaciones Z, el m칠todo IQR (rango intercuart칤lico) o algoritmos m치s sofisticados.

-   **Tratamiento:**

  -  **Eliminaci칩n:** Si se confirma que son errores de entrada de datos.

  -   **Transformaci칩n:** Aplicar transformaciones logar칤tmicas o de ra칤z cuadrada para reducir su impacto.

  -   **Capping/Flooring:** Limitar los valores at칤picos a un percentil superior o inferior (por ejemplo, el 99% o el 1%).

  -   **Mantener:** A veces, los valores at칤picos son observaciones genuinas e importantes que no deben eliminarse.
  
`dlookr` ofrece funciones visuales y program치ticas para abordar estos problemas:

```{r missing-outlier-example, eval=FALSE}
# Visualizar la distribuci칩n de valores faltantes
plot_na(mtcars_na)

# Identificar valores at칤picos para una variable espec칤fica (ej. "hp")
# plot_outlier() es excelente para visualizar.
plot_outlier(mtcars_df, "hp")
```
  

### 3. An치lisis de la Distribuci칩n de las Variables

Comprender la distribuci칩n de cada variable individualmente es clave para seleccionar los m칠todos estad칤sticos y de modelado adecuados.

**Variables Num칠ricas:**

-   **Histogramas y gr치ficos de densidad:** Permiten visualizar la forma de la distribuci칩n, identificar asimetr칤as (skewness), curtosis, y la presencia de m칰ltiples modos.
-   **Medidas de asimetr칤a y curtosis:** Cuantifican la forma de la distribuci칩n.
-   **Pruebas de normalidad:** Aunque muchas veces no son estrictamente necesarias, pueden complementar el an치lisis visual.

**Variables Categ칩ricas:** - **Gr치ficos de barras:** Muestran la frecuencia o proporci칩n de cada categor칤a. - **Tablas de frecuencia:** Resumen el conteo y porcentaje de cada nivel.

`dlookr` simplifica la visualizaci칩n de distribuciones:

```{r distribution-example, eval=FALSE}
# Visualizar la distribuci칩n de una variable num칠rica (ej. "mpg")
plot_hist(mtcars_df, "mpg")

# O ver la distribuci칩n y normalidad
plot_normality(mtcars_df, "mpg")

# Para variables categ칩ricas (como 'cyl' en mtcars que es num칠rica discreta)
# Podemos convertirla a factor para un an치lisis categ칩rico.
mtcars_factor_cyl <- mtcars_df %>% mutate(cyl = as.factor(cyl))
plot_bar(mtcars_factor_cyl, "cyl")
```


Este an치lisis nos ayuda a entender el comportamiento de cada caracter칤stica y a identificar la necesidad de transformaciones futuras.

### 4. An치lisis de las Relaciones entre las Variables

Esta etapa se centra en descubrir c칩mo las variables interact칰an entre s칤. Es fundamental para la selecci칩n de caracter칤sticas, la identificaci칩n de multicolinealidad y la comprensi칩n de la causalidad (o correlaci칩n).

-   **Dos variables num칠ricas:**

  -   **Diagramas de dispersi칩n (scatter plots):** Visualizan la direcci칩n y fuerza de la relaci칩n (positiva, negativa, nula, no lineal).
  -   **Coeficientes de correlaci칩n (Pearson, Spearman):** Cuantifican la fuerza y direcci칩n de la relaci칩n lineal (Pearson) o mon칩tona (Spearman).

-   **Una variable num칠rica y una categ칩rica:**

  -   **Gr치ficos de caja (boxplots) o gr치ficos de viol칤n:** Comparan la distribuci칩n de la variable num칠rica entre las diferentes categor칤as.
  -   **Pruebas t de Student o ANOVA:** Para determinar si hay diferencias estad칤sticamente significativas en las medias.

-   **Dos variables categ칩ricas:**

  -   **Tablas de contingencia y gr치ficos de barras apiladas/agrupadas:** Muestran la distribuci칩n conjunta.
  -   **Pruebas de significaci칩n:** Para evaluar la independencia entre las variables.
  -   **Matrices de correlaci칩n:** Visualizan las correlaciones entre m칰ltiples variables num칠ricas simult치neamente, a menudo con mapas de calor (heatmaps).
  
`dlookr` facilita la exploraci칩n de relaciones:

```{r correlation-example, eval=FALSE}
# Visualizar la matriz de correlaci칩n entre todas las variables num칠ricas
plot_cor(mtcars_df)

# Analizar la relaci칩n entre una variable objetivo ('mpg') y otra caracter칤stica ('wt')
# plot_eda() permite explorar diversas relaciones bivariadas.
plot_eda(mtcars_df, target = "mpg", feature = "wt") # Num칠rica vs Num칠rica (scatterplot)

# Relaci칩n entre 'mpg' (num칠rica) y 'cyl' (considerada categ칩rica aqu칤)
plot_eda(mtcars_df, target = "mpg", feature = "cyl") # Num칠rica vs Categ칩rica (boxplot)
```

### 5. Transformaci칩n de los Datos

Una vez que hemos comprendido nuestros datos, es posible que necesitemos transformarlos para que sean m치s adecuados para los algoritmos de machine learning o para mejorar el rendimiento del modelo.

-   **Manejo de asimetr칤a:**

  -   **Transformaciones logar칤tmicas, de ra칤z cuadrada o de Box-Cox:** Pueden normalizar distribuciones sesgadas, reduciendo la influencia de valores extremos.

-   **Escalado de caracter칤sticas:**

  -   **Normalizaci칩n (Min-Max Scaling):** Escala los datos a un rango fijo (por ejemplo, [0, 1]). 칔til para algoritmos sensibles a la escala como SVM o redes neuronales.

-   **Estandarizaci칩n (Z-score Scaling):** Transforma los datos para que tengan una media de 0 y una desviaci칩n est치ndar de 1. Es com칰n en algoritmos basados en distancia (k-NN, K-Means, PCA).

-   **Codificaci칩n de variables categ칩ricas:**

-   **One-Hot Encoding:** Convierte variables categ칩ricas en m칰ltiples columnas binarias, una por cada categor칤a. Esencial para algoritmos que solo trabajan con entradas num칠ricas.

-   **Label Encoding:** Asigna un n칰mero entero a cada categor칤a. 칔til si hay un orden inherente en las categor칤as.

-   **Ingenier칤a de Caracter칤sticas (Feature Engineering):** Crear nuevas variables a partir de las existentes. Esto puede ser tan simple como combinar dos columnas o tan complejo como extraer informaci칩n de texto o im치genes. Esta etapa es a menudo la que m치s impacto tiene en el rendimiento del modelo.


`dlookr` ofrece funciones 칰tiles para la transformaci칩n de datos:

```{r transform-example, eval=FALSE}
# Transformaci칩n logar칤tmica para reducir la asimetr칤a de una variable
mtcars_transformed_log <- transform_df(mtcars_df, mpg = log(mpg))
# Compara la distribuci칩n de mpg original vs. transformada
plot_normality(mtcars_df, "mpg")
plot_normality(mtcars_transformed_log, "mpg")

# Binarizaci칩n o discretizaci칩n de una variable continua (ej. 'hp' en 3 bins)
mtcars_binned <- binning(mtcars_df, "hp", n = 3)
head(mtcars_binned %>% select(hp, hp_Binned))

# Estandarizaci칩n de variables num칠ricas (Z-score)
mtcars_scaled <- normalize(mtcars_df, method = "scale")
head(mtcars_scaled) # Observa c칩mo los valores de todas las columnas han cambiado
```



## Herramientas Populares para EDA

Para realizar un EDA efectivo, contamos con potentes herramientas en lenguajes como R y Python:

-   **En R:**
    -   El ecosistema `tidyverse` (`dplyr` para manipulaci칩n, `ggplot2` para visualizaci칩n) es indispensable.
    -   Paquetes espec칤ficos para EDA como **`dlookr`**, es excelente por su enfoque estructurado en el diagn칩stico de calidad, exploraci칩n y transformaci칩n de datos, ofreciendo funciones y reportes automatizados que agilizan el proceso. Otros paquetes 칰tiles incluyen `DataExplorer`, `skimr`, y `visdat`.
-   **En Python:**
    -   `pandas` para manipulaci칩n de datos.
    -   `matplotlib` y `seaborn` para visualizaci칩n est치tica.
    -   `plotly` para visualizaciones interactivas.
    -   Bibliotecas como `missingno` para visualizar valores faltantes, `pandas_profiling` para informes autom치ticos de EDA, y `sweetviz` para comparaciones.

## Conclusi칩n

El An치lisis Exploratorio de Datos no es solo una fase inicial, sino un proceso continuo de aprendizaje sobre tus datos. Es una inversi칩n de tiempo que rinde grandes dividendos, ya que una comprensi칩n profunda de los datos nos permite tomar decisiones m치s informadas, construir modelos m치s robustos y, en 칰ltima instancia, extraer conocimientos m치s valiosos. Al dominar el EDA, te equipas con la habilidad de transformar datos brutos en una historia coherente y accionable, evitando la trampa del GIGO y asegurando que tus esfuerzos de ciencia de datos generen un impacto real.
