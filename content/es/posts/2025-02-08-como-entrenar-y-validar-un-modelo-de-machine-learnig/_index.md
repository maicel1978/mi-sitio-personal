---
title: "C√≥mo entrenar y validar un modelo de predicci√≥n cl√≠nica"
subtitle: "Tutorial para el desarrollo de un modelo de predicci√≥n cl√≠nica con ejemplos en R" 
authors: 
  - "admin"
date: '2024-02-08'
summary: "Gu√≠a pr√°ctica con R para desarrollar modelos predictivos robustos en entornos cl√≠nicos"
categories: 
  - "C√≥digo Pr√°ctico en R/Python"
  - "Metodolog√≠a de Investigaci√≥n"
tags:
  - "entrenar modelo ML en R para predicciones cl√≠nicas"
  - "tutorial en r para modelos predictivos m√©dicos"
  - "gu√≠a Steyerberg para modelos predictivos m√©dicos"
  - "evitar overfitting en validaci√≥n de ML"
  - "paso a paso R para machine learning en tesis"
slug: como-entrenar-y-validar-un-modelo-de-machine-learnig
featured: true  # Destacar en la p√°gina principal
language: es
related_posts: [eda]  # Slug de tu post sobre EDA
commentable: yes
---

üéß **Escucha el podcast de esta publicaci√≥n**

{{< audio src="https://ia600607.us.archive.org/24/items/articulo-steyember/_Articulo_Steyember.mp3" controls="yes" >}}

Si usted es un investigador en salud, estudiante de posgrado, maestr√≠a o doctorado en el campo de las ciencias biom√©dicas, y quiere enfocar su trabajo en el desarrollo de **modelos de predicci√≥n cl√≠nica** para el **diagn√≥stico** o el **pron√≥stico**, es probable que haya llegado a la fase donde la metodolog√≠a se vuelve un muro. No conoce qu√© pasos seguir, qu√© software utilizar o, despu√©s de meses de trabajo, existen dudas sobre su utilidad en contextos diferentes a los que fue creado.

Hoy en d√≠a, muchas tesis de alto nivel giran en torno a la creaci√≥n de modelos de predicci√≥n cl√≠nica (usando t√©cnicas de regresiones avanzadas  o Machine Learning).

Este post es su traductor metodol√≥gico y un tutorial. Muestro algunos consejos sobre c√≥mo hacer un modelo predictivo y algunas experiencias que yo mismo pas√© en mi tesis de doctorado.

Olv√≠dese del c√≥digo cr√≠ptico y c√©ntrese en la l√≥gica: vamos a desglosar los siete pasos cruciales del m√©todo Steyerberg para que su modelo predictivo sea robusto, confiable y publicable. Deje de sentir dolor con la estad√≠stica; convierta su modelo en una herramienta cl√≠nica √∫til.

# Estrategia de modelado

Contar con una estrategia de modelado correcta es esencial para desarrollar y validar modelos de predicci√≥n. En este art√≠culo, exploraremos las siete etapas clave del proceso de modelado propuesto por Ewout Steyerberg en su art√≠culo (1).

## 1. Definici√≥n del problema e inspecci√≥n de datos {#sec-1}

El primer paso en cualquier proyecto de modelado es **definir claramente el problema de investigaci√≥n** y seleccionar la **variable de resultado** adecuada.

{{% callout note %}}
### Variable de resultado
La **variable de resultado** debe definirse con precisi√≥n: especifica **qu√© evento se predice**, **c√≥mo y cu√°ndo se mide**, y el **horizonte temporal de predicci√≥n** (por ejemplo, mortalidad a 30 d√≠as). Indica adem√°s el m√©todo de evaluaci√≥n y si hubo **cegamiento** respecto a los predictores, para garantizar coherencia y validez del modelo.
{{% /callout %}}

Durante esta fase, tambi√©n realizamos un an√°lisis exploratorio de datos (EDA) para comprender las caracter√≠sticas de las variables y detectar posibles problemas, como **datos at√≠picos** o **valores faltantes**.



``` r
# Realiza una descripci√≥n general del conjunto de datos
# Instala y Carga de Librer√≠as √∫tiles 
library(caret)
library(MLDataR) # para utilizar la biblioteca diabetes_data
library(dplyr)
library(dlookr) # para EDA
library(predtools)
# Cargar el conjunto de datos
data("gusto")
gusto <- gusto
# EDA
descripcion <- overview(gusto)
summary(descripcion) # descripci√≥n general del conjunto de datos
```

<!-- Para conocer m√°s detalles sobre el proceso de ¬®Exploratory Data Analysis (EDA)¬® [ver la publicaci√≥n dedicada a este tema](es/post/2025-02-11-eda/_index.Rmd) -->

## 2. Codificaci√≥n de las variables predictoras {#sec-2}

La **codificaci√≥n** adecuada de las **variables predictoras** es fundamental para construir modelos robustos.

Es probable que debas utilizar t√©cnicas como la agrupaci√≥n de categor√≠as poco frecuentes y la creaci√≥n de predictores res√∫menes para simplificar informaci√≥n correlacionada. Adem√°s, cuando las relaciones entre variables no son lineales, aplicamos herramientas como **splines c√∫bicos restringidos** , que permiten capturar patrones complejos sin comprometer la precisi√≥n del modelo.

Dicotomizar predictores cuantitativos (por ejemplo, transformar una variable continua como la edad o la presi√≥n arterial en una variable binaria, como ‚Äú‚â•65 a√±os = 1‚Äù y ‚Äú\<65 = 0‚Äù) es considerada una mala pr√°ctica metodol√≥gica.

## 3 .Especificaci√≥n del tipo de modelo {#sec-3}

La elecci√≥n del modelo depende del tipo de relaci√≥n que queremos capturar entre las variables.

![](modelos_elecion.png)


Un aspecto clave es la selecci√≥n de predictores finales para lo que se emplean varios m√©todos. Sin embargo, la aplicaci√≥n mec√°nica de m√©todos algor√≠tmicos tradicionales, como la Regresi√≥n Paso a Paso (RPP), ha demostrado ser inconsistente y poco robusta, especialmente en el contexto de las aplicaciones biom√©dicas y sociales.


## 4. Estimaci√≥n del Modelo {#sec-4}

El paso de estimaci√≥n del modelo es un componente central del desarrollo de modelos predictivos, orientado a obtener los par√°metros o estructuras que mejor expliquen los datos de entrenamiento. Su prop√≥sito es equilibrar el ajuste al conjunto de datos con la capacidad del modelo para generalizar a nuevas observaciones.

La regularizaci√≥n es una estrategia clave dentro de este proceso, dise√±ada para reducir el sobreajuste (overfitting) mediante la introducci√≥n controlada de sesgo que estabiliza las predicciones.

Modelos param√©tricos (p. ej., regresi√≥n): emplean t√©cnicas de contracci√≥n o shrinkage (como LASSO o Ridge regression) que aplican una penalizaci√≥n sobre los coeficientes estimados ‚Äîbasados en m√°xima verosimilitud penalizada‚Äî, reduciendo la varianza y evitando predicciones extremas.

Modelos de machine learning (p. ej., XGBoost, SVM, Random Forest): utilizan la optimizaci√≥n de hiperpar√°metros (como la tasa de aprendizaje, el par√°metro C o la profundidad de los √°rboles) para controlar la complejidad del modelo. Estos ajustes inducen un sesgo controlado que mejora la validez externa y la estabilidad predictiva frente a nuevos datos.

En conjunto, la estimaci√≥n y la regularizaci√≥n contribuyen a lograr un modelo m√°s robusto y generalizable, especialmente cuando se combinan con una validaci√≥n interna adecuada (como cross-validation o bootstrap).


## 5. Evaluaci√≥n del Rendimiento del Modelo {#sec-5}

El rendimiento del modelo se eval√∫a mediante m√©tricas como calibraci√≥n y discriminaci√≥n . La calibraci√≥n mide la concordancia entre las predicciones y los resultados observados, mientras que la discriminaci√≥n eval√∫a la capacidad del modelo para distinguir entre pacientes con diferentes resultados. Herramientas como las rectas de calibraci√≥n y la validaci√≥n cruzada de 10 pliegues fueron fundamentales para asegurar la calidad del modelo.

## 6. Evaluaci√≥n de la Validez del Modelo {#sec-6}

La validaci√≥n del modelo es un paso cr√≠tico para garantizar su aplicabilidad en diferentes contextos. En este estudio, utilizamos tanto validaci√≥n interna como externa , empleando particiones temporales y geogr√°ficas para reflejar escenarios reales. Este enfoque nos permiti√≥ evaluar la robustez del modelo frente a cambios en el tiempo y variaciones regionales.

## 7. Presentaci√≥n del modelo {#sec-7}

La presentaci√≥n efectiva es crucial para la adopci√≥n cl√≠nica. Un modelo perfecto es in√∫til si los m√©dicos no pueden interpretarlo f√°cilmente. Considera:

- **Nomogramas**: Ideales para uso r√°pido en consulta
- **Aplicaciones web/m√≥viles**: Para integraci√≥n en flujos de trabajo cl√≠nicos
- **Puntuaciones de riesgo**: Simplificadas para triaje r√°pido
- **Documentaci√≥n clara**: Incluyendo limitaciones y casos de uso

Recuerda: la transparencia en la presentaci√≥n favorece la confianza cl√≠nica.


¬øHas aplicado estas t√©cnicas en tus proyectos de Machine Learning? ¬øQu√© estrategias usas para entrenar y validar tus modelos? D√©jame tus comentarios üí¨: comparte tus experiencias, dificultades o tips contigo. ¬°Juntos podemos enriquecer este conocimiento!

# Bibliograf√≠a

1.  Steyerberg EW, Vergouwe Y. Towards better clinical prediction models: seven steps for development and an ABCD for validation. European Heart Journal [Internet]. 1 de agosto de 2014 [citado 9 de mayo de 2021];35(29):1925-31. Disponible en: <https://academic.oup.com/eurheartj/article-lookup/doi/10.1093/eurheartj/ehu207>


