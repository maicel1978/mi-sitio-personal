library(mlbench)   # Conjunto de datos de ejemplo (PimaIndiansDiabetes)
library(dplyr)     # Manipulaci√≥n √°gil de datos
library(caret)
library(dplyr)
conflict_scout()
# Bibliotecas esenciales
library(conflicted)  # Evita conflictos entre funciones de distintos paquetes
library(pROC)    # Para curvas ROC y estad√≠sticas de discriminaci√≥n
library(ggplot2)# Gr√°ficos listos para publicaci√≥n
library(missRanger) # Imputaci√≥n moderna y eficiente de valores faltantes
library(mlbench)   # Conjunto de datos de ejemplo (PimaIndiansDiabetes)
library(dplyr)     # Manipulaci√≥n √°gil de datos
library(caret)
library(dplyr)
library(rms)     # El n√∫cleo de la estrategia de modelado (Steyerberg & Harrell)
# Establecer preferencias expl√≠citas
conflict_prefer("filter", "rms")
# Bibliotecas esenciales
library(conflicted)  # Evita conflictos entre funciones de distintos paquetes
library(pROC)    # Para curvas ROC y estad√≠sticas de discriminaci√≥n
library(ggplot2)# Gr√°ficos listos para publicaci√≥n
library(missRanger) # Imputaci√≥n moderna y eficiente de valores faltantes
library(mlbench)   # Conjunto de datos de ejemplo (PimaIndiansDiabetes)
library(dplyr)     # Manipulaci√≥n √°gil de datos
library(caret)
library(dplyr)
library(rms)     # El n√∫cleo de la estrategia de modelado (Steyerberg & Harrell)
# Establecer preferencias expl√≠citas
conflict_prefer("filter", "Hmisc")
# Bibliotecas esenciales
library(conflicted)  # Evita conflictos entre funciones de distintos paquetes
library(rms)     # El n√∫cleo de la estrategia de modelado (Steyerberg & Harrell)
library(Hmisc)
library(pROC)    # Para curvas ROC y estad√≠sticas de discriminaci√≥n
library(ggplot2)# Gr√°ficos listos para publicaci√≥n
library(missRanger) # Imputaci√≥n moderna y eficiente de valores faltantes
library(mlbench)   # Conjunto de datos de ejemplo (PimaIndiansDiabetes)
library(dplyr)     # Manipulaci√≥n √°gil de datos
library(caret)
library(dplyr)
# CONFIGURACI√ìN INICIAL Y GESTI√ìN DE CONFLICTOS
library(conflicted)   # üõ°Ô∏è  Previene conflictos entre paquetes
library(rms)          # üìä  Estrategia de modelado (Steyerberg & Harrell)
library(Hmisc)        # üîç  Herramientas estad√≠sticas complementarias
library(pROC)         # üìà  Curvas ROC y m√©tricas de discriminaci√≥n
library(ggplot2)      # üé®  Gr√°ficos para publicaci√≥n cient√≠fica
library(missRanger)   # üîÑ  Imputaci√≥n m√∫ltiple con bosques aleatorios
library(mlbench)      # üíæ  Conjuntos de datos de ejemplo
library(dplyr)        # üõ†Ô∏è  Manipulaci√≥n moderna de datos
library(caret)        # ü§ñ  Machine Learning y validaci√≥n
# RESOLUCI√ìN EXPL√çCITA DE CONFLICTOS CR√çTICOS
conflict_prefer("filter", "dplyr")
conflict_prefer("select", "dplyr")
conflict_prefer("summarise", "dplyr")
conflict_prefer("rename", "dplyr")
conflict_prefer("recode", "dplyr")
conflict_prefer("describe", "Hmisc")
conflict_prefer("rcorr", "Hmisc")
conflict_prefer("cut2", "Hmisc")
cat("‚úÖ Todas las bibliotecas cargadas y conflictos resueltos\n")
# Manejo de datos
set.seed(123)   # Garantiza reproducibilidad en imputaci√≥n y modelado
# CARGA Y PREPARACI√ìN DE LOS DATOS
data("PimaIndiansDiabetes")
datos <- PimaIndiansDiabetes
# Variables predictoras cl√≠nicas de inter√©s
vars_clinicas <- c("glucose", "pressure", "triceps", "insulin", "mass")
# PASO CR√çTICO: Limpieza e imputaci√≥n
datos <- datos %>%
# En datos cl√≠nicos, el valor 0 suele ser biol√≥gicamente imposible ‚Üí lo convertimos en NA
mutate(across(all_of(vars_clinicas), ~ ifelse(.x == 0, NA, .x))) %>%
# Imputamos los valores faltantes usando missRanger (basado en bosques aleatorios)
missRanger()
# CONFIGURACI√ìN OBLIGATORIA PARA RMS
# datadist almacena res√∫menes de las variables y permite que rms genere predicciones e interpretaciones autom√°ticas
dd <- datadist(datos)
options(datadist = "dd")
blogdown:::serve_site()
#MODELO: PREDICTORES POR FISIOPATOLOG√çA, NO p-valores
modelo <- lrm(diabetes ~ rcs(glucose, 3) + rcs(mass, 3) + age + pregnant + pedigree,
data = datos,
x = TRUE,
y = TRUE)
# calibrate(): Bootstrap para evaluar y corregir la calibraci√≥n
cal_boot <- calibrate(modelo, method = "boot", B = 200)
# GR√ÅFICOS
plot(cal_boot, main = "Probabilidades predichas vs observadas")
abline(0, 1, lty = 2, col = "red")
# validate(): Bootstrap para estimar el optimismo y corregir m√©tricas de discriminaci√≥n
val_boot <- validate(modelo, method = "boot", B = 200)
roc_obj <- roc(datos$diabetes, predict(modelo, type = "fitted"))
plot(roc_obj,
main = paste("AUC =", round(auc(roc_obj), 3)),
col = "blue",
legacy.axes = TRUE)
# NOMOGRAMA: EL TEST DE USABILIDAD CL√çNICA
nom <- nomogram(modelo, fun = plogis, funlabel = "Riesgo Diabetes")
plot(nom)
data(PimaIndiansDiabetes); datos <- PimaIndiansDiabetes
#Simular 100 splits simples y calcular AUC
auc_splits <- replicate(1009, {
trainIndex <- createDataPartition(datos$diabetes, p=0.7, list=FALSE)
train <- datos[trainIndex,]; test <- datos[-trainIndex,]
model <- glm(diabetes ~ glucose + mass + age, family=binomial, data=train)
pred <- predict(model, test, type="response")
roc(test$diabetes, pred)$auc
})
hist(auc_splits, main="Distribuci√≥n de AUC en 100 splits simples", xlab="AUC")
sd(auc_splits)  # Desviaci√≥n est√°ndar alta
# validate(): Bootstrap para estimar el optimismo y corregir m√©tricas de discriminaci√≥n
# validate(): Bootstrap para estimar el optimismo
val_boot <- validate(modelo, method = "boot", B = 200)
# CORRECCI√ìN: Especificar pROC:: y quiera par√©ntesis extra
roc_obj <- pROC::roc(datos$diabetes, predict(modelo, type = "fitted"))
plot(roc_obj,
main = paste("AUC =", round(pROC::auc(roc_obj), 3)),
col = "blue",
legacy.axes = TRUE)
data(PimaIndiansDiabetes); datos_sim <- PimaIndiansDiabetes
# Simular 100 splits simples (n√∫mero razonable)
auc_splits <- replicate(100, {
trainIndex <- caret::createDataPartition(datos_sim$diabetes, p=0.7, list=FALSE)
train <- datos_sim[trainIndex,]; test <- datos_sim[-trainIndex,]
model <- glm(diabetes ~ glucose + mass + age, family=binomial, data=train)
pred <- predict(model, test, type="response")
pROC::roc(test$diabetes, pred)$auc  # Especificar pROC::
})
hist(auc_splits, main="Distribuci√≥n de AUC en 100 splits simples", xlab="AUC")
cat("Desviaci√≥n est√°ndar:", sd(auc_splits), "\n")
blogdown::stop_server()
unlink("public", recursive = TRUE)  # Elimina la carpeta public
unlink("resources", recursive = TRUE)  # Elimina cach√© de recursos
blogdown::build_site(local = TRUE)  # Forzar reconstrucci√≥n completa
blogdown::build_site()
blogdown:::serve_site()
# calibrate(): Bootstrap para evaluar y corregir la calibraci√≥n
cal_boot <- calibrate(modelo, method = "boot", B = 200)
# GR√ÅFICO CORREGIDO
plot(cal_boot,
main = "Curva de Calibraci√≥n: Probabilidades Predichas vs Observadas",
sub = "M√©todo Bootstrap (200 r√©plicas)",  # CORRECCI√ìN: 'sub' no 'subt'
col = "darkblue",
lwd = 2)
# calibrate(): Bootstrap para evaluar y corregir la calibraci√≥n
cal_boot <- calibrate(modelo, method = "boot", B = 200)
# GR√ÅFICO CORREGIDO
plot(cal_boot,
main = "Curva de Calibraci√≥n: Probabilidades Predichas vs Observadas",
sub = "M√©todo Bootstrap (200 r√©plicas)",  # CORRECCI√ìN: 'sub' no 'subt'
col = "darkblue",
lwd = 2)
# Extraer datos de calibraci√≥n
cal_data <- data.frame(
pred = cal_boot[,"predicted"],
obs = cal_boot[,"observed"],
lower = cal_boot[,"lower"],
upper = cal_boot[,"upper"]
)
# calibrate(): Bootstrap para evaluar y corregir la calibraci√≥n
cal_boot <- calibrate(modelo, method = "boot", B = 200)
# GR√ÅFICO CORREGIDO - SIN PAR√ÅMETRO 'sub'
plot(cal_boot,
main = "Curva de Calibraci√≥n: Probabilidades Predichas vs Observadas\nM√©todo Bootstrap (200 r√©plicas)",
col = "darkblue",
lwd = 2)
abline(0, 1, lty = 2, col = "red", lwd = 2)
legend("topleft",
legend = c("Calibraci√≥n observada", "Calibraci√≥n perfecta"),
col = c("darkblue", "red"),
lty = c(1, 2),
lwd = 2,
bty = "n")
# calibrate(): Bootstrap para evaluar y corregir la calibraci√≥n
cal_boot <- calibrate(modelo, method = "boot", B = 200)
# GR√ÅFICO CORREGIDO - SIN PAR√ÅMETRO 'sub'
plot(cal_boot,
main = "Curva de Calibraci√≥n: Probabilidades Predichas vs Observadas\nM√©todo Bootstrap (200 r√©plicas)",
col = "darkblue",
lwd = 2)
abline(0, 1, lty = 2, col = "red", lwd = 2)
legend("topleft",
legend = c("Calibraci√≥n observada", "Calibraci√≥n perfecta"),
col = c("darkblue", "red"),
lty = c(1, 2),
lwd = 2,
bty = "n")
# calibrate(): Bootstrap para evaluar y corregir la calibraci√≥n
cal_boot <- calibrate(modelo, method = "boot", B = 200)
# GR√ÅFICO CORREGIDO - SIN PAR√ÅMETRO 'sub'
plot(cal_boot,
main = "Probabilidades Predichas vs Observadas\nM√©todo Bootstrap (200 r√©plicas)",
col = "darkblue",
lwd = 2)
abline(0, 1, lty = 2, col = "red", lwd = 2)
legend("topleft",
legend = c("Calibraci√≥n observada", "Calibraci√≥n perfecta"),
col = c("darkblue", "red"),
lty = c(1, 2),
lwd = 2,
bty = "n")
# validate(): Bootstrap para estimar el optimismo y corregir m√©tricas de discriminaci√≥n
# validate(): Bootstrap para estimar el optimismo
val_boot <- validate(modelo, method = "boot", B = 200)
# CORRECCI√ìN: Especificar pROC:: y quiera par√©ntesis extra
roc_obj <- pROC::roc(datos$diabetes, predict(modelo, type = "fitted"))
plot(roc_obj,
main = paste("AUC =", round(pROC::auc(roc_obj), 3)),
col = "blue",
legacy.axes = TRUE)
# NOMOGRAMA CON MEJOR VISUALIZACI√ìN
nom <- nomogram(modelo,
fun = plogis,
funlabel = "Riesgo de Diabetes",
lp = FALSE,
col.grid = gray(c(0.8, 0.95)))
nom <- nomogram(modelo,
fun = plogis,
funlabel = "Riesgo de Diabetes",
lp = FALSE,
col.grid = gray(c(0.8, 0.95)))
# NOMOGRAMA CON MEJOR VISUALIZACI√ìN
nom <- nomogram(modelo,
fun = plogis,
funlabel = "Riesgo de Diabetes",
lp = FALSE)
plot(nom,
main = "Nomograma para Predicci√≥n de Diabetes",
cex.axis = 0.8,
lmgp = 0.3)
knitr::opts_chunk$set(
echo = TRUE,
message = FALSE,
warning = FALSE,
fig.width = 8,
fig.height = 6,
fig.align = 'center',
fig.path = "figures/",  # Ruta espec√≠fica para figuras
dev = 'png',           # Formato de salida
dpi = 150              # Resoluci√≥n adecuada para web
)
# Bibliotecas esenciales
library(conflicted)  # Evita conflictos entre funciones de distintos paquetes
library(rms)     # El n√∫cleo de la estrategia de modelado (Steyerberg & Harrell)
library(pROC)    # Para curvas ROC y estad√≠sticas de discriminaci√≥n
library(ggplot2)# Gr√°ficos listos para publicaci√≥n
library(missRanger) # Imputaci√≥n moderna y eficiente de valores faltantes
library(mlbench)   # Conjunto de datos de ejemplo (PimaIndiansDiabetes)
library(dplyr)     # Manipulaci√≥n √°gil de datos
library(caret)
library(dplyr)
set.seed(123)   # Garantiza reproducibilidad en imputaci√≥n y modelado
# CARGA Y PREPARACI√ìN DE LOS DATOS
data("PimaIndiansDiabetes")
datos <- PimaIndiansDiabetes
# Variables predictoras cl√≠nicas de inter√©s
vars_clinicas <- c("glucose", "pressure", "triceps", "insulin", "mass")
# PASO CR√çTICO: Limpieza e imputaci√≥n
datos <- datos %>%
# En datos cl√≠nicos, el valor 0 suele ser biol√≥gicamente imposible ‚Üí lo convertimos en NA
mutate(across(all_of(vars_clinicas), ~ ifelse(.x == 0, NA, .x))) %>%
# Imputamos los valores faltantes usando missRanger (basado en bosques aleatorios)
missRanger()
# CONFIGURACI√ìN OBLIGATORIA PARA RMS
# datadist almacena res√∫menes de las variables y permite que rms genere predicciones e interpretaciones autom√°ticas
dd <- datadist(datos)
options(datadist = "dd")
modelo <- lrm(diabetes ~ rcs(glucose, 3) + rcs(mass, 3) + age + pregnant + pedigree,
data = datos,
x = TRUE,
y = TRUE)
# calibrate(): Bootstrap para evaluar y corregir la calibraci√≥n
cal_boot <- calibrate(modelo, method = "boot", B = 200)
# GR√ÅFICOS
plot(cal_boot, main = "Probabilidasde predichas vs observadas")
abline(0, 1, lty = 2, col = "red")
# validate(): Bootstrap para estimar el optimismo y corregir m√©tricas de discriminaci√≥n
val_boot <- validate(modelo, method = "boot", B = 200)
roc_obj <- roc(datos$diabetes, predict(modelo, type = "fitted"))
plot(roc_obj,
main = paste("AUC =", round(auc(roc_obj), 3)),
col = "blue",
legacy.axes = TRUE)
nom <- nomogram(modelo, fun = plogis, funlabel = "Riesgo Diabetes")
plot(nom)
data(PimaIndiansDiabetes); datos <- PimaIndiansDiabetes
#Simular 100 splits simples y calcular AUC
auc_splits <- replicate(100, {
trainIndex <- createDataPartition(datos$diabetes, p=0.7, list=FALSE)
train <- datos[trainIndex,]; test <- datos[-trainIndex,]
model <- glm(diabetes ~ glucose + mass + age, family=binomial, data=train)
pred <- predict(model, test, type="response")
roc(test$diabetes, pred)$auc
})
hist(auc_splits, main="Distribuci√≥n de AUC en 100 splits simples", xlab="AUC")
knitr::opts_chunk$set(
echo = TRUE,          # Muestra el c√≥digo (ideal para blog educativo)
message = FALSE,      # Oculta mensajes de paquetes
warning = FALSE,      # Oculta warnings (datos limpios)
collapse = TRUE,      # Une c√≥digo y salida
fig.width = 8,        # Ancho est√°ndar
fig.height = 6,       # Alto est√°ndar
fig.align = 'center', # Centrado en web
out.width = '80%',    # Responsive en HTML
fig.path = "figures/",# Carpeta espec√≠fica (blogdown la crea auto)
dev = 'png',          # Formato ligero para web
dpi = 150,            # Resoluci√≥n buena sin archivos pesados
cache = FALSE         # Sin cache para demos r√°pidas (activa si necesitas)
)
Si est√° leyendo esta publicaci√≥n, es probable que le interese desarrollar **modelos de predicci√≥n cl√≠nica** para **diagnosticar** o **pronosticar** enfermedades en pacientes. Seguramente sea investigador o estudiante de posgrado ‚Äîen maestr√≠a o doctorado‚Äî en ciencias biom√©dicas, y busque c√≥mo **desarrollar** y **validar** esos modelos en un **art√≠culo cient√≠fico** o **tesis**.
knitr::opts_chunk$set(
echo = TRUE,          # Muestra el c√≥digo (ideal para blog educativo)
message = FALSE,      # Oculta mensajes de paquetes
warning = FALSE,      # Oculta warnings (datos limpios)
collapse = TRUE,      # Une c√≥digo y salida
fig.width = 8,        # Ancho est√°ndar
fig.height = 6,       # Alto est√°ndar
fig.align = 'center', # Centrado en web
out.width = '80%',    # Responsive en HTML
fig.path = "figures/",# Carpeta espec√≠fica (blogdown la crea auto)
dev = 'png',          # Formato ligero para web
dpi = 150,            # Resoluci√≥n buena sin archivos pesados
cache = FALSE         # Sin cache para demos r√°pidas (activa si necesitas)
)
knitr::opts_chunk$set(
echo = TRUE,          # Muestra el c√≥digo (ideal para blog educativo)
message = FALSE,      # Oculta mensajes de paquetes
warning = FALSE,      # Oculta warnings (datos limpios)
collapse = TRUE,      # Une c√≥digo y salida
fig.width = 8,        # Ancho est√°ndar
fig.height = 6,       # Alto est√°ndar
fig.align = 'center', # Centrado en web
out.width = '80%',    # Responsive en HTML
dev = 'png',          # Formato ligero para web
dpi = 150,            # Resoluci√≥n buena sin archivos pesados
cache = FALSE         # Sin cache para demos r√°pidas (activa si necesitas)
)
library(conflicted)   # Detecta y resuelve conflictos de funciones
library(rms)          # Modelado log√≠stico restringido (lrm) y splines (rcs)
library(pROC)         # Curvas ROC y AUC
library(ggplot2)      # Gr√°ficos pulidos (usado por rms internamente)
library(missRanger)   # Imputaci√≥n iterativa con random forests
library(mlbench)      # Dataset de ejemplo: PimaIndiansDiabetes
library(dplyr)        # Manipulaci√≥n de datos (pipe %>%)
library(caret)        # Particiones de datos (createDataPartition)
set.seed(123)  # Reproducibilidad total (imputaci√≥n, splits, bootstrap)
# Carga del dataset nativo
data("PimaIndiansDiabetes")
datos <- PimaIndiansDiabetes
# Variables cl√≠nicas con 0s imposibles (biol√≥gicamente)
vars_clinicas <- c("glucose", "pressure", "triceps", "insulin", "mass")
# Limpieza: 0 ‚Üí NA, luego imputaci√≥n
datos <- datos %>%
mutate(across(all_of(vars_clinicas), ~ ifelse(.x == 0, NA, .x))) %>%
missRanger()  # Imputa NA con random forests iterativos
# Configuraci√≥n rms: datadist para predicciones autom√°ticas
dd <- datadist(as.data.frame(datos))
options(datadist = "dd")
cal_boot <- calibrate(modelo, method = "boot", B = 100)
plot(cal_boot, main = "Calibraci√≥n: Predichas vs Observadas")
abline(0, 1, lty = 2, col = "red")  # L√≠nea ideal
val_boot <- validate(modelo, method = "boot", B = 100)
roc_obj <- roc(datos$diabetes, predict(modelo, type = "fitted"))
plot(roc_obj,
main = paste("Curva ROC - AUC =", round(auc(roc_obj), 3)),
col = "blue",
legacy.axes = TRUE)
nom <- nomogram(modelo, fun = plogis, funlabel = "Riesgo de Diabetes")
plot(nom, main = "Nomograma del Modelo")
auc_splits <- replicate(100, {
trainIndex <- createDataPartition(datos$diabetes, p = 0.7, list = FALSE)
train <- datos[trainIndex, ]; test <- datos[-trainIndex, ]
model_simple <- glm(diabetes ~ glucose + mass + age, family = binomial, data = train)
pred <- predict(model_simple, test, type = "response")
roc(test$diabetes, pred)$auc
})
hist(auc_splits,
main = "Distribuci√≥n de AUC en 100 Splits Simples",
xlab = "AUC",
col = "lightgray",
border = "black")
blogdown:::serve_site()
knitr::opts_chunk$set(
echo = TRUE,          # Muestra el c√≥digo (ideal para blog educativo)
message = FALSE,      # Oculta mensajes de paquetes
warning = FALSE,      # Oculta warnings (datos limpios)
collapse = TRUE,      # Une c√≥digo y salida
fig.width = 8,        # Ancho est√°ndar
fig.height = 6,       # Alto est√°ndar
fig.align = 'center', # Centrado en web
out.width = '80%',    # Responsive en HTML
dev = 'png',          # Formato ligero para web
dpi = 150,            # Resoluci√≥n buena sin archivos pesados
cache = FALSE         # Sin cache para demos r√°pidas (activa si necesitas)
)
library(conflicted)   # Detecta y resuelve conflictos de funciones
library(rms)          # Modelado log√≠stico restringido (lrm) y splines (rcs)
library(pROC)         # Curvas ROC y AUC
library(ggplot2)      # Gr√°ficos pulidos (usado por rms internamente)
library(missRanger)   # Imputaci√≥n iterativa con random forests
library(mlbench)      # Dataset de ejemplo: PimaIndiansDiabetes
library(dplyr)        # Manipulaci√≥n de datos (pipe %>%)
library(caret)        # Particiones de datos (createDataPartition)
set.seed(123)  # Reproducibilidad total (imputaci√≥n, splits, bootstrap)
# Carga del dataset nativo
data("PimaIndiansDiabetes")
datos <- PimaIndiansDiabetes
# Variables cl√≠nicas con 0s imposibles (biol√≥gicamente)
vars_clinicas <- c("glucose", "pressure", "triceps", "insulin", "mass")
# Limpieza: 0 ‚Üí NA, luego imputaci√≥n
datos <- datos %>%
mutate(across(all_of(vars_clinicas), ~ ifelse(.x == 0, NA, .x))) %>%
missRanger()  # Imputa NA con random forests iterativos
# Configuraci√≥n rms: datadist para predicciones autom√°ticas
dd <- datadist(as.data.frame(datos))
options(datadist = "dd")
modelo <- lrm(
diabetes ~ rcs(glucose, 3) + rcs(mass, 3) + rcs(age, 3) + rcs(pedigree, 3) + pregnant,
data = datos,
x = TRUE,  # Guarda dise√±o para bootstrap
y = TRUE   # Guarda respuesta para bootstrap
)
cal_boot <- calibrate(modelo, method = "boot", B = 100)
plot(cal_boot, main = "Calibraci√≥n: Predichas vs Observadas")
abline(0, 1, lty = 2, col = "red")  # L√≠nea ideal
val_boot <- validate(modelo, method = "boot", B = 100)
roc_obj <- roc(datos$diabetes, predict(modelo, type = "fitted"))
plot(roc_obj,
main = paste("Curva ROC - AUC =", round(auc(roc_obj), 3)),
col = "blue",
legacy.axes = TRUE)
nom <- nomogram(modelo, fun = plogis, funlabel = "Riesgo de Diabetes")
plot(nom, main = "Nomograma del Modelo")
auc_splits <- replicate(100, {
trainIndex <- createDataPartition(datos$diabetes, p = 0.7, list = FALSE)
train <- datos[trainIndex, ]; test <- datos[-trainIndex, ]
model_simple <- glm(diabetes ~ glucose + mass + age, family = binomial, data = train)
pred <- predict(model_simple, test, type = "response")
roc(test$diabetes, pred)$auc
})
hist(auc_splits,
main = "Distribuci√≥n de AUC en 100 Splits Simples",
xlab = "AUC",
col = "lightgray",
border = "black")
library(conflicted)   # Detecta y resuelve conflictos de funciones
library(rms)          # Modelado log√≠stico restringido (lrm) y splines (rcs)
library(pROC)         # Curvas ROC y AUC
library(ggplot2)      # Gr√°ficos pulidos (usado por rms internamente)
library(missRanger)   # Imputaci√≥n iterativa con random forests
library(mlbench)      # Dataset de ejemplo: PimaIndiansDiabetes
library(dplyr)        # Manipulaci√≥n de datos (pipe %>%)
library(caret)        # Particiones de datos (createDataPartition)
blogdown::build_site()
blogdown:::stop_server()
blogdown:::stop_server()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown::build_site()
blogdown::serve_site()
blogdown:::stop_server()
blogdown::serve_site()
blogdown::stop_server()
blogdown::build_site()
blogdown::serve_site()
blogdown::stop_server()
blogdown::serve_site()
blogdown::serve_site()
blogdown::stop_server()
blogdown::serve_site()
blogdown::serve_site()
blogdown::stop_server()
blogdown::build_site()
blogdown::serve_site()
blogdown::build_site()
blogdown::serve_site()
blogdown::stop_server()
blogdown::serve_site()
blogdown::serve_site()
blogdown::stop_server()
blogdown::build_site()
blogdown::serve_site()
blogdown::build_site(local = FALSE)
blogdown:::check_site()  # Verifica errores.
blogdown::build_site(local = FALSE, build_rmd = TRUE)
blogdown:::check_site()  # Verifica errores.
blogdown:::stop_server() # Detiene el servidor.
blogdown:::serve_site()  # Sirve localmente para preview.
blogdown:::stop_server() # Detiene el servidor.
blogdown:::serve_site()  # Sirve localmente para preview.
blogdown:::serve_site()  # Sirve localmente para preview.
blogdown:::stop_server() # Detiene el servidor.
blogdown:::serve_site()  # Sirve localmente para preview.
blogdown::stop_server()
blogdown::serve_site()
blogdown::stop_server()
blogdown::serve_site()
blogdown::stop_server()
blogdown::stop_server()
unlink("public", recursive = TRUE)   # Borrar carpeta public
blogdown::build_site(local = FALSE)
blogdown::stop_server()
blogdown::build_site()
blogdown::serve_site()
blogdown:::check_site()  # Verifica errores.
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::stop_server()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::stop_server()
