library(mlbench)   # Conjunto de datos de ejemplo (PimaIndiansDiabetes)
library(dplyr)     # Manipulación ágil de datos
library(caret)
library(dplyr)
conflict_scout()
# Bibliotecas esenciales
library(conflicted)  # Evita conflictos entre funciones de distintos paquetes
library(pROC)    # Para curvas ROC y estadísticas de discriminación
library(ggplot2)# Gráficos listos para publicación
library(missRanger) # Imputación moderna y eficiente de valores faltantes
library(mlbench)   # Conjunto de datos de ejemplo (PimaIndiansDiabetes)
library(dplyr)     # Manipulación ágil de datos
library(caret)
library(dplyr)
library(rms)     # El núcleo de la estrategia de modelado (Steyerberg & Harrell)
# Establecer preferencias explícitas
conflict_prefer("filter", "rms")
# Bibliotecas esenciales
library(conflicted)  # Evita conflictos entre funciones de distintos paquetes
library(pROC)    # Para curvas ROC y estadísticas de discriminación
library(ggplot2)# Gráficos listos para publicación
library(missRanger) # Imputación moderna y eficiente de valores faltantes
library(mlbench)   # Conjunto de datos de ejemplo (PimaIndiansDiabetes)
library(dplyr)     # Manipulación ágil de datos
library(caret)
library(dplyr)
library(rms)     # El núcleo de la estrategia de modelado (Steyerberg & Harrell)
# Establecer preferencias explícitas
conflict_prefer("filter", "Hmisc")
# Bibliotecas esenciales
library(conflicted)  # Evita conflictos entre funciones de distintos paquetes
library(rms)     # El núcleo de la estrategia de modelado (Steyerberg & Harrell)
library(Hmisc)
library(pROC)    # Para curvas ROC y estadísticas de discriminación
library(ggplot2)# Gráficos listos para publicación
library(missRanger) # Imputación moderna y eficiente de valores faltantes
library(mlbench)   # Conjunto de datos de ejemplo (PimaIndiansDiabetes)
library(dplyr)     # Manipulación ágil de datos
library(caret)
library(dplyr)
# CONFIGURACIÓN INICIAL Y GESTIÓN DE CONFLICTOS
library(conflicted)   # 🛡️  Previene conflictos entre paquetes
library(rms)          # 📊  Estrategia de modelado (Steyerberg & Harrell)
library(Hmisc)        # 🔍  Herramientas estadísticas complementarias
library(pROC)         # 📈  Curvas ROC y métricas de discriminación
library(ggplot2)      # 🎨  Gráficos para publicación científica
library(missRanger)   # 🔄  Imputación múltiple con bosques aleatorios
library(mlbench)      # 💾  Conjuntos de datos de ejemplo
library(dplyr)        # 🛠️  Manipulación moderna de datos
library(caret)        # 🤖  Machine Learning y validación
# RESOLUCIÓN EXPLÍCITA DE CONFLICTOS CRÍTICOS
conflict_prefer("filter", "dplyr")
conflict_prefer("select", "dplyr")
conflict_prefer("summarise", "dplyr")
conflict_prefer("rename", "dplyr")
conflict_prefer("recode", "dplyr")
conflict_prefer("describe", "Hmisc")
conflict_prefer("rcorr", "Hmisc")
conflict_prefer("cut2", "Hmisc")
cat("✅ Todas las bibliotecas cargadas y conflictos resueltos\n")
# Manejo de datos
set.seed(123)   # Garantiza reproducibilidad en imputación y modelado
# CARGA Y PREPARACIÓN DE LOS DATOS
data("PimaIndiansDiabetes")
datos <- PimaIndiansDiabetes
# Variables predictoras clínicas de interés
vars_clinicas <- c("glucose", "pressure", "triceps", "insulin", "mass")
# PASO CRÍTICO: Limpieza e imputación
datos <- datos %>%
# En datos clínicos, el valor 0 suele ser biológicamente imposible → lo convertimos en NA
mutate(across(all_of(vars_clinicas), ~ ifelse(.x == 0, NA, .x))) %>%
# Imputamos los valores faltantes usando missRanger (basado en bosques aleatorios)
missRanger()
# CONFIGURACIÓN OBLIGATORIA PARA RMS
# datadist almacena resúmenes de las variables y permite que rms genere predicciones e interpretaciones automáticas
dd <- datadist(datos)
options(datadist = "dd")
blogdown:::serve_site()
#MODELO: PREDICTORES POR FISIOPATOLOGÍA, NO p-valores
modelo <- lrm(diabetes ~ rcs(glucose, 3) + rcs(mass, 3) + age + pregnant + pedigree,
data = datos,
x = TRUE,
y = TRUE)
# calibrate(): Bootstrap para evaluar y corregir la calibración
cal_boot <- calibrate(modelo, method = "boot", B = 200)
# GRÁFICOS
plot(cal_boot, main = "Probabilidades predichas vs observadas")
abline(0, 1, lty = 2, col = "red")
# validate(): Bootstrap para estimar el optimismo y corregir métricas de discriminación
val_boot <- validate(modelo, method = "boot", B = 200)
roc_obj <- roc(datos$diabetes, predict(modelo, type = "fitted"))
plot(roc_obj,
main = paste("AUC =", round(auc(roc_obj), 3)),
col = "blue",
legacy.axes = TRUE)
# NOMOGRAMA: EL TEST DE USABILIDAD CLÍNICA
nom <- nomogram(modelo, fun = plogis, funlabel = "Riesgo Diabetes")
plot(nom)
data(PimaIndiansDiabetes); datos <- PimaIndiansDiabetes
#Simular 100 splits simples y calcular AUC
auc_splits <- replicate(1009, {
trainIndex <- createDataPartition(datos$diabetes, p=0.7, list=FALSE)
train <- datos[trainIndex,]; test <- datos[-trainIndex,]
model <- glm(diabetes ~ glucose + mass + age, family=binomial, data=train)
pred <- predict(model, test, type="response")
roc(test$diabetes, pred)$auc
})
hist(auc_splits, main="Distribución de AUC en 100 splits simples", xlab="AUC")
sd(auc_splits)  # Desviación estándar alta
# validate(): Bootstrap para estimar el optimismo y corregir métricas de discriminación
# validate(): Bootstrap para estimar el optimismo
val_boot <- validate(modelo, method = "boot", B = 200)
# CORRECCIÓN: Especificar pROC:: y quiera paréntesis extra
roc_obj <- pROC::roc(datos$diabetes, predict(modelo, type = "fitted"))
plot(roc_obj,
main = paste("AUC =", round(pROC::auc(roc_obj), 3)),
col = "blue",
legacy.axes = TRUE)
data(PimaIndiansDiabetes); datos_sim <- PimaIndiansDiabetes
# Simular 100 splits simples (número razonable)
auc_splits <- replicate(100, {
trainIndex <- caret::createDataPartition(datos_sim$diabetes, p=0.7, list=FALSE)
train <- datos_sim[trainIndex,]; test <- datos_sim[-trainIndex,]
model <- glm(diabetes ~ glucose + mass + age, family=binomial, data=train)
pred <- predict(model, test, type="response")
pROC::roc(test$diabetes, pred)$auc  # Especificar pROC::
})
hist(auc_splits, main="Distribución de AUC en 100 splits simples", xlab="AUC")
cat("Desviación estándar:", sd(auc_splits), "\n")
blogdown::stop_server()
unlink("public", recursive = TRUE)  # Elimina la carpeta public
unlink("resources", recursive = TRUE)  # Elimina caché de recursos
blogdown::build_site(local = TRUE)  # Forzar reconstrucción completa
blogdown::build_site()
blogdown:::serve_site()
# calibrate(): Bootstrap para evaluar y corregir la calibración
cal_boot <- calibrate(modelo, method = "boot", B = 200)
# GRÁFICO CORREGIDO
plot(cal_boot,
main = "Curva de Calibración: Probabilidades Predichas vs Observadas",
sub = "Método Bootstrap (200 réplicas)",  # CORRECCIÓN: 'sub' no 'subt'
col = "darkblue",
lwd = 2)
# calibrate(): Bootstrap para evaluar y corregir la calibración
cal_boot <- calibrate(modelo, method = "boot", B = 200)
# GRÁFICO CORREGIDO
plot(cal_boot,
main = "Curva de Calibración: Probabilidades Predichas vs Observadas",
sub = "Método Bootstrap (200 réplicas)",  # CORRECCIÓN: 'sub' no 'subt'
col = "darkblue",
lwd = 2)
# Extraer datos de calibración
cal_data <- data.frame(
pred = cal_boot[,"predicted"],
obs = cal_boot[,"observed"],
lower = cal_boot[,"lower"],
upper = cal_boot[,"upper"]
)
# calibrate(): Bootstrap para evaluar y corregir la calibración
cal_boot <- calibrate(modelo, method = "boot", B = 200)
# GRÁFICO CORREGIDO - SIN PARÁMETRO 'sub'
plot(cal_boot,
main = "Curva de Calibración: Probabilidades Predichas vs Observadas\nMétodo Bootstrap (200 réplicas)",
col = "darkblue",
lwd = 2)
abline(0, 1, lty = 2, col = "red", lwd = 2)
legend("topleft",
legend = c("Calibración observada", "Calibración perfecta"),
col = c("darkblue", "red"),
lty = c(1, 2),
lwd = 2,
bty = "n")
# calibrate(): Bootstrap para evaluar y corregir la calibración
cal_boot <- calibrate(modelo, method = "boot", B = 200)
# GRÁFICO CORREGIDO - SIN PARÁMETRO 'sub'
plot(cal_boot,
main = "Curva de Calibración: Probabilidades Predichas vs Observadas\nMétodo Bootstrap (200 réplicas)",
col = "darkblue",
lwd = 2)
abline(0, 1, lty = 2, col = "red", lwd = 2)
legend("topleft",
legend = c("Calibración observada", "Calibración perfecta"),
col = c("darkblue", "red"),
lty = c(1, 2),
lwd = 2,
bty = "n")
# calibrate(): Bootstrap para evaluar y corregir la calibración
cal_boot <- calibrate(modelo, method = "boot", B = 200)
# GRÁFICO CORREGIDO - SIN PARÁMETRO 'sub'
plot(cal_boot,
main = "Probabilidades Predichas vs Observadas\nMétodo Bootstrap (200 réplicas)",
col = "darkblue",
lwd = 2)
abline(0, 1, lty = 2, col = "red", lwd = 2)
legend("topleft",
legend = c("Calibración observada", "Calibración perfecta"),
col = c("darkblue", "red"),
lty = c(1, 2),
lwd = 2,
bty = "n")
# validate(): Bootstrap para estimar el optimismo y corregir métricas de discriminación
# validate(): Bootstrap para estimar el optimismo
val_boot <- validate(modelo, method = "boot", B = 200)
# CORRECCIÓN: Especificar pROC:: y quiera paréntesis extra
roc_obj <- pROC::roc(datos$diabetes, predict(modelo, type = "fitted"))
plot(roc_obj,
main = paste("AUC =", round(pROC::auc(roc_obj), 3)),
col = "blue",
legacy.axes = TRUE)
# NOMOGRAMA CON MEJOR VISUALIZACIÓN
nom <- nomogram(modelo,
fun = plogis,
funlabel = "Riesgo de Diabetes",
lp = FALSE,
col.grid = gray(c(0.8, 0.95)))
nom <- nomogram(modelo,
fun = plogis,
funlabel = "Riesgo de Diabetes",
lp = FALSE,
col.grid = gray(c(0.8, 0.95)))
# NOMOGRAMA CON MEJOR VISUALIZACIÓN
nom <- nomogram(modelo,
fun = plogis,
funlabel = "Riesgo de Diabetes",
lp = FALSE)
plot(nom,
main = "Nomograma para Predicción de Diabetes",
cex.axis = 0.8,
lmgp = 0.3)
knitr::opts_chunk$set(
echo = TRUE,
message = FALSE,
warning = FALSE,
fig.width = 8,
fig.height = 6,
fig.align = 'center',
fig.path = "figures/",  # Ruta específica para figuras
dev = 'png',           # Formato de salida
dpi = 150              # Resolución adecuada para web
)
# Bibliotecas esenciales
library(conflicted)  # Evita conflictos entre funciones de distintos paquetes
library(rms)     # El núcleo de la estrategia de modelado (Steyerberg & Harrell)
library(pROC)    # Para curvas ROC y estadísticas de discriminación
library(ggplot2)# Gráficos listos para publicación
library(missRanger) # Imputación moderna y eficiente de valores faltantes
library(mlbench)   # Conjunto de datos de ejemplo (PimaIndiansDiabetes)
library(dplyr)     # Manipulación ágil de datos
library(caret)
library(dplyr)
set.seed(123)   # Garantiza reproducibilidad en imputación y modelado
# CARGA Y PREPARACIÓN DE LOS DATOS
data("PimaIndiansDiabetes")
datos <- PimaIndiansDiabetes
# Variables predictoras clínicas de interés
vars_clinicas <- c("glucose", "pressure", "triceps", "insulin", "mass")
# PASO CRÍTICO: Limpieza e imputación
datos <- datos %>%
# En datos clínicos, el valor 0 suele ser biológicamente imposible → lo convertimos en NA
mutate(across(all_of(vars_clinicas), ~ ifelse(.x == 0, NA, .x))) %>%
# Imputamos los valores faltantes usando missRanger (basado en bosques aleatorios)
missRanger()
# CONFIGURACIÓN OBLIGATORIA PARA RMS
# datadist almacena resúmenes de las variables y permite que rms genere predicciones e interpretaciones automáticas
dd <- datadist(datos)
options(datadist = "dd")
modelo <- lrm(diabetes ~ rcs(glucose, 3) + rcs(mass, 3) + age + pregnant + pedigree,
data = datos,
x = TRUE,
y = TRUE)
# calibrate(): Bootstrap para evaluar y corregir la calibración
cal_boot <- calibrate(modelo, method = "boot", B = 200)
# GRÁFICOS
plot(cal_boot, main = "Probabilidasde predichas vs observadas")
abline(0, 1, lty = 2, col = "red")
# validate(): Bootstrap para estimar el optimismo y corregir métricas de discriminación
val_boot <- validate(modelo, method = "boot", B = 200)
roc_obj <- roc(datos$diabetes, predict(modelo, type = "fitted"))
plot(roc_obj,
main = paste("AUC =", round(auc(roc_obj), 3)),
col = "blue",
legacy.axes = TRUE)
nom <- nomogram(modelo, fun = plogis, funlabel = "Riesgo Diabetes")
plot(nom)
data(PimaIndiansDiabetes); datos <- PimaIndiansDiabetes
#Simular 100 splits simples y calcular AUC
auc_splits <- replicate(100, {
trainIndex <- createDataPartition(datos$diabetes, p=0.7, list=FALSE)
train <- datos[trainIndex,]; test <- datos[-trainIndex,]
model <- glm(diabetes ~ glucose + mass + age, family=binomial, data=train)
pred <- predict(model, test, type="response")
roc(test$diabetes, pred)$auc
})
hist(auc_splits, main="Distribución de AUC en 100 splits simples", xlab="AUC")
knitr::opts_chunk$set(
echo = TRUE,          # Muestra el código (ideal para blog educativo)
message = FALSE,      # Oculta mensajes de paquetes
warning = FALSE,      # Oculta warnings (datos limpios)
collapse = TRUE,      # Une código y salida
fig.width = 8,        # Ancho estándar
fig.height = 6,       # Alto estándar
fig.align = 'center', # Centrado en web
out.width = '80%',    # Responsive en HTML
fig.path = "figures/",# Carpeta específica (blogdown la crea auto)
dev = 'png',          # Formato ligero para web
dpi = 150,            # Resolución buena sin archivos pesados
cache = FALSE         # Sin cache para demos rápidas (activa si necesitas)
)
Si está leyendo esta publicación, es probable que le interese desarrollar **modelos de predicción clínica** para **diagnosticar** o **pronosticar** enfermedades en pacientes. Seguramente sea investigador o estudiante de posgrado —en maestría o doctorado— en ciencias biomédicas, y busque cómo **desarrollar** y **validar** esos modelos en un **artículo científico** o **tesis**.
knitr::opts_chunk$set(
echo = TRUE,          # Muestra el código (ideal para blog educativo)
message = FALSE,      # Oculta mensajes de paquetes
warning = FALSE,      # Oculta warnings (datos limpios)
collapse = TRUE,      # Une código y salida
fig.width = 8,        # Ancho estándar
fig.height = 6,       # Alto estándar
fig.align = 'center', # Centrado en web
out.width = '80%',    # Responsive en HTML
fig.path = "figures/",# Carpeta específica (blogdown la crea auto)
dev = 'png',          # Formato ligero para web
dpi = 150,            # Resolución buena sin archivos pesados
cache = FALSE         # Sin cache para demos rápidas (activa si necesitas)
)
knitr::opts_chunk$set(
echo = TRUE,          # Muestra el código (ideal para blog educativo)
message = FALSE,      # Oculta mensajes de paquetes
warning = FALSE,      # Oculta warnings (datos limpios)
collapse = TRUE,      # Une código y salida
fig.width = 8,        # Ancho estándar
fig.height = 6,       # Alto estándar
fig.align = 'center', # Centrado en web
out.width = '80%',    # Responsive en HTML
dev = 'png',          # Formato ligero para web
dpi = 150,            # Resolución buena sin archivos pesados
cache = FALSE         # Sin cache para demos rápidas (activa si necesitas)
)
library(conflicted)   # Detecta y resuelve conflictos de funciones
library(rms)          # Modelado logístico restringido (lrm) y splines (rcs)
library(pROC)         # Curvas ROC y AUC
library(ggplot2)      # Gráficos pulidos (usado por rms internamente)
library(missRanger)   # Imputación iterativa con random forests
library(mlbench)      # Dataset de ejemplo: PimaIndiansDiabetes
library(dplyr)        # Manipulación de datos (pipe %>%)
library(caret)        # Particiones de datos (createDataPartition)
set.seed(123)  # Reproducibilidad total (imputación, splits, bootstrap)
# Carga del dataset nativo
data("PimaIndiansDiabetes")
datos <- PimaIndiansDiabetes
# Variables clínicas con 0s imposibles (biológicamente)
vars_clinicas <- c("glucose", "pressure", "triceps", "insulin", "mass")
# Limpieza: 0 → NA, luego imputación
datos <- datos %>%
mutate(across(all_of(vars_clinicas), ~ ifelse(.x == 0, NA, .x))) %>%
missRanger()  # Imputa NA con random forests iterativos
# Configuración rms: datadist para predicciones automáticas
dd <- datadist(as.data.frame(datos))
options(datadist = "dd")
cal_boot <- calibrate(modelo, method = "boot", B = 100)
plot(cal_boot, main = "Calibración: Predichas vs Observadas")
abline(0, 1, lty = 2, col = "red")  # Línea ideal
val_boot <- validate(modelo, method = "boot", B = 100)
roc_obj <- roc(datos$diabetes, predict(modelo, type = "fitted"))
plot(roc_obj,
main = paste("Curva ROC - AUC =", round(auc(roc_obj), 3)),
col = "blue",
legacy.axes = TRUE)
nom <- nomogram(modelo, fun = plogis, funlabel = "Riesgo de Diabetes")
plot(nom, main = "Nomograma del Modelo")
auc_splits <- replicate(100, {
trainIndex <- createDataPartition(datos$diabetes, p = 0.7, list = FALSE)
train <- datos[trainIndex, ]; test <- datos[-trainIndex, ]
model_simple <- glm(diabetes ~ glucose + mass + age, family = binomial, data = train)
pred <- predict(model_simple, test, type = "response")
roc(test$diabetes, pred)$auc
})
hist(auc_splits,
main = "Distribución de AUC en 100 Splits Simples",
xlab = "AUC",
col = "lightgray",
border = "black")
blogdown:::serve_site()
knitr::opts_chunk$set(
echo = TRUE,          # Muestra el código (ideal para blog educativo)
message = FALSE,      # Oculta mensajes de paquetes
warning = FALSE,      # Oculta warnings (datos limpios)
collapse = TRUE,      # Une código y salida
fig.width = 8,        # Ancho estándar
fig.height = 6,       # Alto estándar
fig.align = 'center', # Centrado en web
out.width = '80%',    # Responsive en HTML
dev = 'png',          # Formato ligero para web
dpi = 150,            # Resolución buena sin archivos pesados
cache = FALSE         # Sin cache para demos rápidas (activa si necesitas)
)
library(conflicted)   # Detecta y resuelve conflictos de funciones
library(rms)          # Modelado logístico restringido (lrm) y splines (rcs)
library(pROC)         # Curvas ROC y AUC
library(ggplot2)      # Gráficos pulidos (usado por rms internamente)
library(missRanger)   # Imputación iterativa con random forests
library(mlbench)      # Dataset de ejemplo: PimaIndiansDiabetes
library(dplyr)        # Manipulación de datos (pipe %>%)
library(caret)        # Particiones de datos (createDataPartition)
set.seed(123)  # Reproducibilidad total (imputación, splits, bootstrap)
# Carga del dataset nativo
data("PimaIndiansDiabetes")
datos <- PimaIndiansDiabetes
# Variables clínicas con 0s imposibles (biológicamente)
vars_clinicas <- c("glucose", "pressure", "triceps", "insulin", "mass")
# Limpieza: 0 → NA, luego imputación
datos <- datos %>%
mutate(across(all_of(vars_clinicas), ~ ifelse(.x == 0, NA, .x))) %>%
missRanger()  # Imputa NA con random forests iterativos
# Configuración rms: datadist para predicciones automáticas
dd <- datadist(as.data.frame(datos))
options(datadist = "dd")
modelo <- lrm(
diabetes ~ rcs(glucose, 3) + rcs(mass, 3) + rcs(age, 3) + rcs(pedigree, 3) + pregnant,
data = datos,
x = TRUE,  # Guarda diseño para bootstrap
y = TRUE   # Guarda respuesta para bootstrap
)
cal_boot <- calibrate(modelo, method = "boot", B = 100)
plot(cal_boot, main = "Calibración: Predichas vs Observadas")
abline(0, 1, lty = 2, col = "red")  # Línea ideal
val_boot <- validate(modelo, method = "boot", B = 100)
roc_obj <- roc(datos$diabetes, predict(modelo, type = "fitted"))
plot(roc_obj,
main = paste("Curva ROC - AUC =", round(auc(roc_obj), 3)),
col = "blue",
legacy.axes = TRUE)
nom <- nomogram(modelo, fun = plogis, funlabel = "Riesgo de Diabetes")
plot(nom, main = "Nomograma del Modelo")
auc_splits <- replicate(100, {
trainIndex <- createDataPartition(datos$diabetes, p = 0.7, list = FALSE)
train <- datos[trainIndex, ]; test <- datos[-trainIndex, ]
model_simple <- glm(diabetes ~ glucose + mass + age, family = binomial, data = train)
pred <- predict(model_simple, test, type = "response")
roc(test$diabetes, pred)$auc
})
hist(auc_splits,
main = "Distribución de AUC en 100 Splits Simples",
xlab = "AUC",
col = "lightgray",
border = "black")
library(conflicted)   # Detecta y resuelve conflictos de funciones
library(rms)          # Modelado logístico restringido (lrm) y splines (rcs)
library(pROC)         # Curvas ROC y AUC
library(ggplot2)      # Gráficos pulidos (usado por rms internamente)
library(missRanger)   # Imputación iterativa con random forests
library(mlbench)      # Dataset de ejemplo: PimaIndiansDiabetes
library(dplyr)        # Manipulación de datos (pipe %>%)
library(caret)        # Particiones de datos (createDataPartition)
blogdown::build_site()
blogdown:::stop_server()
blogdown:::stop_server()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown::build_site()
blogdown::serve_site()
blogdown:::stop_server()
blogdown::serve_site()
blogdown::stop_server()
blogdown::build_site()
blogdown::serve_site()
blogdown::stop_server()
blogdown::serve_site()
blogdown::serve_site()
blogdown::stop_server()
blogdown::serve_site()
blogdown::serve_site()
blogdown::stop_server()
blogdown::build_site()
blogdown::serve_site()
blogdown::build_site()
blogdown::serve_site()
blogdown::stop_server()
blogdown::serve_site()
blogdown::serve_site()
blogdown::stop_server()
blogdown::build_site()
blogdown::serve_site()
blogdown::build_site(local = FALSE)
blogdown:::check_site()  # Verifica errores.
blogdown::build_site(local = FALSE, build_rmd = TRUE)
blogdown:::check_site()  # Verifica errores.
blogdown:::stop_server() # Detiene el servidor.
blogdown:::serve_site()  # Sirve localmente para preview.
blogdown:::stop_server() # Detiene el servidor.
blogdown:::serve_site()  # Sirve localmente para preview.
blogdown:::serve_site()  # Sirve localmente para preview.
blogdown:::stop_server() # Detiene el servidor.
blogdown:::serve_site()  # Sirve localmente para preview.
blogdown::stop_server()
blogdown::serve_site()
blogdown::stop_server()
blogdown::serve_site()
blogdown::stop_server()
blogdown::stop_server()
unlink("public", recursive = TRUE)   # Borrar carpeta public
blogdown::build_site(local = FALSE)
blogdown::stop_server()
blogdown::build_site()
blogdown::serve_site()
blogdown:::check_site()  # Verifica errores.
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::stop_server()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::stop_server()
