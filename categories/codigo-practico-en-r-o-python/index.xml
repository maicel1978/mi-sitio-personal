<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>C√≥digo Pr√°ctico en R O Python | Bioestad√≠stica edu</title><link>https://bioestadisticaedu.com/categories/codigo-practico-en-r-o-python/</link><atom:link href="https://bioestadisticaedu.com/categories/codigo-practico-en-r-o-python/index.xml" rel="self" type="application/rss+xml"/><description>C√≥digo Pr√°ctico en R O Python</description><generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>es-es</language><lastBuildDate>Wed, 22 Oct 2025 00:00:00 +0000</lastBuildDate><image><url>https://bioestadisticaedu.com/media/icon_hu_551fbaee136b383e.png</url><title>C√≥digo Pr√°ctico en R O Python</title><link>https://bioestadisticaedu.com/categories/codigo-practico-en-r-o-python/</link></image><item><title>C√≥mo Entrenar y Validar Modelos de Predicci√≥n Cl√≠nica: Gu√≠a Paso a Paso para Profesionales de la Salud</title><link>https://bioestadisticaedu.com/post/como-entrenar-y-validar-un-modelo-de-machine-learning/</link><pubDate>Wed, 22 Oct 2025 00:00:00 +0000</pubDate><guid>https://bioestadisticaedu.com/post/como-entrenar-y-validar-un-modelo-de-machine-learning/</guid><description>&lt;p>üéß &lt;strong>Escucha el podcast de esta publicaci√≥n&lt;/strong>&lt;/p>
&lt;audio controls >
&lt;source src="https://ia600607.us.archive.org/24/items/articulo-steyember/_Articulo_Steyember.mp3" type="audio/mpeg">
&lt;/audio>
&lt;p>Si est√° leyendo esta publicaci√≥n, es probable que le interese desarrollar &lt;strong>modelos de predicci√≥n cl√≠nica&lt;/strong> para &lt;strong>diagnosticar&lt;/strong> o &lt;strong>pronosticar&lt;/strong> enfermedades en pacientes. Seguramente sea investigador o estudiante de posgrado ‚Äîen maestr√≠a o doctorado‚Äî en ciencias biom√©dicas, y busque c√≥mo &lt;strong>desarrollar&lt;/strong> y &lt;strong>validar&lt;/strong> esos modelos en un &lt;strong>art√≠culo cient√≠fico&lt;/strong> o &lt;strong>tesis&lt;/strong>.&lt;/p>
&lt;p>Casi seguro ha llegado a esa fase en la que la metodolog√≠a se siente como un muro de ladrillos: no sabe &lt;strong>qu√© pasos seguir&lt;/strong>, &lt;strong>qu√© software usar&lt;/strong>, si lo que necesita se puede hacer en &lt;strong>SPSS&lt;/strong> o si tendr√° que meterse con esos &lt;strong>c√≥digos&lt;/strong> inquietantes de &lt;strong>R o Python&lt;/strong> ‚Äîy encima no tiene experiencia en programaci√≥n. Y, lo peor de todo: le asalta la duda de si su modelo servir√° para algo m√°s all√° de llenar un repositorio de tesis‚Ä¶ o si siquiera &lt;strong>ser√° √∫til&lt;/strong> para los propios pacientes de su &lt;strong>muestra&lt;/strong>, sin hablar de otros &lt;strong>contextos cl√≠nicos&lt;/strong>.&lt;/p>
&lt;p>Seamos francos: en el fondo, todos le huimos a ese comentario punzante que nos estalla la burbuja predictiva de un solo golpe:&lt;/p>
&lt;blockquote>
&lt;p>¬°Vaya!, un √°rea bajo la curva de ensue√±o, sin rastros de calibraci√≥n ni validaci√≥n externa‚Ä¶ probablemente fruto de una receta cl√°sica: exceso de predictores, dicotomizaci√≥n entusiasta, escasez de eventos y una pizca de selecci√≥n autom√°tica. TRIPOD lo llamar√≠a ‚Äòoptimismo aparente‚Äô; nosotros, la receta del sobreajuste gourmet ‚Äîcon un cigarro y un gui√±o para rematar.&lt;/p>&lt;/blockquote>
&lt;div class="flex px-4 py-3 mb-6 rounded-md bg-primary-100 dark:bg-primary-900">
&lt;span class="pr-3 pt-1 text-primary-600 dark:text-primary-300">
&lt;svg height="24" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">&lt;path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z"/>&lt;/svg>
&lt;/span>
&lt;span class="dark:text-neutral-300">El &lt;strong>sobreajuste&lt;/strong> ocurre cuando un modelo aprende tan bien los datos de entrenamiento (incluyendo ruido o detalles irrelevantes) que su rendimiento en datos nuevos es mucho peor.&lt;/span>
&lt;/div>
&lt;p>En otras palabras, el modelo &lt;strong>funciona&lt;/strong> espectacularmente bien‚Ä¶ pero &lt;strong>solo con su muestra&lt;/strong> de pacientes. &lt;em>¬°Las m√©tricas de desempe√±o en otros conjuntos de datos son un desastre!&lt;/em> M√°s adelante retomaremos esa idea.&lt;/p>
&lt;p>Mientras las tesis de alto nivel se centran en construir modelos de predicci√≥n cl√≠nica con &lt;strong>t√©cnicas estad√≠sticas&lt;/strong> cl√°sicas o sofisticados &lt;strong>algoritmos de aprendizaje autom√°tico&lt;/strong> como los bosques aleatorios, los cursos de bioestad√≠stica &lt;em>‚Äî¬°incluso en programas de estudio de esta especialidad!‚Äî&lt;/em> apenas rozan el asunto. La &lt;strong>brecha es real&lt;/strong>, y con ella viene la ansiedad de tener que aprenderlo todo ya.&lt;/p>
&lt;p>Pero respire hondo. Este post puede endurecer su burbuja predictiva con una capa extra de titanio: su traductor metodol√≥gico no oficial, (casi) libre de l√°grimas y cargado de herramientas pr√°cticas. Yo mismo navegu√© ese infierno metodol√≥gico en mi &lt;strong>proceso doctoral&lt;/strong>, as√≠ que no solo le ofrezco &lt;strong>consejos gen√©ricos&lt;/strong>: comparto las lecciones de alguien que ya se quem√≥ las pesta√±as por usted, para que avance con &lt;strong>confianza&lt;/strong> y &lt;strong>evite&lt;/strong> los mismos &lt;strong>tropiezos&lt;/strong>.&lt;/p>
&lt;p>Olv√≠dese del c√≥digo complejo y enrevesado. Aqu√≠ nos enfocamos en la &lt;strong>l√≥gica esencial&lt;/strong> para construir un &lt;strong>modelo predictivo fiable&lt;/strong>. Desglosaremos el &lt;strong>proceso paso a paso&lt;/strong>, quit√°ndole el miedo al procesamiento de datos con ejemplos de &lt;strong>c√≥digo pr√°ctico en R&lt;/strong>.&lt;/p>
&lt;p>Si bien este post se centra en las cuestiones pr√°cticas del &lt;strong>procesamiento de datos&lt;/strong>, es importante destacar que la elecci√≥n del dise√±o de la investigaci√≥n est√° determinada por el &lt;strong>objetivo del estudio&lt;/strong> de predicci√≥n, el cual seg√∫n &lt;em>TRIPOD (Transparent Reporting of a multivariable prediction model for Individual Prognosis Or Diagnosis)&lt;/em> se &lt;strong>clasifica&lt;/strong> en tres &lt;strong>categor√≠as fundamentales&lt;/strong> (1):&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Desarrollo&lt;/strong> de un nuevo modelo&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Validaci√≥n&lt;/strong> de un modelo existente&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Actualizaci√≥n&lt;/strong> de un modelo&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Seg√∫n el &lt;strong>objetivo de la investigaci√≥n&lt;/strong> se pueden optar por uno de los siguientes &lt;strong>dise√±os&lt;/strong> de estudios:&lt;/p>
&lt;details class="spoiler " id="spoiler-2">
&lt;summary class="cursor-pointer">Desarrollo, Validaci√≥n o Actualizaci√≥n de Modelos (Click para ver detalles)&lt;/summary>
&lt;div class="rounded-lg bg-neutral-50 dark:bg-neutral-800 p-2">
&lt;ul>
&lt;li>Dise√±os seg√∫n Objetivo
&lt;ul>
&lt;li>Desarrollo de Modelos
&lt;ul>
&lt;li>Estudios de Cohorte&lt;/li>
&lt;li>Ensayos Aleatorizados&lt;/li>
&lt;li>Datos de Atenci√≥n Rutinaria&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Validaci√≥n de Modelos
&lt;ul>
&lt;li>Estudios de Cohorte Independientes&lt;/li>
&lt;li>Meta-an√°lisis&lt;/li>
&lt;li>Datos de Registro&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Actualizaci√≥n de Modelos
&lt;ul>
&lt;li>Cualquier dise√±o anterior con nuevos datos&lt;/li>
&lt;li>Datos con Estructura de Cl√∫ster&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/details>
&lt;p>Se recomienda profundizar en estos temas a partir de la bibliograf√≠a propuesta para esta publicaci√≥n. En este post nos centraremos en la &lt;strong>secuencia de etapas clave&lt;/strong> para desarrollar un &lt;strong>modelo predictivo&lt;/strong>. Como base usar√© el art√≠culo &lt;em>‚ÄúSiete pasos para el desarrollo y un ABCD para la validaci√≥n‚Äù&lt;/em> de Ewout Steyerberg‚ÄØ(1), as√≠ como su libro &lt;em>Clinical Prediction Models&lt;/em>‚ÄØ(2). A la receta a√±adir√© las recomendaciones de Frank Harrell desde su obra &lt;em>Regression Modeling Strategies&lt;/em>‚ÄØ(3), y nos basaremos en su biblioteca &lt;strong>rms&lt;/strong> para desarrollar este tutorial con &lt;strong>c√≥digo pr√°ctico en R&lt;/strong>. Finalmente dar√© mi propia visi√≥n del pol√©mico asunto de particionar los datos en &lt;strong>conjunto de entrenamiento&lt;/strong> y &lt;strong>conjunto de prueba&lt;/strong> en una &lt;strong>proporci√≥n 70:30&lt;/strong> y otras cuestiones que seguramente resultar√°n interesantes.&lt;/p>
&lt;p>Empezaremos con la &lt;strong>estrategia de modelado&lt;/strong>; el tutorial con todo el c√≥digo vendr√° despu√©s.&lt;br>
&lt;strong>¬°Empecemos!&lt;/strong>&lt;/p>
&lt;h2 id="estrategia-de-modelado">Estrategia de modelado&lt;/h2>
&lt;p>Seguir una &lt;strong>estrategia de modelado&lt;/strong> adecuada es esencial para &lt;strong>desarrollar y validar modelos de predicci√≥n&lt;/strong>: no solo &lt;strong>mitiga el sesgo&lt;/strong> y el &lt;strong>sobreajuste&lt;/strong>, sino que nos &lt;strong>orienta&lt;/strong> en un proceso que, de otro modo, puede volverse ca√≥tico.&lt;/p>
&lt;p>A continuaci√≥n, se muestran un conjunto de &lt;strong>bibliotecas en R&lt;/strong> que nos ayudar√° implementar estas ideas, pero este proceso se puede realizar de igual manera en en SPSS o Python &lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>&lt;a href="https://cran.r-project.org/web/packages/rms/index.html" target="_blank" rel="noopener">Puedes descargar e instalar el paquete &lt;strong>rms&lt;/strong> desde su p√°gina oficial en el repositorio de CRAN.&lt;/a>
Tambien le har√°n falta otras bibliotecas para el manejo de datos, confeccionar tablas y gr√°ficos para su publicaci√≥n, entre otras acciones.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-r" data-lang="r">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">library&lt;/span>(conflicted) &lt;span style="color:#75715e"># Detecta y resuelve conflictos de funciones&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">library&lt;/span>(rms) &lt;span style="color:#75715e"># Modelado log√≠stico restringido (lrm) y splines (rcs)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">library&lt;/span>(pROC) &lt;span style="color:#75715e"># Curvas ROC y AUC&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">library&lt;/span>(ggplot2) &lt;span style="color:#75715e"># Gr√°ficos pulidos (usado por rms internamente)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">library&lt;/span>(missRanger) &lt;span style="color:#75715e"># Imputaci√≥n iterativa con random forests&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">library&lt;/span>(mlbench) &lt;span style="color:#75715e"># Dataset de ejemplo: PimaIndiansDiabetes&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">library&lt;/span>(dplyr) &lt;span style="color:#75715e"># Manipulaci√≥n de datos (pipe %&amp;gt;%)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">library&lt;/span>(caret) &lt;span style="color:#75715e"># Particiones de datos (createDataPartition)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="1-definici√≥n-del-problema-e-inspecci√≥n-de-datos">1. Definici√≥n del problema e inspecci√≥n de datos&lt;/h3>
&lt;p>El primer paso en cualquier proyecto de modelado es &lt;strong>definir claramente el problema de investigaci√≥n&lt;/strong> y seleccionar la &lt;strong>variable de resultado&lt;/strong> adecuada.&lt;/p>
&lt;div class="flex px-4 py-3 mb-6 rounded-md bg-primary-100 dark:bg-primary-900">
&lt;span class="pr-3 pt-1 text-primary-600 dark:text-primary-300">
&lt;svg height="24" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">&lt;path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z"/>&lt;/svg>
&lt;/span>
&lt;span class="dark:text-neutral-300">La &lt;strong>variable de resultado&lt;/strong> debe definirse con precisi√≥n: especifique &lt;strong>qu√© evento se predice&lt;/strong>, &lt;strong>c√≥mo y cu√°ndo se mide&lt;/strong>, y el &lt;strong>horizonte temporal de predicci√≥n&lt;/strong> (por ejemplo, mortalidad a los 30 d√≠as). Tambi√©n es clave indicar el m√©todo de evaluaci√≥n del evento y si se aplic√≥ &lt;strong>cegamiento&lt;/strong> respecto a los predictores, para asegurar coherencia interna y validez del modelo.&lt;/span>
&lt;/div>
&lt;p>Durante esta fase tambi√©n realizamos un &lt;em>an√°lisis exploratorio de datos (EDA, por sus siglas en ingles)&lt;/em> para entender las caracter√≠sticas de las variables y detectar posibles problemas, como &lt;strong>datos at√≠picos&lt;/strong> o &lt;strong>valores faltantes&lt;/strong>.&lt;/p>
&lt;p>&lt;a href="https://bioestadisticaedu.com/post/eda/">Para conocer m√°s detalles, ver mi post sobre EDA&lt;/a>.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-r" data-lang="r">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">set.seed&lt;/span>(&lt;span style="color:#ae81ff">123&lt;/span>) &lt;span style="color:#75715e"># Reproducibilidad total (imputaci√≥n, splits, bootstrap)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Carga del dataset nativo&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">data&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;PimaIndiansDiabetes&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>datos &lt;span style="color:#f92672">&amp;lt;-&lt;/span> PimaIndiansDiabetes
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Variables cl√≠nicas con 0s imposibles (biol√≥gicamente)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>vars_clinicas &lt;span style="color:#f92672">&amp;lt;-&lt;/span> &lt;span style="color:#a6e22e">c&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;glucose&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;pressure&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;triceps&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;insulin&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;mass&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Limpieza: 0 ‚Üí NA, luego imputaci√≥n&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>datos &lt;span style="color:#f92672">&amp;lt;-&lt;/span> datos &lt;span style="color:#f92672">%&amp;gt;%&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">mutate&lt;/span>(&lt;span style="color:#a6e22e">across&lt;/span>(&lt;span style="color:#a6e22e">all_of&lt;/span>(vars_clinicas), &lt;span style="color:#f92672">~&lt;/span> &lt;span style="color:#a6e22e">ifelse&lt;/span>(.x &lt;span style="color:#f92672">==&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#66d9ef">NA&lt;/span>, .x))) &lt;span style="color:#f92672">%&amp;gt;%&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">missRanger&lt;/span>() &lt;span style="color:#75715e"># Imputa NA con random forests iterativos&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># nota: idealmente, si se usara una divisi√≥n simple, la imputaci√≥n deber√≠a hacerse solo en el conjunto de entrenamiento.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Configuraci√≥n rms: datadist para predicciones autom√°ticas&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>dd &lt;span style="color:#f92672">&amp;lt;-&lt;/span> &lt;span style="color:#a6e22e">datadist&lt;/span>(&lt;span style="color:#a6e22e">as.data.frame&lt;/span>(datos))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">options&lt;/span>(datadist &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;dd&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="2-codificaci√≥n-de-las-variables-predictoras">2. Codificaci√≥n de las variables predictoras&lt;/h3>
&lt;p>La &lt;strong>codificaci√≥n adecuada de las variables predictoras&lt;/strong> es fundamental para construir &lt;strong>modelos robustos&lt;/strong>.&lt;/p>
&lt;p>Es probable que necesites &lt;strong>agrupar categor√≠as poco frecuentes&lt;/strong> o crear &lt;strong>predictores resumen&lt;/strong> para condensar informaci√≥n redundante o altamente correlacionada. Y si tu modelo se basa en &lt;strong>regresi√≥n log√≠stica&lt;/strong>, no asumas linealidad de entrada: muchas veces es necesario aplicar &lt;strong>splines c√∫bicos restringidos&lt;/strong> para relajar el &lt;strong>supuesto de linealidad&lt;/strong> entre los predictores y el resultado.&lt;/p>
&lt;p>üí° &lt;strong>Tip para la publicaci√≥n:&lt;/strong> Reporta cada predictor con su &lt;em>m√©todo de medici√≥n&lt;/em>, &lt;em>momento&lt;/em> de registro y &lt;em>unidades&lt;/em> (si es continuo). Si categorizas, &lt;em>justifica los puntos de corte&lt;/em>. Si es categ√≥rico, muestra todas las categor√≠as y la de referencia. El modelo final debe reflejar &lt;em>exactamente&lt;/em> la &lt;em>codificaci√≥n&lt;/em> usada.&lt;/p>
&lt;div class="flex px-4 py-3 mb-6 rounded-md bg-yellow-100 dark:bg-yellow-900">
&lt;span class="pr-3 pt-1 text-red-400">
&lt;svg height="24" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">&lt;path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="M12 9v3.75m-9.303 3.376c-.866 1.5.217 3.374 1.948 3.374h14.71c1.73 0 2.813-1.874 1.948-3.374L13.949 3.378c-.866-1.5-3.032-1.5-3.898 0zM12 15.75h.007v.008H12z"/>&lt;/svg>
&lt;/span>
&lt;span class="dark:text-neutral-300">&lt;strong>Alerta:&lt;/strong> Dicotomizar predictores cuantitativos ‚Äîpor ejemplo, convertir una variable continua como la edad o la presi√≥n arterial en una binaria (‚Äú‚â•65 a√±os = 1‚Äù, ‚Äú&amp;lt;65 = 0‚Äù)‚Äî es una mala pr√°ctica ampliamente desaconsejada. Esta estrategia desperdicia informaci√≥n, reduce el poder estad√≠stico, introduce puntos de corte arbitrarios y aumenta el riesgo de sobreajuste. En lugar de categorizar, modela la relaci√≥n continua (por ejemplo, con splines) para preservar la se√±al cl√≠nica real.&lt;/span>
&lt;/div>
&lt;h3 id="3-especificaci√≥n-del-tipo-de-modelo">3 .Especificaci√≥n del tipo de modelo&lt;/h3>
&lt;p>En esta etapa se define la &lt;strong>estructura formal del modelo&lt;/strong>, lo que incluye el tipo de relaci√≥n entre variables (p. ej., lineal, no lineal) y, de manera crucial, la &lt;strong>selecci√≥n de los predictores&lt;/strong> finales que lo integrar√°n.&lt;/p>
&lt;div class="flex px-4 py-3 mb-6 rounded-md bg-yellow-100 dark:bg-yellow-900">
&lt;span class="pr-3 pt-1 text-red-400">
&lt;svg height="24" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">&lt;path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="M12 9v3.75m-9.303 3.376c-.866 1.5.217 3.374 1.948 3.374h14.71c1.73 0 2.813-1.874 1.948-3.374L13.949 3.378c-.866-1.5-3.032-1.5-3.898 0zM12 15.75h.007v.008H12z"/>&lt;/svg>
&lt;/span>
&lt;span class="dark:text-neutral-300">&lt;strong>Alerta:&lt;/strong> La elecci√≥n de predictores no debe basarse en la aplicaci√≥n mec√°nica de m√©todos algor√≠tmicos como la Regresi√≥n Paso a Paso (RPP), ya que suelen producir modelos inestables y sobreajustados, especialmente en contextos biom√©dicos y sociales.&lt;/span>
&lt;/div>
&lt;p>En lugar de la preselecci√≥n de variables basada √∫nicamente en valores &lt;em>p&lt;/em> de an√°lisis bivariados, se recomienda:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Priorizar el &lt;strong>juicio cl√≠nico, la revisi√≥n sistem√°tica de la literatura y la experiencia previa.&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Optar por un conjunto reducido de predictores cl√≠nicamente relevantes definidos a priori, o incluir todos los candidatos en el modelo multivariable inicial sin filtrado estad√≠stico previo.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Existen algoritmos que tienen enfoques alternativos a la selecci√≥n autom√°tica de predictores como la regresi√≥n Lasso o los √°rboles de clasificaci√≥n. En la gu√≠a propuesta por Heinze se puede profundizar sobre este tema (5)&lt;/p>
&lt;h3 id="4-estimaci√≥n-del-modelo">4. Estimaci√≥n del Modelo&lt;/h3>
&lt;p>Una vez especificado el modelo (es decir, definidos los predictores y la estructura funcional), el siguiente paso tiene como objetivo calcular los coeficientes o par√°metros que mejor se ajusten a los datos.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-r" data-lang="r">&lt;span style="display:flex;">&lt;span>modelo &lt;span style="color:#f92672">&amp;lt;-&lt;/span> &lt;span style="color:#a6e22e">lrm&lt;/span>(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> diabetes &lt;span style="color:#f92672">~&lt;/span> &lt;span style="color:#a6e22e">rcs&lt;/span>(glucose, &lt;span style="color:#ae81ff">3&lt;/span>) &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">rcs&lt;/span>(mass, &lt;span style="color:#ae81ff">3&lt;/span>) &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">rcs&lt;/span>(age, &lt;span style="color:#ae81ff">3&lt;/span>) &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">rcs&lt;/span>(pedigree, &lt;span style="color:#ae81ff">3&lt;/span>) &lt;span style="color:#f92672">+&lt;/span> pregnant,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> data &lt;span style="color:#f92672">=&lt;/span> datos,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> x &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">TRUE&lt;/span>, &lt;span style="color:#75715e"># Guarda dise√±o para bootstrap&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> y &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">TRUE&lt;/span> &lt;span style="color:#75715e"># Guarda respuesta para bootstrap&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>En modelos de regresi√≥n, la &lt;strong>estimaci√≥n del modelo&lt;/strong> se realiza a partir de m√©todos como la &lt;strong>m√°xima verosimilitud&lt;/strong>. Sin embargo, cuando el n√∫mero de eventos es limitado o el de predictores es alto, el riesgo de sobreajuste es elevado, lo que genera predicciones extremas y poco generalizables. Para mitigarlo, se emplean t√©cnicas de &lt;strong>regularizaci√≥n, penalizaci√≥n o shrinkage&lt;/strong>, que ajustan los coeficientes hacia cero para mejorar la estabilidad y la calibraci√≥n en nuevas poblaciones.&lt;/p>
&lt;p>El objetivo final no es maximizar el rendimiento aparente en la muestra de desarrollo, sino obtener un modelo con &lt;strong>predicciones estables, bien calibradas y cl√≠nicamente √∫tiles&lt;/strong>.&lt;/p>
&lt;p>üí° &lt;strong>Tip para la publicaci√≥n:&lt;/strong> La ecuaci√≥n final del modelo debe presentarse de forma completa ‚Äîincluyendo todos los coeficientes, el intercepto y, si corresponde, la supervivencia basal‚Äî, reportando m√©tricas de calibraci√≥n y discriminaci√≥n con sus intervalos de confianza.&lt;/p>
&lt;p>En machine learning es com√∫n dividir los datos en entrenamiento y prueba. Sin embargo, en contextos cl√≠nicos es diferente:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Los &lt;strong>conjuntos de datos&lt;/strong> suelen ser &lt;strong>peque√±os o medianos&lt;/strong> (usualmente menos de 1000 filas) ‚Üí dividir reduce la informaci√≥n disponible para entrenar.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Las &lt;strong>m√©tricas&lt;/strong> derivadas de la prueba pueden ser &lt;strong>altamente variables&lt;/strong>, dependiendo de qu√© observaciones caen en la partici√≥n.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Esto genera un &lt;strong>modelo menos estable&lt;/strong> y menos confiable, especialmente en estimaciones de probabilidades individuales.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;div class="flex px-4 py-3 mb-6 rounded-md bg-primary-100 dark:bg-primary-900">
&lt;span class="pr-3 pt-1 text-primary-600 dark:text-primary-300">
&lt;svg height="24" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">&lt;path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z"/>&lt;/svg>
&lt;/span>
&lt;span class="dark:text-neutral-300">La ausencia de particiones en su estudio ser un &lt;strong>tema pol√©mico&lt;/strong>, pero no se preocupe!
&lt;a href="#hi">M√°s adelante, se comentan algunos argumentos para la discusi√≥n.&lt;/a>&lt;/span>
&lt;/div>
&lt;h3 id="5-evaluaci√≥n-del-rendimiento-del-modelo">5. Evaluaci√≥n del Rendimiento del Modelo&lt;/h3>
&lt;p>Una vez desarrollado el modelo, es esencial cuantificar su capacidad predictiva antes de su validaci√≥n. Esta evaluaci√≥n se centra en tres aspectos clave:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Calibraci√≥n:&lt;/strong> Mide la concordancia entre las probabilidades predichas y las observadas. Por ejemplo, ¬øun 10% de riesgo predicho se corresponde con un 10% de eventos observados? Se eval√∫a visualmente con curvas de calibraci√≥n y cuantitativamente con par√°metros como el intercepto (A, calibraci√≥n-in-the-large) y la pendiente de calibraci√≥n (B).&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-r" data-lang="r">&lt;span style="display:flex;">&lt;span>cal_boot &lt;span style="color:#f92672">&amp;lt;-&lt;/span> &lt;span style="color:#a6e22e">calibrate&lt;/span>(modelo, method &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;boot&amp;#34;&lt;/span>, B &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">100&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">plot&lt;/span>(cal_boot, main &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;Calibraci√≥n: Predichas vs Observadas&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">## &lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">## n=768 Mean absolute error=0.016 Mean squared error=0.00045&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">## 0.9 Quantile of absolute error=0.034&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">abline&lt;/span>(&lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, lty &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">2&lt;/span>, col &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;red&amp;#34;&lt;/span>) &lt;span style="color:#75715e"># L√≠nea ideal&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;img src="calibracion-1.png" width="80%" style="display: block; margin: auto;" />
&lt;details class="spoiler " id="spoiler-9">
&lt;summary class="cursor-pointer">El gr√°fico muestra que el modelo est√° bien calibrado (Click para saber por qu√©)&lt;/summary>
&lt;div class="rounded-lg bg-neutral-50 dark:bg-neutral-800 p-2">
La calibraci√≥n perfecta ocurre cuando las probabilidades predichas coinciden con las frecuencias reales. Por ejemplo, si el modelo predice 30% de riesgo, aproximadamente 30 de cada 100 pacientes similares deber√≠an tener la condici√≥n.
&lt;/div>
&lt;/details>
&lt;ul>
&lt;li>&lt;strong>Discriminaci√≥n:&lt;/strong> Eval√∫a la capacidad del modelo para distinguir entre pacientes que experimentan el evento y aquellos que no. La m√©trica m√°s com√∫n es el estad√≠stico C (o AUC-ROC), que representa la probabilidad de que un paciente con el evento tenga una puntuaci√≥n de riesgo m√°s alta que uno sin √©l.&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-r" data-lang="r">&lt;span style="display:flex;">&lt;span>val_boot &lt;span style="color:#f92672">&amp;lt;-&lt;/span> &lt;span style="color:#a6e22e">validate&lt;/span>(modelo, method &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;boot&amp;#34;&lt;/span>, B &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">100&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>roc_obj &lt;span style="color:#f92672">&amp;lt;-&lt;/span> &lt;span style="color:#a6e22e">roc&lt;/span>(datos&lt;span style="color:#f92672">$&lt;/span>diabetes,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">predict&lt;/span>(modelo, type &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;fitted&amp;#34;&lt;/span>))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">plot&lt;/span>(roc_obj,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> main &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">paste&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;Curva ROC - AUC =&amp;#34;&lt;/span>, &lt;span style="color:#a6e22e">round&lt;/span>(&lt;span style="color:#a6e22e">auc&lt;/span>(roc_obj), &lt;span style="color:#ae81ff">3&lt;/span>)),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> col &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;blue&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> legacy.axes &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">TRUE&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;img src="Discriminacion-1.png" width="80%" style="display: block; margin: auto;" />
&lt;details class="spoiler " id="spoiler-10">
&lt;summary class="cursor-pointer">El gr√°fico del √°rea bajo la curva ROC (AUC) muestra muy buena discriminaci√≥n (Click para saber por qu√©)&lt;/summary>
&lt;div class="rounded-lg bg-neutral-50 dark:bg-neutral-800 p-2">
&lt;ul>
&lt;li>La curva ROC eval√∫a la capacidad del modelo para distinguir entre pacientes con y sin la condici√≥n.
&lt;ul>
&lt;li>AUC = Excelente (&amp;gt;0.8 se considera muy bueno en medicina)&lt;/li>
&lt;li>Eje Y: Sensibilidad (capacidad de detectar enfermos)&lt;/li>
&lt;li>Eje X: 1 - Especificidad (tasa de falsos positivos)&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/details>
&lt;ul>
&lt;li>&lt;strong>Utilidad Cl√≠nica:&lt;/strong> Determina si el modelo es √∫til para la toma de decisiones. El an√°lisis de curvas de decisi√≥n y el Beneficio Neto (NB) permiten evaluar si el uso del modelo conduce a mejores resultados cl√≠nicos netos en comparaci√≥n con estrategias alternativas (como tratar a todos o a ninguno).&lt;/li>
&lt;/ul>
&lt;h3 id="6-evaluaci√≥n-de-la-validez-del-modelo">6. Evaluaci√≥n de la Validez del Modelo&lt;/h3>
&lt;p>La &lt;strong>evaluaci√≥n del rendimiento&lt;/strong> en los datos suele ser optimista. Por ello, es crucial evaluar la validez del modelo en datos no utilizados para su construcci√≥n, un proceso que se divide en:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Validaci√≥n Interna:&lt;/strong> Eval√∫a la reproducibilidad del modelo, es decir, su rendimiento en m√∫ltiples muestras de la misma poblaci√≥n subyacente. T√©cnicas como el bootstrapping o la validaci√≥n cruzada son superiores a la divisi√≥n simple de la muestra, ya que cuantifican y corrigen el optimismo en las m√©tricas de rendimiento sin reducir el tama√±o de la muestra de desarrollo.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Validaci√≥n Externa:&lt;/strong> Es la prueba definitiva de la generalizabilidad o transportabilidad del modelo. Consiste en aplicar el modelo a una poblaci√≥n completamente independiente, lo que puede incluir:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Validaci√≥n Temporal:&lt;/strong> Usar pacientes reclutados en un per√≠odo posterior.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Validaci√≥n Geogr√°fica:&lt;/strong> Aplicar el modelo en pacientes de otros centros u hospitales.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="7-presentaci√≥n-del-modelo">7. Presentaci√≥n del modelo&lt;/h3>
&lt;p>La presentaci√≥n efectiva es crucial para la adopci√≥n cl√≠nica. Un modelo perfecto es in√∫til si los m√©dicos no pueden usarlo f√°cilmente. Algunas opciones para llevar el modelo a la pr√°ctica asistencial son:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Nomogramas&lt;/strong>: Ideales para uso r√°pido en consulta.&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-r" data-lang="r">&lt;span style="display:flex;">&lt;span>nom &lt;span style="color:#f92672">&amp;lt;-&lt;/span> &lt;span style="color:#a6e22e">nomogram&lt;/span>(modelo,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> fun &lt;span style="color:#f92672">=&lt;/span> plogis,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> funlabel &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;Riesgo de Diabetes&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">plot&lt;/span>(nom, main &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;Nomograma del Modelo&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;img src="nomograma-1.png" width="80%" style="display: block; margin: auto;" />
&lt;details class="spoiler " id="spoiler-11">
&lt;summary class="cursor-pointer">Nomograma: calculadora visual del riesgo (Click para aprender a usarlo)&lt;/summary>
&lt;div class="rounded-lg bg-neutral-50 dark:bg-neutral-800 p-2">
&lt;p>El &lt;strong>nomograma&lt;/strong> es una herramienta visual que permite calcular el riesgo individual de diabetes manualmente, usando las variables clave del modelo. Permite calcular el riesgo espec√≠fico para cada paciente sin necesidad de software, facilitando su uso en consulta&lt;/p>
&lt;p>¬øC√≥mo funciona?&lt;/p>
&lt;ul>
&lt;li>Por cada variable cl√≠nica (glucosa, IMC, edad, etc.) se asigna un puntaje en la escala &amp;ldquo;Points&amp;rdquo;&lt;/li>
&lt;li>Se suman todos los puntos para obtener el &amp;ldquo;Total Points&amp;rdquo;&lt;/li>
&lt;li>Se proyecta ese total sobre las escalas inferiores para obtener el riesgo predictivo&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/details>
&lt;ul>
&lt;li>&lt;strong>Aplicaciones web/m√≥viles&lt;/strong>: Para integraci√≥n en flujos de trabajo cl√≠nicos&lt;/li>
&lt;/ul>
&lt;p>Una aplicaci√≥n funcional para ejecutar el modelo en una pagina web, tel√©fono movil o tableta es una muy buena opci√≥n para generalizar el modelo.&lt;/p>
&lt;p>En este enlace te muestro la calculadora web que program√© en js, html y css, para el modelo de mi tesis.&lt;/p>
&lt;p>&lt;a href="https://bioestadisticaedu.com/project/covidcencecapk/">ver CovidCencecAPK&lt;/a>&lt;/p>
&lt;h2 id="hi">Mis recomendaciones y posici√≥n&lt;/h2>
&lt;p>Reconozco que la &lt;strong>partici√≥n simple de datos (70/30)&lt;/strong> es un est√°ndar frecuente y, a menudo, el punto de partida en la pr√°ctica del Machine Learning. No obstante, si nuestro objetivo es fortalecer la credibilidad y la robustez de nuestros hallazgos, especialmente en el √°mbito de los &lt;strong>modelos cl√≠nicos&lt;/strong>, este enfoque merece una pausa y una seria reconsideraci√≥n.&lt;/p>
&lt;p>La cr√≠tica a esta pr√°ctica no es nueva ni aislada. Autores influyentes en el campo como Frank Harrell y Edmund Steyerberg han expresado su clara oposici√≥n, y otros expertos se suman a este consenso. Como bien lo resume Smedenen en este &lt;em>tweet&lt;/em>:&lt;/p>
&lt;blockquote class="twitter-tweet">&lt;p lang="en" dir="ltr">Good description of leakage, but very often an even better solution is not to split your data into train-test sets at all. Cross validation and internal-external validation should be the starting point (deviate only when necessary) &lt;a href="https://t.co/l3ZDmv2kzb">https://t.co/l3ZDmv2kzb&lt;/a>&lt;/p>&amp;mdash; Maarten van Smeden (@MaartenvSmeden) &lt;a href="https://twitter.com/MaartenvSmeden/status/1544599686488723461?ref_src=twsrc%5Etfw">July 6, 2022&lt;/a>&lt;/blockquote>
&lt;script async src="https://platform.twitter.com/widgets.js" charset="utf-8">&lt;/script>
&lt;p>Comparto plenamente esta visi√≥n: para muestras peque√±as, como suelen ser los conjuntos de datos de investigaciones cl√≠nicas, una partici√≥n simple ‚Äîaunque sea aleatoria‚Äî introduce m√°s riesgos que beneficios. Esta es una pr√°ctica m√°s com√∫n en entornos de Machine Learning general, donde los datasets son, t√≠picamente, mucho m√°s extensos.&lt;/p>
&lt;p>A continuaci√≥n, exploremos en detalle las principales razones por las que este enfoque puede no ser la mejor pr√°ctica cuando la precisi√≥n y la vida de los pacientes est√°n en juego.&lt;/p>
&lt;h3 id="1-ineficiencia-en-el-uso-de-los-datos-y-p√©rdida-de-poder">1. Ineficiencia en el uso de los datos y p√©rdida de poder&lt;/h3>
&lt;p>Los conjuntos de datos cl√≠nicos son, por naturaleza, a menudo peque√±os (pensemos en menos de 500 pacientes), limitados por costes o la baja incidencia de eventos raros.&lt;/p>
&lt;p>Una partici√≥n t√≠pica 70/30 desperdicia hasta un 30% de los datos solo en la evaluaci√≥n, reduciendo dr√°sticamente el tama√±o efectivo para el entrenamiento. Esto provoca una ca√≠da en la m√©trica clave de Eventos por Variable Predictora (EPV) ‚Äîque mide cu√°ntos eventos, como diagn√≥sticos positivos, hay por cada predictor en el modelo‚Äî, situ√°ndola frecuentemente por debajo del umbral recomendado de 10-20.&lt;/p>
&lt;p>El resultado es predecible: modelos inestables y sesgados. El rendimiento aparente (ej., un AUC alto en el split de entrenamiento) puede caer dr√°sticamente en datos nuevos (por ejemplo, de 0.85 a un decepcionante 0.65). En contextos cl√≠nicos, donde capturar patrones reales es vital, la recomendaci√≥n es clara: &lt;strong>maximizar todos los datos y aplicar t√©cnicas de remuestreo para una estimaci√≥n m√°s honesta.&lt;/strong>&lt;/p>
&lt;h3 id="2-evaluaciones-de-rendimiento-con-alta-variabilidad-e-inestabilidad">2. Evaluaciones de rendimiento con alta variabilidad e inestabilidad&lt;/h3>
&lt;p>Cuando dependemos de una sola partici√≥n simple, las m√©tricas de rendimiento (como el AUC para la discriminaci√≥n o el Brier score para la calibraci√≥n) se vuelven muy sensibles al azar de c√≥mo se dividieron los datos.&lt;/p>
&lt;p>Las simulaciones demuestran que esta &amp;ldquo;suerte&amp;rdquo; puede generar variaciones de hasta de m√°s o menos 0.10-0.15 en el AUC, un ruido significativo. Esta varianza se dispara (2-3 veces m√°s) en muestras peque√±as. Un resultado inestable puede inflar o subestimar la calibraci√≥n (ej. en el test de Hosmer-Lemeshow), lo que podr√≠a llevar a tomar decisiones cl√≠nicas err√≥neas y, lo m√°s importante, poner en riesgo a los pacientes (por ejemplo, subtratando a quienes lo necesitan).&lt;/p>
&lt;p>Para ilustrar esta inestabilidad, aqu√≠ se simula la variabilidad del AUC en splits simples repetidos utilizando el dataset de nuestro ejemplo:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-r" data-lang="r">&lt;span style="display:flex;">&lt;span>auc_splits &lt;span style="color:#f92672">&amp;lt;-&lt;/span> &lt;span style="color:#a6e22e">replicate&lt;/span>(&lt;span style="color:#ae81ff">100&lt;/span>, {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> trainIndex &lt;span style="color:#f92672">&amp;lt;-&lt;/span> &lt;span style="color:#a6e22e">createDataPartition&lt;/span>(datos&lt;span style="color:#f92672">$&lt;/span>diabetes, p &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">0.7&lt;/span>, list &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">FALSE&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> train &lt;span style="color:#f92672">&amp;lt;-&lt;/span> datos[trainIndex, ]; test &lt;span style="color:#f92672">&amp;lt;-&lt;/span> datos[&lt;span style="color:#f92672">-&lt;/span>trainIndex, ]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> model_simple &lt;span style="color:#f92672">&amp;lt;-&lt;/span> &lt;span style="color:#a6e22e">glm&lt;/span>(diabetes &lt;span style="color:#f92672">~&lt;/span> glucose &lt;span style="color:#f92672">+&lt;/span> mass &lt;span style="color:#f92672">+&lt;/span> age, family &lt;span style="color:#f92672">=&lt;/span> binomial, data &lt;span style="color:#f92672">=&lt;/span> train)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> pred &lt;span style="color:#f92672">&amp;lt;-&lt;/span> &lt;span style="color:#a6e22e">predict&lt;/span>(model_simple, test, type &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;response&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">roc&lt;/span>(test&lt;span style="color:#f92672">$&lt;/span>diabetes, pred)&lt;span style="color:#f92672">$&lt;/span>auc
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>})
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">hist&lt;/span>(auc_splits,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> main &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;Distribuci√≥n de AUC en 100 Splits Simples&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> xlab &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;AUC&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> col &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;lightgray&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> border &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;black&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;img src="Simular-1.png" width="80%" style="display: block; margin: auto;" />
&lt;h3 id="3-riesgo-de-sobreajuste-y-falta-de-generalizaci√≥n-robusta">3. Riesgo de sobreajuste y falta de generalizaci√≥n robusta&lt;/h3>
&lt;p>Una simple &amp;ldquo;instant√°nea&amp;rdquo; proporcionada por la partici√≥n de prueba no es suficiente para corregir el sobreajuste. El modelo, al ajustarse al conjunto de entrenamiento (incluyendo su ruido), ofrece un rendimiento aparente (un &amp;ldquo;optimismo&amp;rdquo;) que, seg√∫n Harrell, puede ser un 5-20% superior al real.&lt;/p>
&lt;p>Sin m√©todos de remuestreo, es imposible obtener un error de generalizaci√≥n realista. M√©todos repetidos (como la validaci√≥n cruzada de k-pliegues) promedian las estimaciones a lo largo de m√∫ltiples splits, lo que reduce el sesgo y mejora la estabilidad.&lt;/p>
&lt;p>Cuando no se corrige este optimismo, no solo se afecta la validez interna del estudio, sino que se compromete la generalizaci√≥n del modelo, pues fallar√° al aplicarse a cohortes externas debido a las idiosincrasias (detalles √∫nicos) de la muestra original.&lt;/p>
&lt;h2 id="-mi-sugerencia">üí° Mi Sugerencia&lt;/h2>
&lt;p>En lugar de depender de particiones simples, mi recomendaci√≥n es clara: utilizar m√©todos que aprovechen la totalidad de los datos y ofrezcan estimaciones m√°s estables. Esto incluye:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Validaci√≥n Cruzada Repetida: Divide los datos en particiones y repite el proceso de divisi√≥n y evaluaci√≥n m√∫ltiples veces para promediar los resultados.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Bootstrapping: Muestrea con reemplazo para estimar la estabilidad y corregir el optimismo inherente.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Estos m√©todos no solo corrigen el optimismo sino que reducen la variabilidad, aline√°ndose con las buenas pr√°cticas en el desarrollo de modelos de pron√≥stico cl√≠nico. Por esta raz√≥n, seleccion√© bibliotecas como rms::validate() en R para el ejemplo, ya que se adhieren a esta filosof√≠a.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Para conjuntos de datos peque√±os, la robustez es lo primero. Evite las divisiones simples y priorice la estabilidad para generar resultados que sean verdaderamente √∫tiles en la pr√°ctica asistencial.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Un Apunte sobre la Validaci√≥n Externa&lt;/strong>&lt;/p>
&lt;p>Coincido en que la validaci√≥n externa es crucial y debe realizarse con un conjunto de datos independiente en otros contextos, ya sea en diferentes momentos (validaci√≥n temporal) o en distintos hospitales (validaci√≥n geogr√°fica), para confirmar la verdadera generalizaci√≥n.&lt;/p>
&lt;p>En mi experiencia, las cuestiones operativas y log√≠sticas que implica realizar una validaci√≥n externa en otro centro o en otro momento a menudo desmotivan al investigador que est√° desarrollando un modelo con datos de su propia consulta. Sin embargo, creo que este enfoque es el que abre el camino para obtener mejores resultados a partir de la investigaci√≥n en condiciones reales. Adem√°s, es un acto de m√©rito y un pilar de la ciencia realizar validaciones de modelos de otros en su propia consulta; la ciencia se nutre de la replicaci√≥n y la colaboraci√≥n.&lt;/p>
&lt;h2 id="-qu√©-sigue">‚è≠Ô∏è ¬øQu√© sigue?&lt;/h2>
&lt;p>Esta gu√≠a es una introducci√≥n pr√°ctica y concisa para iniciarse en modelos predictivos cl√≠nicos. Temas avanzados como el c√°lculo detallado de tama√±o de muestra, el manejo exhaustivo de datos faltantes (m√°s all√° de imputaci√≥n b√°sica), la actualizaci√≥n de modelos existentes, an√°lisis profundos de curvas de decisi√≥n para utilidad cl√≠nica, la reproducibilidad, el ajuste del intercepto de la regresi√≥n log√≠stica en escenarios con prevalencias diferentes, los m√©todos de recalibraci√≥n continua, o la construcci√≥n de escalas y clasificaciones cl√≠nicas no se abordan en detalle para mantener la brevedad y enfoque en lo esencial. Para profundizar, consulta referencias como Steyerberg o el marco TRIPOD.&lt;/p>
&lt;h2 id="-tu-turno">üöÄ ¬°Tu Turno!&lt;/h2>
&lt;p>&lt;strong>Pasa de la Teor√≠a a la Pr√°ctica.&lt;/strong> Este material es solo la punta del iceberg. ¬°Ahora aplica estos conceptos con tus datos cl√≠nicos y experimenta para construir modelos m√°s robustos! Si necesitas m√°s recursos, explora las referencias mencionadas.&lt;/p>
&lt;p>Ahora, me encantar√≠a leerte. ¬°La experiencia es la que enriquece el conocimiento!&lt;/p>
&lt;p>üí¨ D√©janos tu &lt;strong>comentario en la caja de comentarios&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>¬øHas aplicado estas t√©cnicas de remuestreo en tus proyectos de modelos predictivos?&lt;/li>
&lt;li>¬øQu√© estrategias usas habitualmente para entrenar y validar tus modelos cl√≠nicos?&lt;/li>
&lt;li>Tus comentarios, tus dificultades y tus logros nos ayudan a todos a seguir aprendiendo.&lt;/li>
&lt;/ul>
&lt;p>üöÄ Lleva el C√≥digo a tu Proyecto&lt;/p>
&lt;p>&lt;a href="https://bioestadisticaedu.com/subscribe/">&lt;strong>Subscribete&lt;/strong> a nuestra comunidad de bioestad√≠sticaedu, recibe art√≠culos directamente en tu bandeja de entrada, sigue nuestro canal RSS o
sigue mi canal de telegram&lt;/a>.&lt;/p>
&lt;div class="flex px-4 py-3 mb-6 rounded-md bg-primary-100 dark:bg-primary-900">
&lt;span class="pr-3 pt-1 text-primary-600 dark:text-primary-300">
&lt;svg height="24" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">&lt;path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z"/>&lt;/svg>
&lt;/span>
&lt;span class="dark:text-neutral-300">Al suscribirte, te enviar√© inmediatamente una &lt;strong>plantilla completa con todo el c√≥digo comentado (¬°incluyendo tablas y estructura!)&lt;/strong> lista para aplicar este proceso en tu pr√≥xima publicaci√≥n o tesis.&lt;/span>
&lt;/div>
&lt;p>ü§ù ¬øNecesitas un Enfoque Personalizado?&lt;/p>
&lt;p>&lt;a href="https://bioestadisticaedu.com/collaborations/">Si quieres aplicar estas estrategias a un dataset espec√≠fico y necesitas la seguridad de un experto a tu lado, tambi√©n puedes contactarme para una consultor√≠a personalizada sobre este tema.&lt;/a>.&lt;/p>
&lt;p>Y recuerda siempre la regla de oro: &lt;strong>¬°Si vas a cometer errores que sean nuevos! üòâ&lt;/strong> &lt;em>m@icel&lt;/em>&lt;/p>
&lt;h2 id="bibliograf√≠a">Bibliograf√≠a&lt;/h2>
&lt;ol>
&lt;li>
&lt;p>Collins GS, Moons KGM, Dhiman P, Riley RD, Beam AL, Van Calster B, et¬†al. TRIPOD+AI statement: updated guidance for reporting clinical prediction models that use regression or machine learning methods. BMJ [Internet]. 16 de abril de 2024 [citado 3 de octubre de 2025];e078378. Disponible en: &lt;a href="https://www.bmj.com/lookup/doi/10.1136/bmj-2023-078378" target="_blank" rel="noopener">https://www.bmj.com/lookup/doi/10.1136/bmj-2023-078378&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Steyerberg EW, Vergouwe Y. Towards better clinical prediction models: seven steps for development and an ABCD for validation. European Heart Journal [Internet]. 1 de agosto de 2014 [citado 9 de mayo de 2021];35(29):1925-31. Disponible en: &lt;a href="https://academic.oup.com/eurheartj/article-lookup/doi/10.1093/eurheartj/ehu207" target="_blank" rel="noopener">https://academic.oup.com/eurheartj/article-lookup/doi/10.1093/eurheartj/ehu207&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Steyerberg E. Clinical Prediction Models. 1th ed. USA: Springer; 2009. (Statistics for Biology and Health).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Harrell Jr FE. Regression Modeling Strategies. 1era ed. New York: Springer; 2015.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Heinze G, Wallisch C, Dunkler D. Variable selection - A review and recommendations for the practicing statistician. Biom J [Internet]. mayo de 2018 [citado 9 de mayo de 2021];60(3):431-49. Disponible en: &lt;a href="http://doi.wiley.com/10.1002/bimj.201700067" target="_blank" rel="noopener">http://doi.wiley.com/10.1002/bimj.201700067&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>&lt;a href="https://bioestadisticaedu.com/collaborations/">Puede contactarme para una consultor√≠a personalizada donde puedo ayudarle a desarrollar un modelo predictivo o ense√±arle a desarrollar la estrategia de modelado con otras herramientas como &lt;strong>SPSS&lt;/strong> o &lt;strong>Python&lt;/strong>.&lt;/a>.&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>An√°lisis Exploratorio de Datos: Desentra√±ando la Verdad de tus Datos</title><link>https://bioestadisticaedu.com/post/eda/</link><pubDate>Tue, 11 Feb 2025 00:00:00 +0000</pubDate><guid>https://bioestadisticaedu.com/post/eda/</guid><description>&lt;p>üéß &lt;strong>Escucha el podcast de esta publicaci√≥n&lt;/strong>
&lt;audio controls >
&lt;source src="https://bioestadisticaedu.com/mp3/eda.mp3" type="audio/mpeg">
&lt;/audio>
&lt;/p>
&lt;h2 id="introducci√≥n">Introducci√≥n&lt;/h2>
&lt;p>El &lt;strong>An√°lisis Exploratorio de Datos (EDA)&lt;/strong> es una disciplina fundamental en el campo de la ciencia de datos, popularizada por el matem√°tico John Tukey. M√°s que una simple serie de pasos, el EDA es una filosof√≠a que nos invita a interactuar con nuestros datos, visualizarlos, resumirlos y &amp;ldquo;hablar&amp;rdquo; con ellos antes de saltar a modelados complejos. Implica el an√°lisis de datos centrado en comprender a fondo su estructura, identificar patrones ocultos, detectar anomal√≠as (valores at√≠picos), gestionar datos ausentes y, en √∫ltima instancia, proporcionar una base s√≥lida para la formulaci√≥n de modelos predictivos o inferenciales. Adem√°s, es crucial para descubrir c√≥mo se relacionan las variables entre s√≠.&lt;/p>
&lt;p>Un concepto popular y vital en el campo de la ciencia de datos es &lt;strong>GIGO&lt;/strong> (Garbage In, Garbage Out, o &amp;ldquo;Basura entra, basura sale&amp;rdquo;). Este concepto subraya que la calidad de los resultados de cualquier an√°lisis o modelo es directamente proporcional a la calidad de los datos de entrada. No importa cu√°n sofisticado sea tu algoritmo o cu√°n potente sea tu infraestructura computacional, los datos de mala calidad siempre producir√°n resultados deficientes, enga√±osos o in√∫tiles. El EDA es nuestra primera l√≠nea de defensa contra el GIGO, asegurando que trabajamos con datos limpios y comprensibles.&lt;/p>
&lt;h2 id="un-flujo-de-trabajo-pr√°ctico-de-eda">Un Flujo de Trabajo Pr√°ctico de EDA&lt;/h2>
&lt;p>Aunque el EDA es un proceso iterativo y no una &amp;ldquo;camisa de fuerza&amp;rdquo; r√≠gida, es √∫til seguir un flujo de trabajo estructurado para garantizar que cubrimos los aspectos m√°s importantes. El orden de las etapas y el √©nfasis en cada una depender√°n en gran medida del problema espec√≠fico, el tipo de datos y los objetivos del an√°lisis.&lt;/p>
&lt;p>Este proceso general incluye:&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="flex justify-center ">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/eda/fig01_hu_1d111632709b1b76.webp 400w,
/post/eda/fig01_hu_b26fdc398618e3dc.webp 760w,
/post/eda/fig01_hu_540748744cda905c.webp 1200w"
src="https://bioestadisticaedu.com/post/eda/fig01_hu_1d111632709b1b76.webp"
width="760"
height="578"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>A continuaci√≥n, profundicemos en cada una de estas etapas, utilizando ejemplos pr√°cticos con el paquete &lt;code>dlookr&lt;/code> en R.&lt;/p>
&lt;h3 id="1-comprensi√≥n-general-de-los-datos-y-evaluaci√≥n-de-su-calidad">1. Comprensi√≥n General de los Datos y Evaluaci√≥n de su Calidad&lt;/h3>
&lt;p>Antes de sumergirnos en an√°lisis profundos, es fundamental tener una visi√≥n panor√°mica de nuestro conjunto de datos. Esta etapa implica:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Dimensiones del dataset:&lt;/strong> ¬øCu√°ntas filas (observaciones) y columnas (variables) tenemos?&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Tipos de datos:&lt;/strong> ¬øLas variables son num√©ricas (enteros, flotantes), categ√≥ricas (factores, caracteres), l√≥gicas o de fecha/hora? Es crucial que los tipos de datos sean correctos para las operaciones que deseamos realizar.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Inspecci√≥n inicial:&lt;/strong> Revisar las primeras y √∫ltimas filas del dataset para obtener una idea general del formato y contenido.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Estad√≠sticas descriptivas b√°sicas:&lt;/strong> Para variables num√©ricas: media, mediana, desviaci√≥n est√°ndar, m√≠nimo, m√°ximo, cuartiles. Para variables categ√≥ricas: conteo de ocurrencias, proporciones. Esto nos da una primera impresi√≥n de la dispersi√≥n y centralidad de los datos.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Con &lt;code>dlookr&lt;/code>, la funci√≥n &lt;code>diagnose()&lt;/code> es ideal para una revisi√≥n r√°pida de la calidad de los datos, mostrando el tipo de variable, el n√∫mero de valores √∫nicos, valores faltantes, valores cero y valores negativos.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-r" data-lang="r">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Para obtener un resumen r√°pido de las caracter√≠sticas de los datos&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">diagnose&lt;/span>(mtcars_na)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Esta fase nos ayuda a formar una primera hip√≥tesis sobre la calidad y estructura de los datos, identificando posibles problemas desde el principio.&lt;/p>
&lt;h3 id="2-identificaci√≥n-y-tratamiento-de-valores-faltantes-y-at√≠picos">2. Identificaci√≥n y Tratamiento de Valores Faltantes y At√≠picos&lt;/h3>
&lt;p>Los valores faltantes (NA, NaN, null) y los valores at√≠picos (outliers) son dos de los desaf√≠os m√°s comunes en cualquier conjunto de datos y pueden distorsionar significativamente los resultados de nuestros an√°lisis y modelos.&lt;/p>
&lt;p>&lt;strong>Valores Faltantes:&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Identificaci√≥n:&lt;/strong> Cuantificar la cantidad y proporci√≥n de valores faltantes por variable. Visualizar patrones de ausencia (¬ølos valores faltantes ocurren aleatoriamente o hay un patr√≥n?).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Tratamiento:&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Eliminaci√≥n:&lt;/strong> Si la cantidad de valores faltantes es peque√±a o si una variable tiene un porcentaje muy alto de NAs, se pueden eliminar filas o columnas.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Imputaci√≥n:&lt;/strong> Rellenar los valores faltantes. M√©todos comunes incluyen la media, mediana o moda (para datos num√©ricos y categ√≥ricos, respectivamente), o m√©todos m√°s avanzados basados en modelos (regresi√≥n, k-NN, etc.). La elecci√≥n depende de la naturaleza de los datos y el problema.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Valores At√≠picos:&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Identificaci√≥n:&lt;/strong> Observaciones que se desv√≠an significativamente del resto de los datos. Se pueden detectar mediante gr√°ficos de caja (boxplots), diagramas de dispersi√≥n, puntuaciones Z, el m√©todo IQR (rango intercuart√≠lico) o algoritmos m√°s sofisticados.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Tratamiento:&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Eliminaci√≥n:&lt;/strong> Si se confirma que son errores de entrada de datos.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Transformaci√≥n:&lt;/strong> Aplicar transformaciones logar√≠tmicas o de ra√≠z cuadrada para reducir su impacto.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Capping/Flooring:&lt;/strong> Limitar los valores at√≠picos a un percentil superior o inferior (por ejemplo, el 99% o el 1%).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Mantener:&lt;/strong> A veces, los valores at√≠picos son observaciones genuinas e importantes que no deben eliminarse.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;code>dlookr&lt;/code> ofrece funciones visuales y program√°ticas para abordar estos problemas:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-r" data-lang="r">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Visualizar la distribuci√≥n de valores faltantes&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">plot_na&lt;/span>(mtcars_na)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Identificar valores at√≠picos para una variable espec√≠fica (ej. &amp;#34;hp&amp;#34;)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># plot_outlier() es excelente para visualizar.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">plot_outlier&lt;/span>(mtcars_df, &lt;span style="color:#e6db74">&amp;#34;hp&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="3-an√°lisis-de-la-distribuci√≥n-de-las-variables">3. An√°lisis de la Distribuci√≥n de las Variables&lt;/h3>
&lt;p>Comprender la distribuci√≥n de cada variable individualmente es clave para seleccionar los m√©todos estad√≠sticos y de modelado adecuados.&lt;/p>
&lt;p>&lt;strong>Variables Num√©ricas:&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Histogramas y gr√°ficos de densidad:&lt;/strong> Permiten visualizar la forma de la distribuci√≥n, identificar asimetr√≠as (skewness), curtosis, y la presencia de m√∫ltiples modos.&lt;/li>
&lt;li>&lt;strong>Medidas de asimetr√≠a y curtosis:&lt;/strong> Cuantifican la forma de la distribuci√≥n.&lt;/li>
&lt;li>&lt;strong>Pruebas de normalidad:&lt;/strong> Aunque muchas veces no son estrictamente necesarias, pueden complementar el an√°lisis visual.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Variables Categ√≥ricas:&lt;/strong> - &lt;strong>Gr√°ficos de barras:&lt;/strong> Muestran la frecuencia o proporci√≥n de cada categor√≠a. - &lt;strong>Tablas de frecuencia:&lt;/strong> Resumen el conteo y porcentaje de cada nivel.&lt;/p>
&lt;p>&lt;code>dlookr&lt;/code> simplifica la visualizaci√≥n de distribuciones:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-r" data-lang="r">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Visualizar la distribuci√≥n de una variable num√©rica (ej. &amp;#34;mpg&amp;#34;)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">plot_hist&lt;/span>(mtcars_df, &lt;span style="color:#e6db74">&amp;#34;mpg&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># O ver la distribuci√≥n y normalidad&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">plot_normality&lt;/span>(mtcars_df, &lt;span style="color:#e6db74">&amp;#34;mpg&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Para variables categ√≥ricas (como &amp;#39;cyl&amp;#39; en mtcars que es num√©rica discreta)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Podemos convertirla a factor para un an√°lisis categ√≥rico.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>mtcars_factor_cyl &lt;span style="color:#f92672">&amp;lt;-&lt;/span> mtcars_df &lt;span style="color:#f92672">%&amp;gt;%&lt;/span> &lt;span style="color:#a6e22e">mutate&lt;/span>(cyl &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">as.factor&lt;/span>(cyl))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">plot_bar&lt;/span>(mtcars_factor_cyl, &lt;span style="color:#e6db74">&amp;#34;cyl&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Este an√°lisis nos ayuda a entender el comportamiento de cada caracter√≠stica y a identificar la necesidad de transformaciones futuras.&lt;/p>
&lt;h3 id="4-an√°lisis-de-las-relaciones-entre-las-variables">4. An√°lisis de las Relaciones entre las Variables&lt;/h3>
&lt;p>Esta etapa se centra en descubrir c√≥mo las variables interact√∫an entre s√≠. Es fundamental para la selecci√≥n de caracter√≠sticas, la identificaci√≥n de multicolinealidad y la comprensi√≥n de la causalidad (o correlaci√≥n).&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Dos variables num√©ricas:&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Diagramas de dispersi√≥n (scatter plots):&lt;/strong> Visualizan la direcci√≥n y fuerza de la relaci√≥n (positiva, negativa, nula, no lineal).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Coeficientes de correlaci√≥n (Pearson, Spearman):&lt;/strong> Cuantifican la fuerza y direcci√≥n de la relaci√≥n lineal (Pearson) o mon√≥tona (Spearman).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Una variable num√©rica y una categ√≥rica:&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Gr√°ficos de caja (boxplots) o gr√°ficos de viol√≠n:&lt;/strong> Comparan la distribuci√≥n de la variable num√©rica entre las diferentes categor√≠as.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Pruebas t de Student o ANOVA:&lt;/strong> Para determinar si hay diferencias estad√≠sticamente significativas en las medias.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Dos variables categ√≥ricas:&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Tablas de contingencia y gr√°ficos de barras apiladas/agrupadas:&lt;/strong> Muestran la distribuci√≥n conjunta.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Pruebas de significaci√≥n:&lt;/strong> Para evaluar la independencia entre las variables.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Matrices de correlaci√≥n:&lt;/strong> Visualizan las correlaciones entre m√∫ltiples variables num√©ricas simult√°neamente, a menudo con mapas de calor (heatmaps).&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;code>dlookr&lt;/code> facilita la exploraci√≥n de relaciones:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-r" data-lang="r">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Visualizar la matriz de correlaci√≥n entre todas las variables num√©ricas&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">plot_cor&lt;/span>(mtcars_df)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Analizar la relaci√≥n entre una variable objetivo (&amp;#39;mpg&amp;#39;) y otra caracter√≠stica (&amp;#39;wt&amp;#39;)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># plot_eda() permite explorar diversas relaciones bivariadas.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">plot_eda&lt;/span>(mtcars_df, target &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;mpg&amp;#34;&lt;/span>, feature &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;wt&amp;#34;&lt;/span>) &lt;span style="color:#75715e"># Num√©rica vs Num√©rica (scatterplot)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Relaci√≥n entre &amp;#39;mpg&amp;#39; (num√©rica) y &amp;#39;cyl&amp;#39; (considerada categ√≥rica aqu√≠)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">plot_eda&lt;/span>(mtcars_df, target &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;mpg&amp;#34;&lt;/span>, feature &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;cyl&amp;#34;&lt;/span>) &lt;span style="color:#75715e"># Num√©rica vs Categ√≥rica (boxplot)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="5-transformaci√≥n-de-los-datos">5. Transformaci√≥n de los Datos&lt;/h3>
&lt;p>Una vez que hemos comprendido nuestros datos, es posible que necesitemos transformarlos para que sean m√°s adecuados para los algoritmos de machine learning o para mejorar el rendimiento del modelo.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Manejo de asimetr√≠a:&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Transformaciones logar√≠tmicas, de ra√≠z cuadrada o de Box-Cox:&lt;/strong> Pueden normalizar distribuciones sesgadas, reduciendo la influencia de valores extremos.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Escalado de caracter√≠sticas:&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Normalizaci√≥n (Min-Max Scaling):&lt;/strong> Escala los datos a un rango fijo (por ejemplo, [0, 1]). √ötil para algoritmos sensibles a la escala como SVM o redes neuronales.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Estandarizaci√≥n (Z-score Scaling):&lt;/strong> Transforma los datos para que tengan una media de 0 y una desviaci√≥n est√°ndar de 1. Es com√∫n en algoritmos basados en distancia (k-NN, K-Means, PCA).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Codificaci√≥n de variables categ√≥ricas:&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>One-Hot Encoding:&lt;/strong> Convierte variables categ√≥ricas en m√∫ltiples columnas binarias, una por cada categor√≠a. Esencial para algoritmos que solo trabajan con entradas num√©ricas.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Label Encoding:&lt;/strong> Asigna un n√∫mero entero a cada categor√≠a. √ötil si hay un orden inherente en las categor√≠as.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Ingenier√≠a de Caracter√≠sticas (Feature Engineering):&lt;/strong> Crear nuevas variables a partir de las existentes. Esto puede ser tan simple como combinar dos columnas o tan complejo como extraer informaci√≥n de texto o im√°genes. Esta etapa es a menudo la que m√°s impacto tiene en el rendimiento del modelo.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;code>dlookr&lt;/code> ofrece funciones √∫tiles para la transformaci√≥n de datos:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-r" data-lang="r">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Transformaci√≥n logar√≠tmica para reducir la asimetr√≠a de una variable&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>mtcars_transformed_log &lt;span style="color:#f92672">&amp;lt;-&lt;/span> &lt;span style="color:#a6e22e">transform_df&lt;/span>(mtcars_df, mpg &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">log&lt;/span>(mpg))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Compara la distribuci√≥n de mpg original vs. transformada&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">plot_normality&lt;/span>(mtcars_df, &lt;span style="color:#e6db74">&amp;#34;mpg&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">plot_normality&lt;/span>(mtcars_transformed_log, &lt;span style="color:#e6db74">&amp;#34;mpg&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Binarizaci√≥n o discretizaci√≥n de una variable continua (ej. &amp;#39;hp&amp;#39; en 3 bins)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>mtcars_binned &lt;span style="color:#f92672">&amp;lt;-&lt;/span> &lt;span style="color:#a6e22e">binning&lt;/span>(mtcars_df, &lt;span style="color:#e6db74">&amp;#34;hp&amp;#34;&lt;/span>, n &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">3&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">head&lt;/span>(mtcars_binned &lt;span style="color:#f92672">%&amp;gt;%&lt;/span> &lt;span style="color:#a6e22e">select&lt;/span>(hp, hp_Binned))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Estandarizaci√≥n de variables num√©ricas (Z-score)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>mtcars_scaled &lt;span style="color:#f92672">&amp;lt;-&lt;/span> &lt;span style="color:#a6e22e">normalize&lt;/span>(mtcars_df, method &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;scale&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">head&lt;/span>(mtcars_scaled) &lt;span style="color:#75715e"># Observa c√≥mo los valores de todas las columnas han cambiado&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="herramientas-populares-para-eda">Herramientas Populares para EDA&lt;/h2>
&lt;p>Para realizar un EDA efectivo, contamos con potentes herramientas en lenguajes como R y Python:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>En R:&lt;/strong>
&lt;ul>
&lt;li>El ecosistema &lt;code>tidyverse&lt;/code> (&lt;code>dplyr&lt;/code> para manipulaci√≥n, &lt;code>ggplot2&lt;/code> para visualizaci√≥n) es indispensable.&lt;/li>
&lt;li>Paquetes espec√≠ficos para EDA como &lt;strong>&lt;code>dlookr&lt;/code>&lt;/strong>, es excelente por su enfoque estructurado en el diagn√≥stico de calidad, exploraci√≥n y transformaci√≥n de datos, ofreciendo funciones y reportes automatizados que agilizan el proceso. Otros paquetes √∫tiles incluyen &lt;code>DataExplorer&lt;/code>, &lt;code>skimr&lt;/code>, y &lt;code>visdat&lt;/code>.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>En Python:&lt;/strong>
&lt;ul>
&lt;li>&lt;code>pandas&lt;/code> para manipulaci√≥n de datos.&lt;/li>
&lt;li>&lt;code>matplotlib&lt;/code> y &lt;code>seaborn&lt;/code> para visualizaci√≥n est√°tica.&lt;/li>
&lt;li>&lt;code>plotly&lt;/code> para visualizaciones interactivas.&lt;/li>
&lt;li>Bibliotecas como &lt;code>missingno&lt;/code> para visualizar valores faltantes, &lt;code>pandas_profiling&lt;/code> para informes autom√°ticos de EDA, y &lt;code>sweetviz&lt;/code> para comparaciones.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="conclusi√≥n">Conclusi√≥n&lt;/h2>
&lt;p>El An√°lisis Exploratorio de Datos no es solo una fase inicial, sino un proceso continuo de aprendizaje sobre tus datos. Es una inversi√≥n de tiempo que rinde grandes dividendos, ya que una comprensi√≥n profunda de los datos nos permite tomar decisiones m√°s informadas, construir modelos m√°s robustos y, en √∫ltima instancia, extraer conocimientos m√°s valiosos. Al dominar el EDA, te equipas con la habilidad de transformar datos brutos en una historia coherente y accionable, evitando la trampa del GIGO y asegurando que tus esfuerzos de ciencia de datos generen un impacto real.&lt;/p></description></item></channel></rss>