<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Código Práctico en R/Python | Bioestadística edu</title><link>https://maicel.netlify.app/categories/codigo-practico-en-r/python/</link><atom:link href="https://maicel.netlify.app/categories/codigo-practico-en-r/python/index.xml" rel="self" type="application/rss+xml"/><description>Código Práctico en R/Python</description><generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>es-es</language><lastBuildDate>Tue, 11 Feb 2025 00:00:00 +0000</lastBuildDate><image><url>https://maicel.netlify.app/media/icon_hu_551fbaee136b383e.png</url><title>Código Práctico en R/Python</title><link>https://maicel.netlify.app/categories/codigo-practico-en-r/python/</link></image><item><title>Análisis Exploratorio de Datos: Desentrañando la Verdad de tus Datos</title><link>https://maicel.netlify.app/posts/2025-02-11-eda/</link><pubDate>Tue, 11 Feb 2025 00:00:00 +0000</pubDate><guid>https://maicel.netlify.app/posts/2025-02-11-eda/</guid><description>&lt;p>🎧 &lt;strong>Escucha el podcast de esta publicación&lt;/strong>
&lt;audio controls >
&lt;source src="https://maicel.netlify.app/mp3/eda.mp3" type="audio/mpeg">
&lt;/audio>
&lt;/p>
&lt;p>El &lt;strong>Análisis Exploratorio de Datos (EDA)&lt;/strong> es una disciplina fundamental en el campo de la ciencia de datos, popularizada por el matemático John Tukey. Más que una simple serie de pasos, el EDA es una filosofía que nos invita a interactuar con nuestros datos, visualizarlos, resumirlos y &amp;ldquo;hablar&amp;rdquo; con ellos antes de saltar a modelados complejos. Implica el análisis de datos centrado en comprender a fondo su estructura, identificar patrones ocultos, detectar anomalías (valores atípicos), gestionar datos ausentes y, en última instancia, proporcionar una base sólida para la formulación de modelos predictivos o inferenciales. Además, es crucial para descubrir cómo se relacionan las variables entre sí.&lt;/p>
&lt;h2 id="la-regla-de-oro-gigo-garbage-in-garbage-out">La Regla de Oro: GIGO (Garbage In, Garbage Out)&lt;/h2>
&lt;p>Un concepto popular y vital en el campo de la ciencia de datos es &lt;strong>GIGO&lt;/strong> (Garbage In, Garbage Out, o &amp;ldquo;Basura entra, basura sale&amp;rdquo;). Este concepto subraya que la calidad de los resultados de cualquier análisis o modelo es directamente proporcional a la calidad de los datos de entrada. No importa cuán sofisticado sea tu algoritmo o cuán potente sea tu infraestructura computacional, los datos de mala calidad siempre producirán resultados deficientes, engañosos o inútiles. El EDA es nuestra primera línea de defensa contra el GIGO, asegurando que trabajamos con datos limpios y comprensibles.&lt;/p>
&lt;h2 id="un-flujo-de-trabajo-práctico-de-eda">Un Flujo de Trabajo Práctico de EDA&lt;/h2>
&lt;p>Aunque el EDA es un proceso iterativo y no una &amp;ldquo;camisa de fuerza&amp;rdquo; rígida, es útil seguir un flujo de trabajo estructurado para garantizar que cubrimos los aspectos más importantes. El orden de las etapas y el énfasis en cada una dependerán en gran medida del problema específico, el tipo de datos y los objetivos del análisis.&lt;/p>
&lt;p>Este proceso general incluye:&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="flex justify-center ">
&lt;div class="w-100" >&lt;img alt="" srcset="
/posts/2025-02-11-eda/fig01_hu_1d111632709b1b76.webp 400w,
/posts/2025-02-11-eda/fig01_hu_b26fdc398618e3dc.webp 760w,
/posts/2025-02-11-eda/fig01_hu_540748744cda905c.webp 1200w"
src="https://maicel.netlify.app/posts/2025-02-11-eda/fig01_hu_1d111632709b1b76.webp"
width="760"
height="578"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>A continuación, profundicemos en cada una de estas etapas, utilizando ejemplos prácticos con el paquete &lt;code>dlookr&lt;/code> en R.&lt;/p>
&lt;h3 id="1-comprensión-general-de-los-datos-y-evaluación-de-su-calidad">1. Comprensión General de los Datos y Evaluación de su Calidad&lt;/h3>
&lt;p>Antes de sumergirnos en análisis profundos, es fundamental tener una visión panorámica de nuestro conjunto de datos. Esta etapa implica:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Dimensiones del dataset:&lt;/strong> ¿Cuántas filas (observaciones) y columnas (variables) tenemos?&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Tipos de datos:&lt;/strong> ¿Las variables son numéricas (enteros, flotantes), categóricas (factores, caracteres), lógicas o de fecha/hora? Es crucial que los tipos de datos sean correctos para las operaciones que deseamos realizar.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Inspección inicial:&lt;/strong> Revisar las primeras y últimas filas del dataset para obtener una idea general del formato y contenido.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Estadísticas descriptivas básicas:&lt;/strong> Para variables numéricas: media, mediana, desviación estándar, mínimo, máximo, cuartiles. Para variables categóricas: conteo de ocurrencias, proporciones. Esto nos da una primera impresión de la dispersión y centralidad de los datos.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Con &lt;code>dlookr&lt;/code>, la función &lt;code>diagnose()&lt;/code> es ideal para una revisión rápida de la calidad de los datos, mostrando el tipo de variable, el número de valores únicos, valores faltantes, valores cero y valores negativos.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-r" data-lang="r">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Para obtener un resumen rápido de las características de los datos&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">diagnose&lt;/span>(mtcars_na)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Esta fase nos ayuda a formar una primera hipótesis sobre la calidad y estructura de los datos, identificando posibles problemas desde el principio.&lt;/p>
&lt;h4 id="2-identificación-y-tratamiento-de-valores-faltantes-y-atípicos">2. Identificación y Tratamiento de Valores Faltantes y Atípicos&lt;/h4>
&lt;p>Los valores faltantes (NA, NaN, null) y los valores atípicos (outliers) son dos de los desafíos más comunes en cualquier conjunto de datos y pueden distorsionar significativamente los resultados de nuestros análisis y modelos.&lt;/p>
&lt;p>&lt;strong>Valores Faltantes:&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Identificación:&lt;/strong> Cuantificar la cantidad y proporción de valores faltantes por variable. Visualizar patrones de ausencia (¿los valores faltantes ocurren aleatoriamente o hay un patrón?).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Tratamiento:&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Eliminación:&lt;/strong> Si la cantidad de valores faltantes es pequeña o si una variable tiene un porcentaje muy alto de NAs, se pueden eliminar filas o columnas.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Imputación:&lt;/strong> Rellenar los valores faltantes. Métodos comunes incluyen la media, mediana o moda (para datos numéricos y categóricos, respectivamente), o métodos más avanzados basados en modelos (regresión, k-NN, etc.). La elección depende de la naturaleza de los datos y el problema.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Valores Atípicos:&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Identificación:&lt;/strong> Observaciones que se desvían significativamente del resto de los datos. Se pueden detectar mediante gráficos de caja (boxplots), diagramas de dispersión, puntuaciones Z, el método IQR (rango intercuartílico) o algoritmos más sofisticados.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Tratamiento:&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Eliminación:&lt;/strong> Si se confirma que son errores de entrada de datos.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Transformación:&lt;/strong> Aplicar transformaciones logarítmicas o de raíz cuadrada para reducir su impacto.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Capping/Flooring:&lt;/strong> Limitar los valores atípicos a un percentil superior o inferior (por ejemplo, el 99% o el 1%).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Mantener:&lt;/strong> A veces, los valores atípicos son observaciones genuinas e importantes que no deben eliminarse.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;code>dlookr&lt;/code> ofrece funciones visuales y programáticas para abordar estos problemas:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-r" data-lang="r">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Visualizar la distribución de valores faltantes&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">plot_na&lt;/span>(mtcars_na)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Identificar valores atípicos para una variable específica (ej. &amp;#34;hp&amp;#34;)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># plot_outlier() es excelente para visualizar.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">plot_outlier&lt;/span>(mtcars_df, &lt;span style="color:#e6db74">&amp;#34;hp&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="3-análisis-de-la-distribución-de-las-variables">3. Análisis de la Distribución de las Variables&lt;/h3>
&lt;p>Comprender la distribución de cada variable individualmente es clave para seleccionar los métodos estadísticos y de modelado adecuados.&lt;/p>
&lt;p>&lt;strong>Variables Numéricas:&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Histogramas y gráficos de densidad:&lt;/strong> Permiten visualizar la forma de la distribución, identificar asimetrías (skewness), curtosis, y la presencia de múltiples modos.&lt;/li>
&lt;li>&lt;strong>Medidas de asimetría y curtosis:&lt;/strong> Cuantifican la forma de la distribución.&lt;/li>
&lt;li>&lt;strong>Pruebas de normalidad:&lt;/strong> Aunque muchas veces no son estrictamente necesarias, pueden complementar el análisis visual.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Variables Categóricas:&lt;/strong> - &lt;strong>Gráficos de barras:&lt;/strong> Muestran la frecuencia o proporción de cada categoría. - &lt;strong>Tablas de frecuencia:&lt;/strong> Resumen el conteo y porcentaje de cada nivel.&lt;/p>
&lt;p>&lt;code>dlookr&lt;/code> simplifica la visualización de distribuciones:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-r" data-lang="r">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Visualizar la distribución de una variable numérica (ej. &amp;#34;mpg&amp;#34;)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">plot_hist&lt;/span>(mtcars_df, &lt;span style="color:#e6db74">&amp;#34;mpg&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># O ver la distribución y normalidad&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">plot_normality&lt;/span>(mtcars_df, &lt;span style="color:#e6db74">&amp;#34;mpg&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Para variables categóricas (como &amp;#39;cyl&amp;#39; en mtcars que es numérica discreta)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Podemos convertirla a factor para un análisis categórico.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>mtcars_factor_cyl &lt;span style="color:#f92672">&amp;lt;-&lt;/span> mtcars_df &lt;span style="color:#f92672">%&amp;gt;%&lt;/span> &lt;span style="color:#a6e22e">mutate&lt;/span>(cyl &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">as.factor&lt;/span>(cyl))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">plot_bar&lt;/span>(mtcars_factor_cyl, &lt;span style="color:#e6db74">&amp;#34;cyl&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Este análisis nos ayuda a entender el comportamiento de cada característica y a identificar la necesidad de transformaciones futuras.&lt;/p>
&lt;h3 id="4-análisis-de-las-relaciones-entre-las-variables">4. Análisis de las Relaciones entre las Variables&lt;/h3>
&lt;p>Esta etapa se centra en descubrir cómo las variables interactúan entre sí. Es fundamental para la selección de características, la identificación de multicolinealidad y la comprensión de la causalidad (o correlación).&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Dos variables numéricas:&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Diagramas de dispersión (scatter plots):&lt;/strong> Visualizan la dirección y fuerza de la relación (positiva, negativa, nula, no lineal).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Coeficientes de correlación (Pearson, Spearman):&lt;/strong> Cuantifican la fuerza y dirección de la relación lineal (Pearson) o monótona (Spearman).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Una variable numérica y una categórica:&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Gráficos de caja (boxplots) o gráficos de violín:&lt;/strong> Comparan la distribución de la variable numérica entre las diferentes categorías.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Pruebas t de Student o ANOVA:&lt;/strong> Para determinar si hay diferencias estadísticamente significativas en las medias.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Dos variables categóricas:&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Tablas de contingencia y gráficos de barras apiladas/agrupadas:&lt;/strong> Muestran la distribución conjunta.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Pruebas de significación:&lt;/strong> Para evaluar la independencia entre las variables.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Matrices de correlación:&lt;/strong> Visualizan las correlaciones entre múltiples variables numéricas simultáneamente, a menudo con mapas de calor (heatmaps).&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;code>dlookr&lt;/code> facilita la exploración de relaciones:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-r" data-lang="r">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Visualizar la matriz de correlación entre todas las variables numéricas&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">plot_cor&lt;/span>(mtcars_df)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Analizar la relación entre una variable objetivo (&amp;#39;mpg&amp;#39;) y otra característica (&amp;#39;wt&amp;#39;)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># plot_eda() permite explorar diversas relaciones bivariadas.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">plot_eda&lt;/span>(mtcars_df, target &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;mpg&amp;#34;&lt;/span>, feature &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;wt&amp;#34;&lt;/span>) &lt;span style="color:#75715e"># Numérica vs Numérica (scatterplot)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Relación entre &amp;#39;mpg&amp;#39; (numérica) y &amp;#39;cyl&amp;#39; (considerada categórica aquí)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">plot_eda&lt;/span>(mtcars_df, target &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;mpg&amp;#34;&lt;/span>, feature &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;cyl&amp;#34;&lt;/span>) &lt;span style="color:#75715e"># Numérica vs Categórica (boxplot)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="5-transformación-de-los-datos">5. Transformación de los Datos&lt;/h3>
&lt;p>Una vez que hemos comprendido nuestros datos, es posible que necesitemos transformarlos para que sean más adecuados para los algoritmos de machine learning o para mejorar el rendimiento del modelo.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Manejo de asimetría:&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Transformaciones logarítmicas, de raíz cuadrada o de Box-Cox:&lt;/strong> Pueden normalizar distribuciones sesgadas, reduciendo la influencia de valores extremos.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Escalado de características:&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Normalización (Min-Max Scaling):&lt;/strong> Escala los datos a un rango fijo (por ejemplo, [0, 1]). Útil para algoritmos sensibles a la escala como SVM o redes neuronales.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Estandarización (Z-score Scaling):&lt;/strong> Transforma los datos para que tengan una media de 0 y una desviación estándar de 1. Es común en algoritmos basados en distancia (k-NN, K-Means, PCA).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Codificación de variables categóricas:&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>One-Hot Encoding:&lt;/strong> Convierte variables categóricas en múltiples columnas binarias, una por cada categoría. Esencial para algoritmos que solo trabajan con entradas numéricas.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Label Encoding:&lt;/strong> Asigna un número entero a cada categoría. Útil si hay un orden inherente en las categorías.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Ingeniería de Características (Feature Engineering):&lt;/strong> Crear nuevas variables a partir de las existentes. Esto puede ser tan simple como combinar dos columnas o tan complejo como extraer información de texto o imágenes. Esta etapa es a menudo la que más impacto tiene en el rendimiento del modelo.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;code>dlookr&lt;/code> ofrece funciones útiles para la transformación de datos:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-r" data-lang="r">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Transformación logarítmica para reducir la asimetría de una variable&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>mtcars_transformed_log &lt;span style="color:#f92672">&amp;lt;-&lt;/span> &lt;span style="color:#a6e22e">transform_df&lt;/span>(mtcars_df, mpg &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">log&lt;/span>(mpg))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Compara la distribución de mpg original vs. transformada&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">plot_normality&lt;/span>(mtcars_df, &lt;span style="color:#e6db74">&amp;#34;mpg&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">plot_normality&lt;/span>(mtcars_transformed_log, &lt;span style="color:#e6db74">&amp;#34;mpg&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Binarización o discretización de una variable continua (ej. &amp;#39;hp&amp;#39; en 3 bins)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>mtcars_binned &lt;span style="color:#f92672">&amp;lt;-&lt;/span> &lt;span style="color:#a6e22e">binning&lt;/span>(mtcars_df, &lt;span style="color:#e6db74">&amp;#34;hp&amp;#34;&lt;/span>, n &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">3&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">head&lt;/span>(mtcars_binned &lt;span style="color:#f92672">%&amp;gt;%&lt;/span> &lt;span style="color:#a6e22e">select&lt;/span>(hp, hp_Binned))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Estandarización de variables numéricas (Z-score)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>mtcars_scaled &lt;span style="color:#f92672">&amp;lt;-&lt;/span> &lt;span style="color:#a6e22e">normalize&lt;/span>(mtcars_df, method &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;scale&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">head&lt;/span>(mtcars_scaled) &lt;span style="color:#75715e"># Observa cómo los valores de todas las columnas han cambiado&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="herramientas-populares-para-eda">Herramientas Populares para EDA&lt;/h2>
&lt;p>Para realizar un EDA efectivo, contamos con potentes herramientas en lenguajes como R y Python:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>En R:&lt;/strong>
&lt;ul>
&lt;li>El ecosistema &lt;code>tidyverse&lt;/code> (&lt;code>dplyr&lt;/code> para manipulación, &lt;code>ggplot2&lt;/code> para visualización) es indispensable.&lt;/li>
&lt;li>Paquetes específicos para EDA como &lt;strong>&lt;code>dlookr&lt;/code>&lt;/strong>, es excelente por su enfoque estructurado en el diagnóstico de calidad, exploración y transformación de datos, ofreciendo funciones y reportes automatizados que agilizan el proceso. Otros paquetes útiles incluyen &lt;code>DataExplorer&lt;/code>, &lt;code>skimr&lt;/code>, y &lt;code>visdat&lt;/code>.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>En Python:&lt;/strong>
&lt;ul>
&lt;li>&lt;code>pandas&lt;/code> para manipulación de datos.&lt;/li>
&lt;li>&lt;code>matplotlib&lt;/code> y &lt;code>seaborn&lt;/code> para visualización estática.&lt;/li>
&lt;li>&lt;code>plotly&lt;/code> para visualizaciones interactivas.&lt;/li>
&lt;li>Bibliotecas como &lt;code>missingno&lt;/code> para visualizar valores faltantes, &lt;code>pandas_profiling&lt;/code> para informes automáticos de EDA, y &lt;code>sweetviz&lt;/code> para comparaciones.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="conclusión">Conclusión&lt;/h2>
&lt;p>El Análisis Exploratorio de Datos no es solo una fase inicial, sino un proceso continuo de aprendizaje sobre tus datos. Es una inversión de tiempo que rinde grandes dividendos, ya que una comprensión profunda de los datos nos permite tomar decisiones más informadas, construir modelos más robustos y, en última instancia, extraer conocimientos más valiosos. Al dominar el EDA, te equipas con la habilidad de transformar datos brutos en una historia coherente y accionable, evitando la trampa del GIGO y asegurando que tus esfuerzos de ciencia de datos generen un impacto real.&lt;/p></description></item><item><title>Cómo entrenar y validar un modelo de predicción clínica</title><link>https://maicel.netlify.app/posts/2025-02-08-como-entrenar-y-validar-un-modelo-de-machine-learnig/</link><pubDate>Thu, 08 Feb 2024 00:00:00 +0000</pubDate><guid>https://maicel.netlify.app/posts/2025-02-08-como-entrenar-y-validar-un-modelo-de-machine-learnig/</guid><description>&lt;p>🎧 &lt;strong>Escucha el podcast de esta publicación&lt;/strong>&lt;/p>
&lt;audio controls >
&lt;source src="https://ia600607.us.archive.org/24/items/articulo-steyember/_Articulo_Steyember.mp3" type="audio/mpeg">
&lt;/audio>
&lt;p>Si usted es un investigador en salud, estudiante de posgrado, maestría o doctorado en el campo de las ciencias biomédicas, y quiere enfocar su trabajo en el desarrollo de &lt;strong>modelos de predicción clínica&lt;/strong> para el &lt;strong>diagnóstico&lt;/strong> o el &lt;strong>pronóstico&lt;/strong>, es probable que haya llegado a la fase donde la metodología se vuelve un muro. No conoce qué pasos seguir, qué software utilizar o, después de meses de trabajo, existen dudas sobre su utilidad en contextos diferentes a los que fue creado.&lt;/p>
&lt;p>Hoy en día, muchas tesis de alto nivel giran en torno a la creación de modelos de predicción clínica (usando técnicas de regresiones avanzadas o Machine Learning).&lt;/p>
&lt;p>Este post es su traductor metodológico y un tutorial. Muestro algunos consejos sobre cómo hacer un modelo predictivo y algunas experiencias que yo mismo pasé en mi tesis de doctorado.&lt;/p>
&lt;p>Olvídese del código críptico y céntrese en la lógica: vamos a desglosar los siete pasos cruciales del método Steyerberg para que su modelo predictivo sea robusto, confiable y publicable. Deje de sentir dolor con la estadística; convierta su modelo en una herramienta clínica útil.&lt;/p>
&lt;h1 id="estrategia-de-modelado">Estrategia de modelado&lt;/h1>
&lt;p>Contar con una estrategia de modelado correcta es esencial para desarrollar y validar modelos de predicción. En este artículo, exploraremos las siete etapas clave del proceso de modelado propuesto por Ewout Steyerberg en su artículo (1).&lt;/p>
&lt;h2 id="sec-1">1. Definición del problema e inspección de datos&lt;/h2>
&lt;p>El primer paso en cualquier proyecto de modelado es &lt;strong>definir claramente el problema de investigación&lt;/strong> y seleccionar la &lt;strong>variable de resultado&lt;/strong> adecuada.&lt;/p>
&lt;div class="flex px-4 py-3 mb-6 rounded-md bg-primary-100 dark:bg-primary-900">
&lt;span class="pr-3 pt-1 text-primary-600 dark:text-primary-300">
&lt;svg height="24" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">&lt;path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z"/>&lt;/svg>
&lt;/span>
&lt;span class="dark:text-neutral-300">&lt;h3 id="variable-de-resultado">Variable de resultado&lt;/h3>
&lt;p>La &lt;strong>variable de resultado&lt;/strong> debe definirse con precisión: especifica &lt;strong>qué evento se predice&lt;/strong>, &lt;strong>cómo y cuándo se mide&lt;/strong>, y el &lt;strong>horizonte temporal de predicción&lt;/strong> (por ejemplo, mortalidad a 30 días). Indica además el método de evaluación y si hubo &lt;strong>cegamiento&lt;/strong> respecto a los predictores, para garantizar coherencia y validez del modelo.&lt;/p>&lt;/span>
&lt;/div>
&lt;p>Durante esta fase, también realizamos un análisis exploratorio de datos (EDA) para comprender las características de las variables y detectar posibles problemas, como &lt;strong>datos atípicos&lt;/strong> o &lt;strong>valores faltantes&lt;/strong>.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-r" data-lang="r">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Realiza una descripción general del conjunto de datos&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Instala y Carga de Librerías útiles &lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">library&lt;/span>(caret)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">library&lt;/span>(MLDataR) &lt;span style="color:#75715e"># para utilizar la biblioteca diabetes_data&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">library&lt;/span>(dplyr)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">library&lt;/span>(dlookr) &lt;span style="color:#75715e"># para EDA&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">library&lt;/span>(predtools)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Cargar el conjunto de datos&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">data&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;gusto&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>gusto &lt;span style="color:#f92672">&amp;lt;-&lt;/span> gusto
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># EDA&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>descripcion &lt;span style="color:#f92672">&amp;lt;-&lt;/span> &lt;span style="color:#a6e22e">overview&lt;/span>(gusto)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">summary&lt;/span>(descripcion) &lt;span style="color:#75715e"># descripción general del conjunto de datos&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;!-- Para conocer más detalles sobre el proceso de ¨Exploratory Data Analysis (EDA)¨ [ver la publicación dedicada a este tema](es/post/2025-02-11-eda/_index.Rmd) -->
&lt;h2 id="sec-2">2. Codificación de las variables predictoras&lt;/h2>
&lt;p>La &lt;strong>codificación&lt;/strong> adecuada de las &lt;strong>variables predictoras&lt;/strong> es fundamental para construir modelos robustos.&lt;/p>
&lt;p>Es probable que debas utilizar técnicas como la agrupación de categorías poco frecuentes y la creación de predictores resúmenes para simplificar información correlacionada. Además, cuando las relaciones entre variables no son lineales, aplicamos herramientas como &lt;strong>splines cúbicos restringidos&lt;/strong> , que permiten capturar patrones complejos sin comprometer la precisión del modelo.&lt;/p>
&lt;p>Dicotomizar predictores cuantitativos (por ejemplo, transformar una variable continua como la edad o la presión arterial en una variable binaria, como “≥65 años = 1” y “&amp;lt;65 = 0”) es considerada una mala práctica metodológica.&lt;/p>
&lt;h2 id="sec-3">3 .Especificación del tipo de modelo&lt;/h2>
&lt;p>La elección del modelo depende del tipo de relación que queremos capturar entre las variables.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="flex justify-center ">
&lt;div class="w-100" >&lt;img alt="" srcset="
/posts/2025-02-08-como-entrenar-y-validar-un-modelo-de-machine-learnig/modelos_elecion_hu_8c0e0341cce17729.webp 400w,
/posts/2025-02-08-como-entrenar-y-validar-un-modelo-de-machine-learnig/modelos_elecion_hu_7b91ac5dc10d2f43.webp 760w,
/posts/2025-02-08-como-entrenar-y-validar-un-modelo-de-machine-learnig/modelos_elecion_hu_e3e07ff54d991fd6.webp 1200w"
src="https://maicel.netlify.app/posts/2025-02-08-como-entrenar-y-validar-un-modelo-de-machine-learnig/modelos_elecion_hu_8c0e0341cce17729.webp"
width="760"
height="507"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Un aspecto clave es la selección de predictores finales para lo que se emplean varios métodos. Sin embargo, la aplicación mecánica de métodos algorítmicos tradicionales, como la Regresión Paso a Paso (RPP), ha demostrado ser inconsistente y poco robusta, especialmente en el contexto de las aplicaciones biomédicas y sociales.&lt;/p>
&lt;h2 id="sec-4">4. Estimación del Modelo&lt;/h2>
&lt;p>El paso de estimación del modelo es un componente central del desarrollo de modelos predictivos, orientado a obtener los parámetros o estructuras que mejor expliquen los datos de entrenamiento. Su propósito es equilibrar el ajuste al conjunto de datos con la capacidad del modelo para generalizar a nuevas observaciones.&lt;/p>
&lt;p>La regularización es una estrategia clave dentro de este proceso, diseñada para reducir el sobreajuste (overfitting) mediante la introducción controlada de sesgo que estabiliza las predicciones.&lt;/p>
&lt;p>Modelos paramétricos (p. ej., regresión): emplean técnicas de contracción o shrinkage (como LASSO o Ridge regression) que aplican una penalización sobre los coeficientes estimados —basados en máxima verosimilitud penalizada—, reduciendo la varianza y evitando predicciones extremas.&lt;/p>
&lt;p>Modelos de machine learning (p. ej., XGBoost, SVM, Random Forest): utilizan la optimización de hiperparámetros (como la tasa de aprendizaje, el parámetro C o la profundidad de los árboles) para controlar la complejidad del modelo. Estos ajustes inducen un sesgo controlado que mejora la validez externa y la estabilidad predictiva frente a nuevos datos.&lt;/p>
&lt;p>En conjunto, la estimación y la regularización contribuyen a lograr un modelo más robusto y generalizable, especialmente cuando se combinan con una validación interna adecuada (como cross-validation o bootstrap).&lt;/p>
&lt;h2 id="sec-5">5. Evaluación del Rendimiento del Modelo&lt;/h2>
&lt;p>El rendimiento del modelo se evalúa mediante métricas como calibración y discriminación . La calibración mide la concordancia entre las predicciones y los resultados observados, mientras que la discriminación evalúa la capacidad del modelo para distinguir entre pacientes con diferentes resultados. Herramientas como las rectas de calibración y la validación cruzada de 10 pliegues fueron fundamentales para asegurar la calidad del modelo.&lt;/p>
&lt;h2 id="sec-6">6. Evaluación de la Validez del Modelo&lt;/h2>
&lt;p>La validación del modelo es un paso crítico para garantizar su aplicabilidad en diferentes contextos. En este estudio, utilizamos tanto validación interna como externa , empleando particiones temporales y geográficas para reflejar escenarios reales. Este enfoque nos permitió evaluar la robustez del modelo frente a cambios en el tiempo y variaciones regionales.&lt;/p>
&lt;h2 id="sec-7">7. Presentación del modelo&lt;/h2>
&lt;p>La presentación efectiva es crucial para la adopción clínica. Un modelo perfecto es inútil si los médicos no pueden interpretarlo fácilmente. Considera:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Nomogramas&lt;/strong>: Ideales para uso rápido en consulta&lt;/li>
&lt;li>&lt;strong>Aplicaciones web/móviles&lt;/strong>: Para integración en flujos de trabajo clínicos&lt;/li>
&lt;li>&lt;strong>Puntuaciones de riesgo&lt;/strong>: Simplificadas para triaje rápido&lt;/li>
&lt;li>&lt;strong>Documentación clara&lt;/strong>: Incluyendo limitaciones y casos de uso&lt;/li>
&lt;/ul>
&lt;p>Recuerda: la transparencia en la presentación favorece la confianza clínica.&lt;/p>
&lt;p>¿Has aplicado estas técnicas en tus proyectos de Machine Learning? ¿Qué estrategias usas para entrenar y validar tus modelos? Déjame tus comentarios 💬: comparte tus experiencias, dificultades o tips contigo. ¡Juntos podemos enriquecer este conocimiento!&lt;/p>
&lt;h1 id="bibliografía">Bibliografía&lt;/h1>
&lt;ol>
&lt;li>Steyerberg EW, Vergouwe Y. Towards better clinical prediction models: seven steps for development and an ABCD for validation. European Heart Journal [Internet]. 1 de agosto de 2014 [citado 9 de mayo de 2021];35(29):1925-31. Disponible en: &lt;a href="https://academic.oup.com/eurheartj/article-lookup/doi/10.1093/eurheartj/ehu207" target="_blank" rel="noopener">https://academic.oup.com/eurheartj/article-lookup/doi/10.1093/eurheartj/ehu207&lt;/a>&lt;/li>
&lt;/ol></description></item></channel></rss>