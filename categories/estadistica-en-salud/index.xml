<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Estadística en Salud | Bioestadística edu</title><link>https://maicel.netlify.app/categories/estadistica-en-salud/</link><atom:link href="https://maicel.netlify.app/categories/estadistica-en-salud/index.xml" rel="self" type="application/rss+xml"/><description>Estadística en Salud</description><generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>es-es</language><lastBuildDate>Wed, 24 Sep 2025 00:00:00 +0000</lastBuildDate><image><url>https://maicel.netlify.app/media/icon_hu_551fbaee136b383e.png</url><title>Estadística en Salud</title><link>https://maicel.netlify.app/categories/estadistica-en-salud/</link></image><item><title>Las trampas de la correlación disfrazada de causalidad</title><link>https://maicel.netlify.app/posts/2025-09-24-correlacionvscausalidad/</link><pubDate>Wed, 24 Sep 2025 00:00:00 +0000</pubDate><guid>https://maicel.netlify.app/posts/2025-09-24-correlacionvscausalidad/</guid><description>&lt;p>El ojo humano ama los patrones: ver dos líneas que se mueven juntas y concluir que una provoca la otra. La estadística, mal interpretada, a veces alimenta esa ilusión. La correlación es apenas la danza conjunta de dos variables, no una flecha de causa. Y, sin embargo, titulares, políticas y hasta decisiones médicas se sostienen sobre esta trampa.&lt;/p>
&lt;h1 id="1-correlaciones-curiosas-pero-falsas">1) Correlaciones curiosas (pero falsas)&lt;/h1>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Helados y ahogamientos.&lt;/strong> En verano, ambos aumentan. No porque el helado mate, sino porque el calor atrae bañistas y heladeros.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Cigüeñas y natalidad.&lt;/strong> En pueblos europeos, donde hay más cigüeñas, también hay más nacimientos… simplemente porque se trata de áreas rurales más fértiles, no porque las aves traigan bebés.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Películas de Nicolas Cage y ahogamientos en piscinas.&lt;/strong> Ejemplo clásico de correlaciones espurias recopiladas por Tyler Vigen: cómico, pero ilustrativo.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="2-la-correlación-y-su-impacto-en-la-toma-de-decisiones">2) La correlación y su impacto en la toma de decisiones&lt;/h2>
&lt;p>La confusión entre causalidad y correlación no es solo un chiste; tiene consecuencias graves.&lt;/p>
&lt;p>&lt;strong>Política pública:&lt;/strong> Un estudio muestra que los países con más médicos per cápita tienen más diagnósticos de cáncer. Conclusión errada: “los médicos causan cáncer”. Realidad: mayor densidad médica implica mejor detección.&lt;/p>
&lt;p>&lt;strong>Falacia de la causa inversa:&lt;/strong> Niños con bajo rendimiento escolar pasan más horas frente a la televisión. ¿La TV los perjudica? ¿O los niños con dificultades recurren más a ella? La dirección de la causalidad puede invertirse fácilmente.&lt;/p>
&lt;hr>
&lt;h1 id="3-qué-mide-realmente-la-correlación">3) &lt;strong>¿Qué mide realmente la correlación?&lt;/strong>&lt;/h1>
&lt;ul>
&lt;li>El &lt;strong>coeficiente de correlación (r)&lt;/strong> mide la fuerza y dirección de la relación entre dos variables.&lt;/li>
&lt;li>Sus valores van de &lt;strong>-1 a +1&lt;/strong>:
&lt;ul>
&lt;li>+1 → relación positiva perfecta&lt;/li>
&lt;li>-1 → relación negativa perfecta&lt;/li>
&lt;li>0 → ausencia de relación lineal&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;div class="flex px-4 py-3 mb-6 rounded-md bg-primary-100 dark:bg-primary-900">
&lt;span class="pr-3 pt-1 text-primary-600 dark:text-primary-300">
&lt;svg height="24" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">&lt;path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z"/>&lt;/svg>
&lt;/span>
&lt;span class="dark:text-neutral-300">&lt;strong>Advertencia:&lt;/strong> un r alto no significa causalidad. Puede deberse a &lt;strong>confusores&lt;/strong>, &lt;strong>azar&lt;/strong> o &lt;strong>causalidad inversa&lt;/strong>.&lt;/span>
&lt;/div>
&lt;hr>
&lt;h1 id="4-tipos-de-coeficientes-de-correlación-más-allá-de-pearson">4) Tipos de coeficientes de correlación (más allá de Pearson)&lt;/h1>
&lt;p>
&lt;figure >
&lt;div class="flex justify-center ">
&lt;div class="w-100" >&lt;img alt="" srcset="
/posts/2025-09-24-correlacionvscausalidad/correlacion_hu_c614a73ad03379b6.webp 400w,
/posts/2025-09-24-correlacionvscausalidad/correlacion_hu_e6f9def3a13f9eea.webp 760w,
/posts/2025-09-24-correlacionvscausalidad/correlacion_hu_dedc904516865376.webp 1200w"
src="https://maicel.netlify.app/posts/2025-09-24-correlacionvscausalidad/correlacion_hu_c614a73ad03379b6.webp"
width="507"
height="760"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;hr>
&lt;h1 id="5-causalidad-un-desafío-que-exige-rigurosidad">5) &lt;strong>Causalidad:&lt;/strong> un desafío que exige rigurosidad&lt;/h1>
&lt;p>Identificar la causalidad no se improvisa. Requiere algo más que una simple correlación. Exige un diseño experimental riguroso, criterios de Bradford Hill y construcción de modelos causales. La estadística sugiere, pero no prueba por sí sola.&lt;/p>
&lt;hr>
&lt;h1 id="6-metáfora-para-recordar">6) Metáfora para recordar&lt;/h1>
&lt;p>Piensa en la correlación como ver dos hojas que caen juntas en otoño. Creer que una arrastra a la otra es ignorar el viento invisible que las mueve a ambas.&lt;/p>
&lt;hr>
&lt;h1 id="7-checklist-para-evitar-caer-en-la-trampa">7) Checklist para evitar caer en la trampa&lt;/h1>
&lt;ol>
&lt;li>¿Existe una variable oculta (confusor) que explique la relación? ✔&lt;/li>
&lt;li>¿Podría la causalidad ir en sentido contrario? ✔&lt;/li>
&lt;li>¿El diseño permite concluir causa o solo asociación? ✔&lt;/li>
&lt;li>¿Hay criterios teóricos/experimentales que respalden esta relación? ✔&lt;/li>
&lt;li>¿Se comunicó claramente que es correlación, no causalidad? ✔&lt;/li>
&lt;/ol>
&lt;hr>
&lt;h1 id="bibliografía">Bibliografía&lt;/h1>
&lt;p>Silva Aycaguer LC. &lt;em>Cultura estadística e investigación científica en el campo de la salud: una mirada crítica&lt;/em>. Madrid: Díaz de Santos; 1998.&lt;/p>
&lt;p>Pearl, J. (2009). Causality: Models, Reasoning, and Inference (2nd ed.). Cambridge University Press.&lt;/p>
&lt;p>Hernán, M. A., &amp;amp; Robins, J. M. (2020). Causal Inference: What If. Chapman &amp;amp; Hall/CRC. [Disponible gratis en línea].&lt;/p>
&lt;p>Hill, A. B. (1965). The environment and disease: association or causation? Proceedings of the Royal Society of Medicine, 58(5), 295–300. (Criterios de Bradford Hill).&lt;/p>
&lt;p>Freedman, D. A. (2005). Statistical Models: Theory and Practice. Cambridge University Press. (Discusión crítica sobre correlación y causalidad).&lt;/p></description></item><item><title>Desvelando la Lógica Matemática Detrás de Causa y Efecto</title><link>https://maicel.netlify.app/posts/2025-09-01-m-s-all-del-rct-en-salud-p-blica-y-epidemiolog-a/</link><pubDate>Mon, 01 Sep 2025 00:00:00 +0000</pubDate><guid>https://maicel.netlify.app/posts/2025-09-01-m-s-all-del-rct-en-salud-p-blica-y-epidemiolog-a/</guid><description>&lt;h1 id="inferencia-causal-">Inferencia Causal :&lt;/h1>
&lt;p>El &lt;strong>marco de resultados potenciales&lt;/strong> se mantiene como la piedra angular del pensamiento causal, proporcionando el andamiaje conceptual para diferenciar la mera correlación de la causalidad. Ante la imposibilidad de llevar a cabo &lt;strong>ensayos controlados aleatorizados (RCT)&lt;/strong>, la investigación se ha nutrido de &lt;strong>métodos robustos&lt;/strong> que permiten extraer inferencias causales creíbles de datos observacionales. En este contexto, herramientas como el &lt;strong>Propensity Score&lt;/strong> y los &lt;strong>estimadores doblemente robustos&lt;/strong> (DR) se utilizan para controlar los sesgos de selección a partir de covariables observables, mientras que los &lt;strong>Efectos de Tratamiento Promedio Condicionales (CATE)&lt;/strong>, apoyados en machine learning, permiten explorar la heterogeneidad del efecto entre subpoblaciones. Asimismo, un conjunto de estrategias cuasi-experimentales ha abierto nuevos horizontes en la investigación, incluyendo el uso de &lt;strong>Variables Instrumentales (IV)&lt;/strong> para corregir la confusión no observada, el &lt;strong>Diferencias-en-Diferencias (DID)&lt;/strong> y el &lt;strong>Control Sintético (SC)&lt;/strong> para comparar trayectorias temporales, y la &lt;strong>Regresión Discontinua (RDD)&lt;/strong> para explotar umbrales de asignación, todas ellas permitiendo identificar efectos causales en contextos donde la aleatorización no es factible.&lt;/p>
&lt;hr>
&lt;h2 id="1-el-desafío-central-solo-vemos-un-lado-de-la-moneda">1. El desafío central: solo vemos un lado de la moneda&lt;/h2>
&lt;p>Imagina que quieres evaluar el impacto de una nueva política de vacunación. Para cada persona, podríamos definir dos mundos posibles: uno donde recibe la vacuna y otro donde no. Pero en la práctica solo observamos un mundo: el que ocurrió. Ese es el &lt;strong>“problema fundamental de la inferencia causal”&lt;/strong>.&lt;/p>
&lt;p>El &lt;strong>marco de resultados potenciales&lt;/strong> formaliza esta idea:&lt;/p>
$$
\tau_{\text{sample}} = \frac{1}{N} \sum_{i=1}^{N} (Y_i(1) - Y_i(0))
$$
&lt;p>En un ensayo controlado aleatorizado (RCT), la aleatorización nos permite estimar este efecto promedio simplemente comparando medias. Pero ¿qué pasa cuando los RCT no son factibles por razones éticas, logísticas o económicas?&lt;/p>
&lt;hr>
&lt;h2 id="2-estudios-observacionales-cuando-no-hay-azar-pero-sí-ingenio">2. Estudios observacionales: cuando no hay azar, pero sí ingenio&lt;/h2>
&lt;p>En contextos reales —salud pública, economía, políticas sociales— dependemos de datos observacionales. Allí, la clave es suponer que, condicional en ciertas variables previas ($X_i$), la asignación al tratamiento es “tan buena como aleatoria”.&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Propensity Score (Rosenbaum &amp;amp; Rubin, 1983):&lt;/strong> condensa múltiples covariables en una única probabilidad de recibir tratamiento, facilitando el emparejamiento y la ponderación.&lt;/li>
&lt;li>&lt;strong>Estimadores doblemente robustos:&lt;/strong> combinan modelos de resultado y de asignación al tratamiento; basta con que uno esté bien especificado para obtener estimaciones consistentes.&lt;/li>
&lt;li>&lt;strong>CATE (Conditional Average Treatment Effect):&lt;/strong> con machine learning, hoy podemos explorar cómo los efectos varían entre subpoblaciones (ej. políticas de empleo más efectivas en jóvenes que en adultos mayores).&lt;/li>
&lt;/ul>
&lt;p>⚠️ Cuando sospechamos de confusión no observada, entran en juego &lt;strong>análisis de sensibilidad&lt;/strong> (Manski bounds, métodos de Rosenbaum).&lt;/p>
&lt;hr>
&lt;h2 id="3-estrategias-avanzadas-cuando-la-confusión-no-puede-ignorarse">3. Estrategias avanzadas cuando la confusión no puede ignorarse&lt;/h2>
&lt;h3 id="a-variables-instrumentales-iv">a) Variables Instrumentales (IV)&lt;/h3>
&lt;p>Si un confusor no observado afecta tanto al tratamiento como al resultado, un &lt;strong>instrumento válido&lt;/strong> ($Z$) puede rescatar el análisis. Ejemplo clásico: la distancia a una universidad como instrumento para estudiar el impacto de la educación en ingresos.&lt;/p>
&lt;p>Bajo ciertos supuestos, identificamos el &lt;strong>LATE (Local Average Treatment Effect)&lt;/strong> para quienes cambian su estado de tratamiento debido al instrumento.&lt;/p>
&lt;hr>
&lt;h3 id="b-diferencias-en-diferencias-did-y-control-sintético-sc">b) Diferencias-en-Diferencias (DID) y Control Sintético (SC)&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>DID&lt;/strong>: compara tendencias pre y post en grupos tratados y no tratados. Ejemplo: medir el impacto de un aumento del salario mínimo sobre el empleo.&lt;/li>
&lt;li>&lt;strong>SC&lt;/strong>: construye un “gemelo sintético” de la unidad tratada combinando unidades no tratadas. Ejemplo: evaluar el impacto de una ley antitabaco en California comparando con un control sintético formado por otros estados.&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h3 id="c-regresión-discontinua-rdd">c) Regresión Discontinua (RDD)&lt;/h3>
&lt;p>Aprovecha umbrales de asignación. Ejemplo: un programa de becas asignado a estudiantes con notas ≥ 8.0. Comparar resultados justo por encima y por debajo del corte estima el efecto del programa en los “marginales”.&lt;/p>
&lt;hr>
&lt;h2 id="4-horizontes-emergentes-combinar-evidencia">4. Horizontes emergentes: combinar evidencia&lt;/h2>
&lt;p>Dos líneas prometedoras:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Surrogacy:&lt;/strong> usar resultados a corto plazo como sustitutos de resultados de largo plazo.&lt;/li>
&lt;li>&lt;strong>Integración de experimentos y observacionales:&lt;/strong> Athey et al. (2020) proponen usar experimentos para identificar y corregir confusores en estudios observacionales.&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="-tabla-comparativa-de-métodos-de-inferencia-causal">📊 Tabla comparativa de métodos de inferencia causal&lt;/h2>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Método&lt;/th>
&lt;th>Supuesto clave&lt;/th>
&lt;th>Ventajas&lt;/th>
&lt;th>Limitaciones&lt;/th>
&lt;th>Ejemplo típico&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;strong>RCT&lt;/strong>&lt;/td>
&lt;td>Asignación aleatoria&lt;/td>
&lt;td>Estimador insesgado, alta validez interna&lt;/td>
&lt;td>Costoso, a veces poco ético, baja validez externa&lt;/td>
&lt;td>Ensayo clínico de un fármaco&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Propensity Score / DR&lt;/strong>&lt;/td>
&lt;td>Confusión controlada por covariables observadas&lt;/td>
&lt;td>Flexibilidad, usa datos observacionales grandes&lt;/td>
&lt;td>Vulnerable a confusión no observada&lt;/td>
&lt;td>Impacto de programas sociales&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>IV&lt;/strong>&lt;/td>
&lt;td>Relevancia + exclusión + exogeneidad&lt;/td>
&lt;td>Corrige confusión no observada&lt;/td>
&lt;td>Difícil encontrar instrumentos válidos&lt;/td>
&lt;td>Educación → ingresos&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>DID&lt;/strong>&lt;/td>
&lt;td>Tendencias paralelas&lt;/td>
&lt;td>Simple, interpretable&lt;/td>
&lt;td>Frágil si tendencias difieren&lt;/td>
&lt;td>Políticas laborales&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>SC&lt;/strong>&lt;/td>
&lt;td>Unidades control combinan bien la pre-tendencia&lt;/td>
&lt;td>Más creíble que DID en casos individuales&lt;/td>
&lt;td>Requiere datos ricos pre-tratamiento&lt;/td>
&lt;td>Leyes de salud pública&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>RDD&lt;/strong>&lt;/td>
&lt;td>Continuidad de potenciales en el umbral&lt;/td>
&lt;td>Interpretación clara, diseño cuasi-experimental&lt;/td>
&lt;td>Válido solo cerca del umbral&lt;/td>
&lt;td>Programas de becas&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;hr>
&lt;h2 id="5-conclusión-práctica">5. Conclusión práctica&lt;/h2>
&lt;p>La inferencia causal no es una caja negra: es un conjunto de &lt;strong>herramientas matemáticas y conceptuales&lt;/strong> que, bien aplicadas, permiten a responsables de políticas, clínicos y científicos sociales responder la pregunta clave: &lt;em>¿qué pasaría si?&lt;/em>&lt;/p>
&lt;p>La frontera actual está en combinar evidencia, explotar machine learning para heterogeneidad y desarrollar métodos más robustos frente a confusión no observada.&lt;/p>
&lt;hr>
&lt;h2 id="-referencias-recomendadas">📚 Referencias recomendadas&lt;/h2>
&lt;ul>
&lt;li>Rosenbaum PR, Rubin DB. &lt;em>The central role of the propensity score…&lt;/em> Biometrika. 1983. &lt;a href="https://pubmed.ncbi.nlm.nih.gov/12009849/" target="_blank" rel="noopener">PubMed PMID: 12009849&lt;/a>&lt;/li>
&lt;li>Hernán MA, Robins JM. &lt;em>Causal Inference: What If&lt;/em>. 2020. &lt;a href="https://pubmed.ncbi.nlm.nih.gov/33290294/" target="_blank" rel="noopener">PubMed PMID: 33290294&lt;/a>&lt;/li>
&lt;li>Imbens GW, Rubin DB. &lt;em>Causal Inference for Statistics, Social, and Biomedical Sciences&lt;/em>. 2015.&lt;/li>
&lt;li>Athey S, Imbens GW. &lt;em>Design-based analysis in difference-in-differences settings.&lt;/em> J Econometrics. 2022. &lt;a href="https://pubmed.ncbi.nlm.nih.gov/36212825/" target="_blank" rel="noopener">PubMed PMID: 36212825&lt;/a>&lt;/li>
&lt;li>Abadie A. &lt;em>Using synthetic controls.&lt;/em> J Econometrics. 2021.&lt;/li>
&lt;/ul></description></item><item><title>Ciencia o Pirotecnia: Por Qué la 'Significación Estadística' Nos Ciega con Falsos Destellos</title><link>https://maicel.netlify.app/posts/2025-08-10-significacion/</link><pubDate>Sun, 10 Aug 2025 15:30:00 +0000</pubDate><guid>https://maicel.netlify.app/posts/2025-08-10-significacion/</guid><description>&lt;p>Ese momento de euforia al ver &lt;code>p &amp;lt; 0.05&lt;/code>… ¿es un descubrimiento genuino o solo un destello engañoso de pirotecnia estadística?&lt;/p>
&lt;p>En la ciencia, hay un instante que todos los investigadores anhelan. Es la culminación de meses, a veces años, de riguroso trabajo. Corres el análisis y, de repente, ahí está: &lt;code>p &amp;lt; 0.05&lt;/code>. Es una &lt;strong>explosión de alivio&lt;/strong>, un destello de “¡Eureka!” en la oscuridad de la incertidumbre. Sentimos que hemos encontrado algo real, algo digno de ser publicado.&lt;/p>
&lt;p>Pero, ¿y si ese destello es solo eso? Un estallido momentáneo, deslumbrante y ruidoso, pero que en el fondo significa muy poco. ¿Y si nuestro ritual más sagrado es, en realidad, un simple juego de pirotecnia, diseñado para impresionar más que para iluminar?&lt;/p>
&lt;p>Durante décadas, hemos aceptado el umbral de significación estadística como el árbitro indiscutible de la verdad científica. Sin embargo, la evidencia acumulada —desde las críticas de su propio creador (Ronald Fisher) hasta las advertencias oficiales de la American Statistical Association (ASA) en 2016 y el clamor de cientos de científicos en la revista &lt;em>Nature&lt;/em> — nos obliga a una conclusión incómoda(Amrhein, Greenland, and McShane 2019; Wasserstein and Lazar 2016) : &lt;strong>el emperador estadístico está desnudo&lt;/strong>. La práctica de las Pruebas de Significación de la Hipótesis Nula (NHST, por sus siglas en inglés) no es un pilar de rigor, sino un ritual plagado de lógica errónea, confusión e inadecuación para la verdadera investigación.&lt;/p>
&lt;h2 id="el-cohete-más-grande-no-significa-mejor">El Cohete: Más Grande no Significa Mejor&lt;/h2>
&lt;p>En la pirotecnia, un cohete más grande produce una explosión más fuerte. Es simple física. En la estadística, ocurre algo perturbadoramente similar. El “cohete” es nuestro tamaño muestral.&lt;/p>
&lt;p>La conclusión de una prueba de significación depende de manera crucial del tamaño de la muestra. Con un cohete lo suficientemente grande (una muestra de miles o decenas de miles de personas), la diferencia más trivial e insignificante para el mundo real se convertirá, casi por arte de magia, en “estadísticamente significativa”. Por el contrario, un efecto importante y real puede pasar desapercibido si nuestro cohete es demasiado pequeño.&lt;/p>
&lt;p>Esto nos lleva a una &lt;strong>verdad grotesca&lt;/strong>: la decisión sobre si un hallazgo es “real” a menudo depende más de los recursos del investigador para recolectar datos masivos que de la naturaleza fundamental del fenómeno estudiado. El estallido nos dice más sobre el tamaño del cohete que sobre la belleza del cielo que intenta iluminar.&lt;/p>
&lt;!-- ```{r} -->
&lt;!-- set.seed(123) -->
&lt;!-- library(ggplot2) -->
&lt;!-- effect &lt;- 0.1 -->
&lt;!-- sd &lt;- 1 -->
&lt;!-- N &lt;- seq(20, 10000, by=50) -->
&lt;!-- p_values &lt;- sapply(N, function(n) { -->
&lt;!-- t.test(rnorm(n, mean=effect, sd=sd), mu=0)$p.value -->
&lt;!-- }) -->
&lt;!-- data &lt;- data.frame(N, p_values) -->
&lt;!-- ggplot(data, aes(N, p_values)) + -->
&lt;!-- geom_line() + -->
&lt;!-- geom_hline(yintercept = 0.05, linetype = "dashed", color="red") + -->
&lt;!-- labs(x = "Tamaño muestral (N)", y = "Valor p") + -->
&lt;!-- theme_minimal() -->
&lt;!-- ``` -->
&lt;!-- Aquí iría tu gráfico explicativo del "Cohete (Tamaño Muestral)": -->
&lt;!-- Un gráfico mostrando cómo un efecto trivial (ej: diferencia de 0.1 unidades) se vuelve "significativo" (p&lt;0.05) a medida que N aumenta de 100 a 10,000. Puedes usar `ggplot2` en R para esto. -->
&lt;!-- Ejemplo de código R (este no generaría un gráfico, solo un placeholder para tu referencia): -->
&lt;!-- ```{r cohete_plot, echo=FALSE, fig.cap="Impacto del tamaño muestral en la significación estadística para un efecto constante."} -->
&lt;!-- # Código para generar el gráfico de N vs p-valor -->
&lt;!-- # plot(your_data$N, your_data$p_value, type="l", main="Cómo N afecta el p-valor", -->
&lt;!-- # xlab="Tamaño Muestral (N)", ylab="Valor p") -->
&lt;!-- # abline(h=0.05, col="red", lty=2) -->
&lt;!-- ``` -->
&lt;h2 id="la-explosión-un-caos-de-luz-y-malentendidos">La Explosión: Un Caos de Luz y Malentendidos&lt;/h2>
&lt;p>La explosión de un fuego artificial es un evento caótico. Su interpretación es subjetiva. ¿Fue espectacular? ¿Fue un fracaso? Lo mismo ocurre con el valor &lt;em>p&lt;/em>.&lt;/p>
&lt;h2 id="lógica-errónea-juzgando-por-lo-que-no-vimos">Lógica Errónea: Juzgando por lo que no Vimos&lt;/h2>
&lt;p>La lógica detrás del valor &lt;em>p&lt;/em> es, siendo generosos, peculiar. Se calcula asumiendo que la hipótesis nula (H₀ —la hipótesis de no-efecto, de que no hay diferencia o relación) es cierta, y luego se determina la probabilidad de haber observado nuestros datos &lt;em>o datos aún más extremos&lt;/em> bajo esa suposición. Piénsalo: nuestra conclusión sobre lo que &lt;em>sí&lt;/em> ocurrió depende de la probabilidad de cosas que ni siquiera presenciamos. Es un &lt;strong>absurdo subyacente&lt;/strong>.&lt;/p>
&lt;p>Además, caemos constantemente en la &lt;strong>falacia de la probabilidad invertida&lt;/strong>: el valor &lt;em>p&lt;/em> nos dice la probabilidad de los datos dada la hipótesis nula (P(Datos|H₀)), pero nosotros creemos erróneamente que nos dice la probabilidad de que la hipótesis nula sea cierta dados nuestros datos (P(H₀|Datos)). Son dos cosas radicalmente distintas, y confundirlas es un error fundamental.&lt;/p>
&lt;!-- &lt;!-- Aquí iría tu diagrama de flujo simple o tabla comparativa para "Confusión P(D|H) vs P(H|D)": -->
&lt;!-- Puedes usarmermaid para diagramas simples en RMarkdown o una tabla Markdown para la comparación. -->
&lt;!-- Ejemplo de código mermaid (necesitarías `config: {mermaid: {sequence: {diagramMarginX: 10}}}` en el YAML para que funcione): -->
&lt;h2 id="confusión-el-ruido-no-es-la-señal">Confusión: El Ruido no es la Señal&lt;/h2>
&lt;p>La confusión más extendida es la de equiparar “significación estadística” con “importancia práctica” o “relevancia científica”. Un estallido muy ruidoso no significa que el descubrimiento sea importante, útil o generalizable. Esta obsesión por el ruido estadístico, esta endémica “significant-itis”, nos ha distraído de lo que realmente importa en la investigación: la magnitud del efecto y la relevancia clínica, social o teórica de nuestros hallazgos.&lt;/p>
&lt;h2 id="el-caso-del-chocolate-que-hace-perder-peso">El Caso del Chocolate que Hace Perder Peso&lt;/h2>
&lt;p>Para ilustrar esta locura, consideremos el tristemente famoso estudio de John Bohannon en 2015, “Chocolate con fines de pérdida de peso” . Con un pequeño presupuesto, Bohannon realizó un ensayo aleatorio, controlado con chocolate, utilizando un número muy reducido de participantes y midiendo 18 variables distintas(Bohannon 2015). Al analizar &lt;em>todas&lt;/em> las combinaciones posibles, encontró que con una muestra tan pequeña y al realizar múltiples pruebas (un tipo de &lt;em>p-hacking&lt;/em>), era casi inevitable que alguna variable arrojara un p-valor menor a 0.05 &lt;strong>por pura casualidad&lt;/strong>. Con su &lt;code>p &amp;lt; 0.05&lt;/code> “significativo”, los medios de comunicación sensacionalistas se lanzaron a la noticia: “El chocolate hace perder peso!”. Este caso es un claro ejemplo de cómo un “destello” estadístico puede ser completamente engañoso y carecer de cualquier importancia real, pero aun así generar titulares y confusión(Bohannon 2015).&lt;/p>
&lt;h2 id="el-veredicto-la-falsa-dicotomía-del-ohhh-o-el-silencio">El Veredicto: La Falsa Dicotomía del “Ohhh” o el Silencio&lt;/h2>
&lt;p>Quien observa fuegos artificiales emite un veredicto simple: el “¡Ohhh!” de asombro o el silencio de la indiferencia. Las pruebas de significación nos han impuesto esta misma decisión binaria: o un resultado es significativo (&lt;code>p &amp;lt; 0.05&lt;/code>), o no lo es. Es un interruptor de encendido/apagado.&lt;/p>
&lt;p>Pero la ciencia no funciona así. El conocimiento científico no es una serie de decisiones de “sí/no”. Es un proceso gradual de ajuste de nuestras creencias a la luz de la evidencia acumulada. Es un paisaje de grises, no un contraste de blanco y negro. Al forzarnos a este mecanicismo, a esta “sucesión de ‘decisiones’ automáticas” que el propio Fisher denunció, hemos empobrecido el discurso científico, ignorando matices cruciales como la magnitud del efecto o la precisión de la estimación.&lt;/p>
&lt;h2 id="después-del-humo-hacia-una-ciencia-iluminada">Después del Humo: Hacia una Ciencia Iluminada&lt;/h2>
&lt;p>Cuando el humo de la pirotecnia se disipa, ¿qué nos queda? Nos queda la tarea de encontrar una luz más honesta y duradera para la ciencia. Afortunadamente, esta luz existe y está ganando terreno.&lt;/p>
&lt;p>La alternativa fundamental es pasar de la &lt;strong>decisión binaria&lt;/strong> a la &lt;strong>estimación&lt;/strong>. En lugar de preguntar obsesivamente “¿Hay un efecto (sí/no)?”, debemos preguntar “¿Cuál es la magnitud del efecto y cuán seguros estamos de esa estimación?”.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Intervalos de Confianza (o de Compatibilidad):&lt;/strong> Son nuestra primera y más accesible herramienta para una inferencia más sensata. Los Intervalos de Confianza no nos dan un simple “sí/no”, sino un &lt;strong>rango de valores plausibles&lt;/strong> para el efecto real en la población. Nos muestran tanto la magnitud estimada del efecto como la incertidumbre que lo rodea.&lt;/p>
&lt;p>Cuando vemos un Intervalo de Confianza del 95% para una diferencia, por ejemplo, esto significa que si repitiéramos el estudio muchas, muchas veces bajo las mismas condiciones, el 95% de esos intervalos contendrían el verdadero valor del efecto que estamos tratando de estimar. Nos invitan a pensar en la variabilidad y la precisión de nuestras estimaciones, no solo en un umbral arbitrario. Son una luz constante que ilumina un paisaje, permitiéndonos ver el terreno completo, no un destello que ciega momentáneamente.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;!-- &lt;!-- Aquí iría tu gráfico de "Intervalos de Confianza/Compatibilidad": -->
&lt;!-- Un gráfico con varios ICs superpuestos (algunos estrechos, otros anchos, algunos cruzando cero, otros no) para ilustrar que muestran magnitud *e* incertidumbre, no solo "sí/no". -->
&lt;!-- ```{r ic_plot, echo=FALSE, fig.cap="Visualización de Intervalos de Confianza: Magnitud y Incertidumbre."} -->
&lt;!-- # Código para generar el gráfico de ICs -->
&lt;!-- # library(ggplot2) -->
&lt;!-- # data.frame( -->
&lt;!-- # Effect = c(0.5, 1.2, -0.3, 0.8), -->
&lt;!-- # Lower = c(0.1, 0.8, -0.7, 0.2), -->
&lt;!-- # Upper = c(0.9, 1.6, 0.1, 1.4) -->
&lt;!-- # ) %>% -->
&lt;!-- # ggplot(aes(y = factor(1:4), x = Effect, xmin = Lower, xmax = Upper)) + -->
&lt;!-- # geom_point() + geom_errorbarh(height = 0.2) + -->
&lt;!-- # geom_vline(xintercept = 0, linetype = "dashed", color = "grey") + -->
&lt;!-- # labs(x = "Magnitud del Efecto", y = "Estudio") + -->
&lt;!-- # theme_minimal() -->
&lt;!-- ``` -->
&lt;!-- -->
&lt;ul>
&lt;li>
&lt;p>&lt;strong>El Enfoque Bayesiano:&lt;/strong> Es el siguiente paso evolutivo en la inferencia estadística, y es la encarnación matemática del razonamiento científico. Los métodos bayesianos nos permiten hacer lo que siempre hemos querido hacer: &lt;strong>combinar la evidencia de nuestro estudio actual con todo el conocimiento previo existente&lt;/strong> (estudios anteriores, plausibilidad biológica, experiencia clínica) para llegar a una conclusión actualizada y probabilística sobre nuestras hipótesis.&lt;/p>
&lt;p>A diferencia del valor &lt;em>p&lt;/em>, el enfoque bayesiano responde directamente a la pregunta que realmente queremos hacer: “&lt;strong>Dados estos nuevos datos, ¿qué tan creíble es mi hipótesis ahora?&lt;/strong>”. Nos da una probabilidad posterior de nuestra hipótesis, una medida directa de nuestra creencia actualizada. Aunque puede parecer más complejo al principio, el razonamiento bayesiano se alinea intuitivamente con cómo los científicos y las personas actualizan sus creencias en la vida real.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Dejemos la pirotecnia para las celebraciones. Es hora de que la ciencia deje de buscar destellos efímeros y se dedique a construir una iluminación constante, acumulativa y, sobre todo, &lt;strong>honesta&lt;/strong>. Es el momento de una ciencia más transparente, rigurosa y, sí, ¡más divertida de interpretar!&lt;/p>
&lt;hr>
&lt;h2 id="tu-turno">¡Tu Turno!&lt;/h2>
&lt;p>¿Te has encontrado con la “tiranía del p&amp;lt;0.05” en tu campo? ¿Qué alternativas usas o te gustaría ver más promovidas en la investigación? ¡Comparte tu experiencia y tus pensamientos en los comentarios a continuación!&lt;/p>
&lt;hr>
&lt;h2 id="referencias">Referencias&lt;/h2>
&lt;div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
&lt;div id="ref-amrhein2019" class="csl-entry">
&lt;p>Amrhein, Valentin, Sander Greenland, and Blake McShane. 2019. “Scientists Rise up Against Statistical Significance.” &lt;em>Nature&lt;/em> 567 (7748): 305–7. &lt;a href="https://doi.org/10.1038/d41586-019-00857-9" target="_blank" rel="noopener">https://doi.org/10.1038/d41586-019-00857-9&lt;/a>.&lt;/p>
&lt;/div>
&lt;div id="ref-bohannon2015" class="csl-entry">
&lt;p>Bohannon, John. 2015. “I Fooled Millions into Thinking Chocolate Helps Weight Loss. Here’s How.” &lt;a href="https://gizmodo.com/i-fooled-millions-into-thinking-chocolate-helps-weight-1707251800" target="_blank" rel="noopener">https://gizmodo.com/i-fooled-millions-into-thinking-chocolate-helps-weight-1707251800&lt;/a>.&lt;/p>
&lt;/div>
&lt;div id="ref-wasserstein2016" class="csl-entry">
&lt;p>Wasserstein, Ronald L., and Nicole A. Lazar. 2016. “The ASA Statement on &lt;em>p&lt;/em> -Values: Context, Process, and Purpose.” &lt;em>The American Statistician&lt;/em> 70 (2): 129–33. &lt;a href="https://doi.org/10.1080/00031305.2016.1154108" target="_blank" rel="noopener">https://doi.org/10.1080/00031305.2016.1154108&lt;/a>.&lt;/p>
&lt;/div>
&lt;/div></description></item></channel></rss>