<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Blog | Bioestad√≠stica edu</title><link>https://bioestadisticaedu.com/post/</link><atom:link href="https://bioestadisticaedu.com/post/index.xml" rel="self" type="application/rss+xml"/><description>Blog</description><generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>es-es</language><lastBuildDate>Wed, 22 Oct 2025 00:00:00 +0000</lastBuildDate><image><url>https://bioestadisticaedu.com/media/icon_hu_551fbaee136b383e.png</url><title>Blog</title><link>https://bioestadisticaedu.com/post/</link></image><item><title>C√≥mo Entrenar y Validar Modelos de Predicci√≥n Cl√≠nica: Gu√≠a Paso a Paso para Profesionales de la Salud</title><link>https://bioestadisticaedu.com/post/como-entrenar-y-validar-un-modelo-de-machine-learning/</link><pubDate>Wed, 22 Oct 2025 00:00:00 +0000</pubDate><guid>https://bioestadisticaedu.com/post/como-entrenar-y-validar-un-modelo-de-machine-learning/</guid><description>&lt;p>üéß &lt;strong>Escucha el podcast de esta publicaci√≥n&lt;/strong>&lt;/p>
&lt;audio controls >
&lt;source src="https://ia600607.us.archive.org/24/items/articulo-steyember/_Articulo_Steyember.mp3" type="audio/mpeg">
&lt;/audio>
&lt;p>Si est√° leyendo esta publicaci√≥n, es probable que le interese desarrollar &lt;strong>modelos de predicci√≥n cl√≠nica&lt;/strong> para &lt;strong>diagnosticar&lt;/strong> o &lt;strong>pronosticar&lt;/strong> enfermedades en pacientes. Seguramente sea investigador o estudiante de posgrado ‚Äîen maestr√≠a o doctorado‚Äî en ciencias biom√©dicas, y busque c√≥mo &lt;strong>desarrollar&lt;/strong> y &lt;strong>validar&lt;/strong> esos modelos en un &lt;strong>art√≠culo cient√≠fico&lt;/strong> o &lt;strong>tesis&lt;/strong>.&lt;/p>
&lt;p>Casi seguro ha llegado a esa fase en la que la metodolog√≠a se siente como un muro de ladrillos: no sabe &lt;strong>qu√© pasos seguir&lt;/strong>, &lt;strong>qu√© software usar&lt;/strong>, si lo que necesita se puede hacer en &lt;strong>SPSS&lt;/strong> o si tendr√° que meterse con esos &lt;strong>c√≥digos&lt;/strong> inquietantes de &lt;strong>R o Python&lt;/strong> ‚Äîy encima no tiene experiencia en programaci√≥n. Y, lo peor de todo: le asalta la duda de si su modelo servir√° para algo m√°s all√° de llenar un repositorio de tesis‚Ä¶ o si siquiera &lt;strong>ser√° √∫til&lt;/strong> para los propios pacientes de su &lt;strong>muestra&lt;/strong>, sin hablar de otros &lt;strong>contextos cl√≠nicos&lt;/strong>.&lt;/p>
&lt;p>Seamos francos: en el fondo, todos le huimos a ese comentario punzante que nos estalla la burbuja predictiva de un solo golpe:&lt;/p>
&lt;blockquote>
&lt;p>¬°Vaya!, un √°rea bajo la curva de ensue√±o, sin rastros de calibraci√≥n ni validaci√≥n externa‚Ä¶ probablemente fruto de una receta cl√°sica: exceso de predictores, dicotomizaci√≥n entusiasta, escasez de eventos y una pizca de selecci√≥n autom√°tica. TRIPOD lo llamar√≠a ‚Äòoptimismo aparente‚Äô; nosotros, la receta del sobreajuste gourmet ‚Äîcon un cigarro y un gui√±o para rematar.&lt;/p>&lt;/blockquote>
&lt;div class="flex px-4 py-3 mb-6 rounded-md bg-primary-100 dark:bg-primary-900">
&lt;span class="pr-3 pt-1 text-primary-600 dark:text-primary-300">
&lt;svg height="24" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">&lt;path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z"/>&lt;/svg>
&lt;/span>
&lt;span class="dark:text-neutral-300">El &lt;strong>sobreajuste&lt;/strong> ocurre cuando un modelo aprende tan bien los datos de entrenamiento (incluyendo ruido o detalles irrelevantes) que su rendimiento en datos nuevos es mucho peor.&lt;/span>
&lt;/div>
&lt;p>En otras palabras, el modelo &lt;strong>funciona&lt;/strong> espectacularmente bien‚Ä¶ pero &lt;strong>solo con su muestra&lt;/strong> de pacientes. &lt;em>¬°Las m√©tricas de desempe√±o en otros conjuntos de datos son un desastre!&lt;/em> M√°s adelante retomaremos esa idea.&lt;/p>
&lt;p>Mientras las tesis de alto nivel se centran en construir modelos de predicci√≥n cl√≠nica con &lt;strong>t√©cnicas estad√≠sticas&lt;/strong> cl√°sicas o sofisticados &lt;strong>algoritmos de aprendizaje autom√°tico&lt;/strong> como los bosques aleatorios, los cursos de bioestad√≠stica &lt;em>‚Äî¬°incluso en programas de estudio de esta especialidad!‚Äî&lt;/em> apenas rozan el asunto. La &lt;strong>brecha es real&lt;/strong>, y con ella viene la ansiedad de tener que aprenderlo todo ya.&lt;/p>
&lt;p>Pero respire hondo. Este post puede endurecer su burbuja predictiva con una capa extra de titanio: su traductor metodol√≥gico no oficial, (casi) libre de l√°grimas y cargado de herramientas pr√°cticas. Yo mismo navegu√© ese infierno metodol√≥gico en mi &lt;strong>proceso doctoral&lt;/strong>, as√≠ que no solo le ofrezco &lt;strong>consejos gen√©ricos&lt;/strong>: comparto las lecciones de alguien que ya se quem√≥ las pesta√±as por usted, para que avance con &lt;strong>confianza&lt;/strong> y &lt;strong>evite&lt;/strong> los mismos &lt;strong>tropiezos&lt;/strong>.&lt;/p>
&lt;p>Olv√≠dese del c√≥digo complejo y enrevesado. Aqu√≠ nos enfocamos en la &lt;strong>l√≥gica esencial&lt;/strong> para construir un &lt;strong>modelo predictivo fiable&lt;/strong>. Desglosaremos el &lt;strong>proceso paso a paso&lt;/strong>, quit√°ndole el miedo al procesamiento de datos con ejemplos de &lt;strong>c√≥digo pr√°ctico en R&lt;/strong>.&lt;/p>
&lt;p>Si bien este post se centra en las cuestiones pr√°cticas del &lt;strong>procesamiento de datos&lt;/strong>, es importante destacar que la elecci√≥n del dise√±o de la investigaci√≥n est√° determinada por el &lt;strong>objetivo del estudio&lt;/strong> de predicci√≥n, el cual seg√∫n &lt;em>TRIPOD (Transparent Reporting of a multivariable prediction model for Individual Prognosis Or Diagnosis)&lt;/em> se &lt;strong>clasifica&lt;/strong> en tres &lt;strong>categor√≠as fundamentales&lt;/strong> (1):&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Desarrollo&lt;/strong> de un nuevo modelo&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Validaci√≥n&lt;/strong> de un modelo existente&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Actualizaci√≥n&lt;/strong> de un modelo&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Seg√∫n el &lt;strong>objetivo de la investigaci√≥n&lt;/strong> se pueden optar por uno de los siguientes &lt;strong>dise√±os&lt;/strong> de estudios:&lt;/p>
&lt;details class="spoiler " id="spoiler-2">
&lt;summary class="cursor-pointer">Desarrollo, Validaci√≥n o Actualizaci√≥n de Modelos (Click para ver detalles)&lt;/summary>
&lt;div class="rounded-lg bg-neutral-50 dark:bg-neutral-800 p-2">
&lt;ul>
&lt;li>Dise√±os seg√∫n Objetivo
&lt;ul>
&lt;li>Desarrollo de Modelos
&lt;ul>
&lt;li>Estudios de Cohorte&lt;/li>
&lt;li>Ensayos Aleatorizados&lt;/li>
&lt;li>Datos de Atenci√≥n Rutinaria&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Validaci√≥n de Modelos
&lt;ul>
&lt;li>Estudios de Cohorte Independientes&lt;/li>
&lt;li>Meta-an√°lisis&lt;/li>
&lt;li>Datos de Registro&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Actualizaci√≥n de Modelos
&lt;ul>
&lt;li>Cualquier dise√±o anterior con nuevos datos&lt;/li>
&lt;li>Datos con Estructura de Cl√∫ster&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/details>
&lt;p>Se recomienda profundizar en estos temas a partir de la bibliograf√≠a propuesta para esta publicaci√≥n. En este post nos centraremos en la &lt;strong>secuencia de etapas clave&lt;/strong> para desarrollar un &lt;strong>modelo predictivo&lt;/strong>. Como base usar√© el art√≠culo &lt;em>‚ÄúSiete pasos para el desarrollo y un ABCD para la validaci√≥n‚Äù&lt;/em> de Ewout Steyerberg‚ÄØ(1), as√≠ como su libro &lt;em>Clinical Prediction Models&lt;/em>‚ÄØ(2). A la receta a√±adir√© las recomendaciones de Frank Harrell desde su obra &lt;em>Regression Modeling Strategies&lt;/em>‚ÄØ(3), y nos basaremos en su biblioteca &lt;strong>rms&lt;/strong> para desarrollar este tutorial con &lt;strong>c√≥digo pr√°ctico en R&lt;/strong>. Finalmente dar√© mi propia visi√≥n del pol√©mico asunto de particionar los datos en &lt;strong>conjunto de entrenamiento&lt;/strong> y &lt;strong>conjunto de prueba&lt;/strong> en una &lt;strong>proporci√≥n 70:30&lt;/strong> y otras cuestiones que seguramente resultar√°n interesantes.&lt;/p>
&lt;p>Empezaremos con la &lt;strong>estrategia de modelado&lt;/strong>; el tutorial con todo el c√≥digo vendr√° despu√©s.&lt;br>
&lt;strong>¬°Empecemos!&lt;/strong>&lt;/p>
&lt;h2 id="estrategia-de-modelado">Estrategia de modelado&lt;/h2>
&lt;p>Seguir una &lt;strong>estrategia de modelado&lt;/strong> adecuada es esencial para &lt;strong>desarrollar y validar modelos de predicci√≥n&lt;/strong>: no solo &lt;strong>mitiga el sesgo&lt;/strong> y el &lt;strong>sobreajuste&lt;/strong>, sino que nos &lt;strong>orienta&lt;/strong> en un proceso que, de otro modo, puede volverse ca√≥tico.&lt;/p>
&lt;p>A continuaci√≥n, se muestran un conjunto de &lt;strong>bibliotecas en R&lt;/strong> que nos ayudar√° implementar estas ideas, pero este proceso se puede realizar de igual manera en en SPSS o Python &lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>&lt;a href="https://cran.r-project.org/web/packages/rms/index.html" target="_blank" rel="noopener">Puedes descargar e instalar el paquete &lt;strong>rms&lt;/strong> desde su p√°gina oficial en el repositorio de CRAN.&lt;/a>
Tambien le har√°n falta otras bibliotecas para el manejo de datos, confeccionar tablas y gr√°ficos para su publicaci√≥n, entre otras acciones.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-r" data-lang="r">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">library&lt;/span>(conflicted) &lt;span style="color:#75715e"># Detecta y resuelve conflictos de funciones&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">library&lt;/span>(rms) &lt;span style="color:#75715e"># Modelado log√≠stico restringido (lrm) y splines (rcs)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">library&lt;/span>(pROC) &lt;span style="color:#75715e"># Curvas ROC y AUC&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">library&lt;/span>(ggplot2) &lt;span style="color:#75715e"># Gr√°ficos pulidos (usado por rms internamente)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">library&lt;/span>(missRanger) &lt;span style="color:#75715e"># Imputaci√≥n iterativa con random forests&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">library&lt;/span>(mlbench) &lt;span style="color:#75715e"># Dataset de ejemplo: PimaIndiansDiabetes&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">library&lt;/span>(dplyr) &lt;span style="color:#75715e"># Manipulaci√≥n de datos (pipe %&amp;gt;%)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">library&lt;/span>(caret) &lt;span style="color:#75715e"># Particiones de datos (createDataPartition)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="1-definici√≥n-del-problema-e-inspecci√≥n-de-datos">1. Definici√≥n del problema e inspecci√≥n de datos&lt;/h3>
&lt;p>El primer paso en cualquier proyecto de modelado es &lt;strong>definir claramente el problema de investigaci√≥n&lt;/strong> y seleccionar la &lt;strong>variable de resultado&lt;/strong> adecuada.&lt;/p>
&lt;div class="flex px-4 py-3 mb-6 rounded-md bg-primary-100 dark:bg-primary-900">
&lt;span class="pr-3 pt-1 text-primary-600 dark:text-primary-300">
&lt;svg height="24" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">&lt;path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z"/>&lt;/svg>
&lt;/span>
&lt;span class="dark:text-neutral-300">La &lt;strong>variable de resultado&lt;/strong> debe definirse con precisi√≥n: especifique &lt;strong>qu√© evento se predice&lt;/strong>, &lt;strong>c√≥mo y cu√°ndo se mide&lt;/strong>, y el &lt;strong>horizonte temporal de predicci√≥n&lt;/strong> (por ejemplo, mortalidad a los 30 d√≠as). Tambi√©n es clave indicar el m√©todo de evaluaci√≥n del evento y si se aplic√≥ &lt;strong>cegamiento&lt;/strong> respecto a los predictores, para asegurar coherencia interna y validez del modelo.&lt;/span>
&lt;/div>
&lt;p>Durante esta fase tambi√©n realizamos un &lt;em>an√°lisis exploratorio de datos (EDA, por sus siglas en ingles)&lt;/em> para entender las caracter√≠sticas de las variables y detectar posibles problemas, como &lt;strong>datos at√≠picos&lt;/strong> o &lt;strong>valores faltantes&lt;/strong>.&lt;/p>
&lt;p>&lt;a href="https://bioestadisticaedu.com/post/eda/">Para conocer m√°s detalles, ver mi post sobre EDA&lt;/a>.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-r" data-lang="r">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">set.seed&lt;/span>(&lt;span style="color:#ae81ff">123&lt;/span>) &lt;span style="color:#75715e"># Reproducibilidad total (imputaci√≥n, splits, bootstrap)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Carga del dataset nativo&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">data&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;PimaIndiansDiabetes&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>datos &lt;span style="color:#f92672">&amp;lt;-&lt;/span> PimaIndiansDiabetes
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Variables cl√≠nicas con 0s imposibles (biol√≥gicamente)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>vars_clinicas &lt;span style="color:#f92672">&amp;lt;-&lt;/span> &lt;span style="color:#a6e22e">c&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;glucose&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;pressure&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;triceps&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;insulin&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;mass&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Limpieza: 0 ‚Üí NA, luego imputaci√≥n&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>datos &lt;span style="color:#f92672">&amp;lt;-&lt;/span> datos &lt;span style="color:#f92672">%&amp;gt;%&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">mutate&lt;/span>(&lt;span style="color:#a6e22e">across&lt;/span>(&lt;span style="color:#a6e22e">all_of&lt;/span>(vars_clinicas), &lt;span style="color:#f92672">~&lt;/span> &lt;span style="color:#a6e22e">ifelse&lt;/span>(.x &lt;span style="color:#f92672">==&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#66d9ef">NA&lt;/span>, .x))) &lt;span style="color:#f92672">%&amp;gt;%&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">missRanger&lt;/span>() &lt;span style="color:#75715e"># Imputa NA con random forests iterativos&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># nota: idealmente, si se usara una divisi√≥n simple, la imputaci√≥n deber√≠a hacerse solo en el conjunto de entrenamiento.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Configuraci√≥n rms: datadist para predicciones autom√°ticas&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>dd &lt;span style="color:#f92672">&amp;lt;-&lt;/span> &lt;span style="color:#a6e22e">datadist&lt;/span>(&lt;span style="color:#a6e22e">as.data.frame&lt;/span>(datos))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">options&lt;/span>(datadist &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;dd&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="2-codificaci√≥n-de-las-variables-predictoras">2. Codificaci√≥n de las variables predictoras&lt;/h3>
&lt;p>La &lt;strong>codificaci√≥n adecuada de las variables predictoras&lt;/strong> es fundamental para construir &lt;strong>modelos robustos&lt;/strong>.&lt;/p>
&lt;p>Es probable que necesites &lt;strong>agrupar categor√≠as poco frecuentes&lt;/strong> o crear &lt;strong>predictores resumen&lt;/strong> para condensar informaci√≥n redundante o altamente correlacionada. Y si tu modelo se basa en &lt;strong>regresi√≥n log√≠stica&lt;/strong>, no asumas linealidad de entrada: muchas veces es necesario aplicar &lt;strong>splines c√∫bicos restringidos&lt;/strong> para relajar el &lt;strong>supuesto de linealidad&lt;/strong> entre los predictores y el resultado.&lt;/p>
&lt;p>üí° &lt;strong>Tip para la publicaci√≥n:&lt;/strong> Reporta cada predictor con su &lt;em>m√©todo de medici√≥n&lt;/em>, &lt;em>momento&lt;/em> de registro y &lt;em>unidades&lt;/em> (si es continuo). Si categorizas, &lt;em>justifica los puntos de corte&lt;/em>. Si es categ√≥rico, muestra todas las categor√≠as y la de referencia. El modelo final debe reflejar &lt;em>exactamente&lt;/em> la &lt;em>codificaci√≥n&lt;/em> usada.&lt;/p>
&lt;div class="flex px-4 py-3 mb-6 rounded-md bg-yellow-100 dark:bg-yellow-900">
&lt;span class="pr-3 pt-1 text-red-400">
&lt;svg height="24" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">&lt;path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="M12 9v3.75m-9.303 3.376c-.866 1.5.217 3.374 1.948 3.374h14.71c1.73 0 2.813-1.874 1.948-3.374L13.949 3.378c-.866-1.5-3.032-1.5-3.898 0zM12 15.75h.007v.008H12z"/>&lt;/svg>
&lt;/span>
&lt;span class="dark:text-neutral-300">&lt;strong>Alerta:&lt;/strong> Dicotomizar predictores cuantitativos ‚Äîpor ejemplo, convertir una variable continua como la edad o la presi√≥n arterial en una binaria (‚Äú‚â•65 a√±os = 1‚Äù, ‚Äú&amp;lt;65 = 0‚Äù)‚Äî es una mala pr√°ctica ampliamente desaconsejada. Esta estrategia desperdicia informaci√≥n, reduce el poder estad√≠stico, introduce puntos de corte arbitrarios y aumenta el riesgo de sobreajuste. En lugar de categorizar, modela la relaci√≥n continua (por ejemplo, con splines) para preservar la se√±al cl√≠nica real.&lt;/span>
&lt;/div>
&lt;h3 id="3-especificaci√≥n-del-tipo-de-modelo">3 .Especificaci√≥n del tipo de modelo&lt;/h3>
&lt;p>En esta etapa se define la &lt;strong>estructura formal del modelo&lt;/strong>, lo que incluye el tipo de relaci√≥n entre variables (p. ej., lineal, no lineal) y, de manera crucial, la &lt;strong>selecci√≥n de los predictores&lt;/strong> finales que lo integrar√°n.&lt;/p>
&lt;div class="flex px-4 py-3 mb-6 rounded-md bg-yellow-100 dark:bg-yellow-900">
&lt;span class="pr-3 pt-1 text-red-400">
&lt;svg height="24" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">&lt;path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="M12 9v3.75m-9.303 3.376c-.866 1.5.217 3.374 1.948 3.374h14.71c1.73 0 2.813-1.874 1.948-3.374L13.949 3.378c-.866-1.5-3.032-1.5-3.898 0zM12 15.75h.007v.008H12z"/>&lt;/svg>
&lt;/span>
&lt;span class="dark:text-neutral-300">&lt;strong>Alerta:&lt;/strong> La elecci√≥n de predictores no debe basarse en la aplicaci√≥n mec√°nica de m√©todos algor√≠tmicos como la Regresi√≥n Paso a Paso (RPP), ya que suelen producir modelos inestables y sobreajustados, especialmente en contextos biom√©dicos y sociales.&lt;/span>
&lt;/div>
&lt;p>En lugar de la preselecci√≥n de variables basada √∫nicamente en valores &lt;em>p&lt;/em> de an√°lisis bivariados, se recomienda:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Priorizar el &lt;strong>juicio cl√≠nico, la revisi√≥n sistem√°tica de la literatura y la experiencia previa.&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Optar por un conjunto reducido de predictores cl√≠nicamente relevantes definidos a priori, o incluir todos los candidatos en el modelo multivariable inicial sin filtrado estad√≠stico previo.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Existen algoritmos que tienen enfoques alternativos a la selecci√≥n autom√°tica de predictores como la regresi√≥n Lasso o los √°rboles de clasificaci√≥n. En la gu√≠a propuesta por Heinze se puede profundizar sobre este tema (5)&lt;/p>
&lt;h3 id="4-estimaci√≥n-del-modelo">4. Estimaci√≥n del Modelo&lt;/h3>
&lt;p>Una vez especificado el modelo (es decir, definidos los predictores y la estructura funcional), el siguiente paso tiene como objetivo calcular los coeficientes o par√°metros que mejor se ajusten a los datos.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-r" data-lang="r">&lt;span style="display:flex;">&lt;span>modelo &lt;span style="color:#f92672">&amp;lt;-&lt;/span> &lt;span style="color:#a6e22e">lrm&lt;/span>(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> diabetes &lt;span style="color:#f92672">~&lt;/span> &lt;span style="color:#a6e22e">rcs&lt;/span>(glucose, &lt;span style="color:#ae81ff">3&lt;/span>) &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">rcs&lt;/span>(mass, &lt;span style="color:#ae81ff">3&lt;/span>) &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">rcs&lt;/span>(age, &lt;span style="color:#ae81ff">3&lt;/span>) &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">rcs&lt;/span>(pedigree, &lt;span style="color:#ae81ff">3&lt;/span>) &lt;span style="color:#f92672">+&lt;/span> pregnant,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> data &lt;span style="color:#f92672">=&lt;/span> datos,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> x &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">TRUE&lt;/span>, &lt;span style="color:#75715e"># Guarda dise√±o para bootstrap&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> y &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">TRUE&lt;/span> &lt;span style="color:#75715e"># Guarda respuesta para bootstrap&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>En modelos de regresi√≥n, la &lt;strong>estimaci√≥n del modelo&lt;/strong> se realiza a partir de m√©todos como la &lt;strong>m√°xima verosimilitud&lt;/strong>. Sin embargo, cuando el n√∫mero de eventos es limitado o el de predictores es alto, el riesgo de sobreajuste es elevado, lo que genera predicciones extremas y poco generalizables. Para mitigarlo, se emplean t√©cnicas de &lt;strong>regularizaci√≥n, penalizaci√≥n o shrinkage&lt;/strong>, que ajustan los coeficientes hacia cero para mejorar la estabilidad y la calibraci√≥n en nuevas poblaciones.&lt;/p>
&lt;p>El objetivo final no es maximizar el rendimiento aparente en la muestra de desarrollo, sino obtener un modelo con &lt;strong>predicciones estables, bien calibradas y cl√≠nicamente √∫tiles&lt;/strong>.&lt;/p>
&lt;p>üí° &lt;strong>Tip para la publicaci√≥n:&lt;/strong> La ecuaci√≥n final del modelo debe presentarse de forma completa ‚Äîincluyendo todos los coeficientes, el intercepto y, si corresponde, la supervivencia basal‚Äî, reportando m√©tricas de calibraci√≥n y discriminaci√≥n con sus intervalos de confianza.&lt;/p>
&lt;p>En machine learning es com√∫n dividir los datos en entrenamiento y prueba. Sin embargo, en contextos cl√≠nicos es diferente:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Los &lt;strong>conjuntos de datos&lt;/strong> suelen ser &lt;strong>peque√±os o medianos&lt;/strong> (usualmente menos de 1000 filas) ‚Üí dividir reduce la informaci√≥n disponible para entrenar.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Las &lt;strong>m√©tricas&lt;/strong> derivadas de la prueba pueden ser &lt;strong>altamente variables&lt;/strong>, dependiendo de qu√© observaciones caen en la partici√≥n.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Esto genera un &lt;strong>modelo menos estable&lt;/strong> y menos confiable, especialmente en estimaciones de probabilidades individuales.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;div class="flex px-4 py-3 mb-6 rounded-md bg-primary-100 dark:bg-primary-900">
&lt;span class="pr-3 pt-1 text-primary-600 dark:text-primary-300">
&lt;svg height="24" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">&lt;path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z"/>&lt;/svg>
&lt;/span>
&lt;span class="dark:text-neutral-300">La ausencia de particiones en su estudio ser un &lt;strong>tema pol√©mico&lt;/strong>, pero no se preocupe!
&lt;a href="#hi">M√°s adelante, se comentan algunos argumentos para la discusi√≥n.&lt;/a>&lt;/span>
&lt;/div>
&lt;h3 id="5-evaluaci√≥n-del-rendimiento-del-modelo">5. Evaluaci√≥n del Rendimiento del Modelo&lt;/h3>
&lt;p>Una vez desarrollado el modelo, es esencial cuantificar su capacidad predictiva antes de su validaci√≥n. Esta evaluaci√≥n se centra en tres aspectos clave:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Calibraci√≥n:&lt;/strong> Mide la concordancia entre las probabilidades predichas y las observadas. Por ejemplo, ¬øun 10% de riesgo predicho se corresponde con un 10% de eventos observados? Se eval√∫a visualmente con curvas de calibraci√≥n y cuantitativamente con par√°metros como el intercepto (A, calibraci√≥n-in-the-large) y la pendiente de calibraci√≥n (B).&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-r" data-lang="r">&lt;span style="display:flex;">&lt;span>cal_boot &lt;span style="color:#f92672">&amp;lt;-&lt;/span> &lt;span style="color:#a6e22e">calibrate&lt;/span>(modelo, method &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;boot&amp;#34;&lt;/span>, B &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">100&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">plot&lt;/span>(cal_boot, main &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;Calibraci√≥n: Predichas vs Observadas&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">## &lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">## n=768 Mean absolute error=0.016 Mean squared error=0.00045&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">## 0.9 Quantile of absolute error=0.034&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">abline&lt;/span>(&lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, lty &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">2&lt;/span>, col &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;red&amp;#34;&lt;/span>) &lt;span style="color:#75715e"># L√≠nea ideal&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;img src="calibracion-1.png" width="80%" style="display: block; margin: auto;" />
&lt;details class="spoiler " id="spoiler-9">
&lt;summary class="cursor-pointer">El gr√°fico muestra que el modelo est√° bien calibrado (Click para saber por qu√©)&lt;/summary>
&lt;div class="rounded-lg bg-neutral-50 dark:bg-neutral-800 p-2">
La calibraci√≥n perfecta ocurre cuando las probabilidades predichas coinciden con las frecuencias reales. Por ejemplo, si el modelo predice 30% de riesgo, aproximadamente 30 de cada 100 pacientes similares deber√≠an tener la condici√≥n.
&lt;/div>
&lt;/details>
&lt;ul>
&lt;li>&lt;strong>Discriminaci√≥n:&lt;/strong> Eval√∫a la capacidad del modelo para distinguir entre pacientes que experimentan el evento y aquellos que no. La m√©trica m√°s com√∫n es el estad√≠stico C (o AUC-ROC), que representa la probabilidad de que un paciente con el evento tenga una puntuaci√≥n de riesgo m√°s alta que uno sin √©l.&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-r" data-lang="r">&lt;span style="display:flex;">&lt;span>val_boot &lt;span style="color:#f92672">&amp;lt;-&lt;/span> &lt;span style="color:#a6e22e">validate&lt;/span>(modelo, method &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;boot&amp;#34;&lt;/span>, B &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">100&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>roc_obj &lt;span style="color:#f92672">&amp;lt;-&lt;/span> &lt;span style="color:#a6e22e">roc&lt;/span>(datos&lt;span style="color:#f92672">$&lt;/span>diabetes,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">predict&lt;/span>(modelo, type &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;fitted&amp;#34;&lt;/span>))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">plot&lt;/span>(roc_obj,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> main &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">paste&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;Curva ROC - AUC =&amp;#34;&lt;/span>, &lt;span style="color:#a6e22e">round&lt;/span>(&lt;span style="color:#a6e22e">auc&lt;/span>(roc_obj), &lt;span style="color:#ae81ff">3&lt;/span>)),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> col &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;blue&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> legacy.axes &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">TRUE&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;img src="Discriminacion-1.png" width="80%" style="display: block; margin: auto;" />
&lt;details class="spoiler " id="spoiler-10">
&lt;summary class="cursor-pointer">El gr√°fico del √°rea bajo la curva ROC (AUC) muestra muy buena discriminaci√≥n (Click para saber por qu√©)&lt;/summary>
&lt;div class="rounded-lg bg-neutral-50 dark:bg-neutral-800 p-2">
&lt;ul>
&lt;li>La curva ROC eval√∫a la capacidad del modelo para distinguir entre pacientes con y sin la condici√≥n.
&lt;ul>
&lt;li>AUC = Excelente (&amp;gt;0.8 se considera muy bueno en medicina)&lt;/li>
&lt;li>Eje Y: Sensibilidad (capacidad de detectar enfermos)&lt;/li>
&lt;li>Eje X: 1 - Especificidad (tasa de falsos positivos)&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/details>
&lt;ul>
&lt;li>&lt;strong>Utilidad Cl√≠nica:&lt;/strong> Determina si el modelo es √∫til para la toma de decisiones. El an√°lisis de curvas de decisi√≥n y el Beneficio Neto (NB) permiten evaluar si el uso del modelo conduce a mejores resultados cl√≠nicos netos en comparaci√≥n con estrategias alternativas (como tratar a todos o a ninguno).&lt;/li>
&lt;/ul>
&lt;h3 id="6-evaluaci√≥n-de-la-validez-del-modelo">6. Evaluaci√≥n de la Validez del Modelo&lt;/h3>
&lt;p>La &lt;strong>evaluaci√≥n del rendimiento&lt;/strong> en los datos suele ser optimista. Por ello, es crucial evaluar la validez del modelo en datos no utilizados para su construcci√≥n, un proceso que se divide en:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Validaci√≥n Interna:&lt;/strong> Eval√∫a la reproducibilidad del modelo, es decir, su rendimiento en m√∫ltiples muestras de la misma poblaci√≥n subyacente. T√©cnicas como el bootstrapping o la validaci√≥n cruzada son superiores a la divisi√≥n simple de la muestra, ya que cuantifican y corrigen el optimismo en las m√©tricas de rendimiento sin reducir el tama√±o de la muestra de desarrollo.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Validaci√≥n Externa:&lt;/strong> Es la prueba definitiva de la generalizabilidad o transportabilidad del modelo. Consiste en aplicar el modelo a una poblaci√≥n completamente independiente, lo que puede incluir:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Validaci√≥n Temporal:&lt;/strong> Usar pacientes reclutados en un per√≠odo posterior.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Validaci√≥n Geogr√°fica:&lt;/strong> Aplicar el modelo en pacientes de otros centros u hospitales.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="7-presentaci√≥n-del-modelo">7. Presentaci√≥n del modelo&lt;/h3>
&lt;p>La presentaci√≥n efectiva es crucial para la adopci√≥n cl√≠nica. Un modelo perfecto es in√∫til si los m√©dicos no pueden usarlo f√°cilmente. Algunas opciones para llevar el modelo a la pr√°ctica asistencial son:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Nomogramas&lt;/strong>: Ideales para uso r√°pido en consulta.&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-r" data-lang="r">&lt;span style="display:flex;">&lt;span>nom &lt;span style="color:#f92672">&amp;lt;-&lt;/span> &lt;span style="color:#a6e22e">nomogram&lt;/span>(modelo,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> fun &lt;span style="color:#f92672">=&lt;/span> plogis,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> funlabel &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;Riesgo de Diabetes&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">plot&lt;/span>(nom, main &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;Nomograma del Modelo&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;img src="nomograma-1.png" width="80%" style="display: block; margin: auto;" />
&lt;details class="spoiler " id="spoiler-11">
&lt;summary class="cursor-pointer">Nomograma: calculadora visual del riesgo (Click para aprender a usarlo)&lt;/summary>
&lt;div class="rounded-lg bg-neutral-50 dark:bg-neutral-800 p-2">
&lt;p>El &lt;strong>nomograma&lt;/strong> es una herramienta visual que permite calcular el riesgo individual de diabetes manualmente, usando las variables clave del modelo. Permite calcular el riesgo espec√≠fico para cada paciente sin necesidad de software, facilitando su uso en consulta&lt;/p>
&lt;p>¬øC√≥mo funciona?&lt;/p>
&lt;ul>
&lt;li>Por cada variable cl√≠nica (glucosa, IMC, edad, etc.) se asigna un puntaje en la escala &amp;ldquo;Points&amp;rdquo;&lt;/li>
&lt;li>Se suman todos los puntos para obtener el &amp;ldquo;Total Points&amp;rdquo;&lt;/li>
&lt;li>Se proyecta ese total sobre las escalas inferiores para obtener el riesgo predictivo&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/details>
&lt;ul>
&lt;li>&lt;strong>Aplicaciones web/m√≥viles&lt;/strong>: Para integraci√≥n en flujos de trabajo cl√≠nicos&lt;/li>
&lt;/ul>
&lt;p>Una aplicaci√≥n funcional para ejecutar el modelo en una pagina web, tel√©fono movil o tableta es una muy buena opci√≥n para generalizar el modelo.&lt;/p>
&lt;p>En este enlace te muestro la calculadora web que program√© en js, html y css, para el modelo de mi tesis.&lt;/p>
&lt;p>&lt;a href="https://bioestadisticaedu.com/project/covidcencecapk/">ver CovidCencecAPK&lt;/a>&lt;/p>
&lt;h2 id="hi">Mis recomendaciones y posici√≥n&lt;/h2>
&lt;p>Reconozco que la &lt;strong>partici√≥n simple de datos (70/30)&lt;/strong> es un est√°ndar frecuente y, a menudo, el punto de partida en la pr√°ctica del Machine Learning. No obstante, si nuestro objetivo es fortalecer la credibilidad y la robustez de nuestros hallazgos, especialmente en el √°mbito de los &lt;strong>modelos cl√≠nicos&lt;/strong>, este enfoque merece una pausa y una seria reconsideraci√≥n.&lt;/p>
&lt;p>La cr√≠tica a esta pr√°ctica no es nueva ni aislada. Autores influyentes en el campo como Frank Harrell y Edmund Steyerberg han expresado su clara oposici√≥n, y otros expertos se suman a este consenso. Como bien lo resume Smedenen en este &lt;em>tweet&lt;/em>:&lt;/p>
&lt;blockquote class="twitter-tweet">&lt;p lang="en" dir="ltr">Good description of leakage, but very often an even better solution is not to split your data into train-test sets at all. Cross validation and internal-external validation should be the starting point (deviate only when necessary) &lt;a href="https://t.co/l3ZDmv2kzb">https://t.co/l3ZDmv2kzb&lt;/a>&lt;/p>&amp;mdash; Maarten van Smeden (@MaartenvSmeden) &lt;a href="https://twitter.com/MaartenvSmeden/status/1544599686488723461?ref_src=twsrc%5Etfw">July 6, 2022&lt;/a>&lt;/blockquote>
&lt;script async src="https://platform.twitter.com/widgets.js" charset="utf-8">&lt;/script>
&lt;p>Comparto plenamente esta visi√≥n: para muestras peque√±as, como suelen ser los conjuntos de datos de investigaciones cl√≠nicas, una partici√≥n simple ‚Äîaunque sea aleatoria‚Äî introduce m√°s riesgos que beneficios. Esta es una pr√°ctica m√°s com√∫n en entornos de Machine Learning general, donde los datasets son, t√≠picamente, mucho m√°s extensos.&lt;/p>
&lt;p>A continuaci√≥n, exploremos en detalle las principales razones por las que este enfoque puede no ser la mejor pr√°ctica cuando la precisi√≥n y la vida de los pacientes est√°n en juego.&lt;/p>
&lt;h3 id="1-ineficiencia-en-el-uso-de-los-datos-y-p√©rdida-de-poder">1. Ineficiencia en el uso de los datos y p√©rdida de poder&lt;/h3>
&lt;p>Los conjuntos de datos cl√≠nicos son, por naturaleza, a menudo peque√±os (pensemos en menos de 500 pacientes), limitados por costes o la baja incidencia de eventos raros.&lt;/p>
&lt;p>Una partici√≥n t√≠pica 70/30 desperdicia hasta un 30% de los datos solo en la evaluaci√≥n, reduciendo dr√°sticamente el tama√±o efectivo para el entrenamiento. Esto provoca una ca√≠da en la m√©trica clave de Eventos por Variable Predictora (EPV) ‚Äîque mide cu√°ntos eventos, como diagn√≥sticos positivos, hay por cada predictor en el modelo‚Äî, situ√°ndola frecuentemente por debajo del umbral recomendado de 10-20.&lt;/p>
&lt;p>El resultado es predecible: modelos inestables y sesgados. El rendimiento aparente (ej., un AUC alto en el split de entrenamiento) puede caer dr√°sticamente en datos nuevos (por ejemplo, de 0.85 a un decepcionante 0.65). En contextos cl√≠nicos, donde capturar patrones reales es vital, la recomendaci√≥n es clara: &lt;strong>maximizar todos los datos y aplicar t√©cnicas de remuestreo para una estimaci√≥n m√°s honesta.&lt;/strong>&lt;/p>
&lt;h3 id="2-evaluaciones-de-rendimiento-con-alta-variabilidad-e-inestabilidad">2. Evaluaciones de rendimiento con alta variabilidad e inestabilidad&lt;/h3>
&lt;p>Cuando dependemos de una sola partici√≥n simple, las m√©tricas de rendimiento (como el AUC para la discriminaci√≥n o el Brier score para la calibraci√≥n) se vuelven muy sensibles al azar de c√≥mo se dividieron los datos.&lt;/p>
&lt;p>Las simulaciones demuestran que esta &amp;ldquo;suerte&amp;rdquo; puede generar variaciones de hasta de m√°s o menos 0.10-0.15 en el AUC, un ruido significativo. Esta varianza se dispara (2-3 veces m√°s) en muestras peque√±as. Un resultado inestable puede inflar o subestimar la calibraci√≥n (ej. en el test de Hosmer-Lemeshow), lo que podr√≠a llevar a tomar decisiones cl√≠nicas err√≥neas y, lo m√°s importante, poner en riesgo a los pacientes (por ejemplo, subtratando a quienes lo necesitan).&lt;/p>
&lt;p>Para ilustrar esta inestabilidad, aqu√≠ se simula la variabilidad del AUC en splits simples repetidos utilizando el dataset de nuestro ejemplo:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-r" data-lang="r">&lt;span style="display:flex;">&lt;span>auc_splits &lt;span style="color:#f92672">&amp;lt;-&lt;/span> &lt;span style="color:#a6e22e">replicate&lt;/span>(&lt;span style="color:#ae81ff">100&lt;/span>, {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> trainIndex &lt;span style="color:#f92672">&amp;lt;-&lt;/span> &lt;span style="color:#a6e22e">createDataPartition&lt;/span>(datos&lt;span style="color:#f92672">$&lt;/span>diabetes, p &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">0.7&lt;/span>, list &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">FALSE&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> train &lt;span style="color:#f92672">&amp;lt;-&lt;/span> datos[trainIndex, ]; test &lt;span style="color:#f92672">&amp;lt;-&lt;/span> datos[&lt;span style="color:#f92672">-&lt;/span>trainIndex, ]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> model_simple &lt;span style="color:#f92672">&amp;lt;-&lt;/span> &lt;span style="color:#a6e22e">glm&lt;/span>(diabetes &lt;span style="color:#f92672">~&lt;/span> glucose &lt;span style="color:#f92672">+&lt;/span> mass &lt;span style="color:#f92672">+&lt;/span> age, family &lt;span style="color:#f92672">=&lt;/span> binomial, data &lt;span style="color:#f92672">=&lt;/span> train)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> pred &lt;span style="color:#f92672">&amp;lt;-&lt;/span> &lt;span style="color:#a6e22e">predict&lt;/span>(model_simple, test, type &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;response&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">roc&lt;/span>(test&lt;span style="color:#f92672">$&lt;/span>diabetes, pred)&lt;span style="color:#f92672">$&lt;/span>auc
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>})
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">hist&lt;/span>(auc_splits,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> main &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;Distribuci√≥n de AUC en 100 Splits Simples&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> xlab &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;AUC&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> col &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;lightgray&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> border &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;black&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;img src="Simular-1.png" width="80%" style="display: block; margin: auto;" />
&lt;h3 id="3-riesgo-de-sobreajuste-y-falta-de-generalizaci√≥n-robusta">3. Riesgo de sobreajuste y falta de generalizaci√≥n robusta&lt;/h3>
&lt;p>Una simple &amp;ldquo;instant√°nea&amp;rdquo; proporcionada por la partici√≥n de prueba no es suficiente para corregir el sobreajuste. El modelo, al ajustarse al conjunto de entrenamiento (incluyendo su ruido), ofrece un rendimiento aparente (un &amp;ldquo;optimismo&amp;rdquo;) que, seg√∫n Harrell, puede ser un 5-20% superior al real.&lt;/p>
&lt;p>Sin m√©todos de remuestreo, es imposible obtener un error de generalizaci√≥n realista. M√©todos repetidos (como la validaci√≥n cruzada de k-pliegues) promedian las estimaciones a lo largo de m√∫ltiples splits, lo que reduce el sesgo y mejora la estabilidad.&lt;/p>
&lt;p>Cuando no se corrige este optimismo, no solo se afecta la validez interna del estudio, sino que se compromete la generalizaci√≥n del modelo, pues fallar√° al aplicarse a cohortes externas debido a las idiosincrasias (detalles √∫nicos) de la muestra original.&lt;/p>
&lt;h2 id="-mi-sugerencia">üí° Mi Sugerencia&lt;/h2>
&lt;p>En lugar de depender de particiones simples, mi recomendaci√≥n es clara: utilizar m√©todos que aprovechen la totalidad de los datos y ofrezcan estimaciones m√°s estables. Esto incluye:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Validaci√≥n Cruzada Repetida: Divide los datos en particiones y repite el proceso de divisi√≥n y evaluaci√≥n m√∫ltiples veces para promediar los resultados.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Bootstrapping: Muestrea con reemplazo para estimar la estabilidad y corregir el optimismo inherente.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Estos m√©todos no solo corrigen el optimismo sino que reducen la variabilidad, aline√°ndose con las buenas pr√°cticas en el desarrollo de modelos de pron√≥stico cl√≠nico. Por esta raz√≥n, seleccion√© bibliotecas como rms::validate() en R para el ejemplo, ya que se adhieren a esta filosof√≠a.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Para conjuntos de datos peque√±os, la robustez es lo primero. Evite las divisiones simples y priorice la estabilidad para generar resultados que sean verdaderamente √∫tiles en la pr√°ctica asistencial.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Un Apunte sobre la Validaci√≥n Externa&lt;/strong>&lt;/p>
&lt;p>Coincido en que la validaci√≥n externa es crucial y debe realizarse con un conjunto de datos independiente en otros contextos, ya sea en diferentes momentos (validaci√≥n temporal) o en distintos hospitales (validaci√≥n geogr√°fica), para confirmar la verdadera generalizaci√≥n.&lt;/p>
&lt;p>En mi experiencia, las cuestiones operativas y log√≠sticas que implica realizar una validaci√≥n externa en otro centro o en otro momento a menudo desmotivan al investigador que est√° desarrollando un modelo con datos de su propia consulta. Sin embargo, creo que este enfoque es el que abre el camino para obtener mejores resultados a partir de la investigaci√≥n en condiciones reales. Adem√°s, es un acto de m√©rito y un pilar de la ciencia realizar validaciones de modelos de otros en su propia consulta; la ciencia se nutre de la replicaci√≥n y la colaboraci√≥n.&lt;/p>
&lt;h2 id="-qu√©-sigue">‚è≠Ô∏è ¬øQu√© sigue?&lt;/h2>
&lt;p>Esta gu√≠a es una introducci√≥n pr√°ctica y concisa para iniciarse en modelos predictivos cl√≠nicos. Temas avanzados como el c√°lculo detallado de tama√±o de muestra, el manejo exhaustivo de datos faltantes (m√°s all√° de imputaci√≥n b√°sica), la actualizaci√≥n de modelos existentes, an√°lisis profundos de curvas de decisi√≥n para utilidad cl√≠nica, la reproducibilidad, el ajuste del intercepto de la regresi√≥n log√≠stica en escenarios con prevalencias diferentes, los m√©todos de recalibraci√≥n continua, o la construcci√≥n de escalas y clasificaciones cl√≠nicas no se abordan en detalle para mantener la brevedad y enfoque en lo esencial. Para profundizar, consulta referencias como Steyerberg o el marco TRIPOD.&lt;/p>
&lt;h2 id="-tu-turno">üöÄ ¬°Tu Turno!&lt;/h2>
&lt;p>&lt;strong>Pasa de la Teor√≠a a la Pr√°ctica.&lt;/strong> Este material es solo la punta del iceberg. ¬°Ahora aplica estos conceptos con tus datos cl√≠nicos y experimenta para construir modelos m√°s robustos! Si necesitas m√°s recursos, explora las referencias mencionadas.&lt;/p>
&lt;p>Ahora, me encantar√≠a leerte. ¬°La experiencia es la que enriquece el conocimiento!&lt;/p>
&lt;p>üí¨ D√©janos tu &lt;strong>comentario en la caja de comentarios&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>¬øHas aplicado estas t√©cnicas de remuestreo en tus proyectos de modelos predictivos?&lt;/li>
&lt;li>¬øQu√© estrategias usas habitualmente para entrenar y validar tus modelos cl√≠nicos?&lt;/li>
&lt;li>Tus comentarios, tus dificultades y tus logros nos ayudan a todos a seguir aprendiendo.&lt;/li>
&lt;/ul>
&lt;p>üöÄ Lleva el C√≥digo a tu Proyecto&lt;/p>
&lt;p>&lt;a href="https://bioestadisticaedu.com/subscribe/">&lt;strong>Subscribete&lt;/strong> a nuestra comunidad de bioestad√≠sticaedu, recibe art√≠culos directamente en tu bandeja de entrada, sigue nuestro canal RSS o
sigue mi canal de telegram&lt;/a>.&lt;/p>
&lt;div class="flex px-4 py-3 mb-6 rounded-md bg-primary-100 dark:bg-primary-900">
&lt;span class="pr-3 pt-1 text-primary-600 dark:text-primary-300">
&lt;svg height="24" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">&lt;path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z"/>&lt;/svg>
&lt;/span>
&lt;span class="dark:text-neutral-300">Al suscribirte, te enviar√© inmediatamente una &lt;strong>plantilla completa con todo el c√≥digo comentado (¬°incluyendo tablas y estructura!)&lt;/strong> lista para aplicar este proceso en tu pr√≥xima publicaci√≥n o tesis.&lt;/span>
&lt;/div>
&lt;p>ü§ù ¬øNecesitas un Enfoque Personalizado?&lt;/p>
&lt;p>&lt;a href="https://bioestadisticaedu.com/collaborations/">Si quieres aplicar estas estrategias a un dataset espec√≠fico y necesitas la seguridad de un experto a tu lado, tambi√©n puedes contactarme para una consultor√≠a personalizada sobre este tema.&lt;/a>.&lt;/p>
&lt;p>Y recuerda siempre la regla de oro: &lt;strong>¬°Si vas a cometer errores que sean nuevos! üòâ&lt;/strong> &lt;em>m@icel&lt;/em>&lt;/p>
&lt;h2 id="bibliograf√≠a">Bibliograf√≠a&lt;/h2>
&lt;ol>
&lt;li>
&lt;p>Collins GS, Moons KGM, Dhiman P, Riley RD, Beam AL, Van Calster B, et¬†al. TRIPOD+AI statement: updated guidance for reporting clinical prediction models that use regression or machine learning methods. BMJ [Internet]. 16 de abril de 2024 [citado 3 de octubre de 2025];e078378. Disponible en: &lt;a href="https://www.bmj.com/lookup/doi/10.1136/bmj-2023-078378" target="_blank" rel="noopener">https://www.bmj.com/lookup/doi/10.1136/bmj-2023-078378&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Steyerberg EW, Vergouwe Y. Towards better clinical prediction models: seven steps for development and an ABCD for validation. European Heart Journal [Internet]. 1 de agosto de 2014 [citado 9 de mayo de 2021];35(29):1925-31. Disponible en: &lt;a href="https://academic.oup.com/eurheartj/article-lookup/doi/10.1093/eurheartj/ehu207" target="_blank" rel="noopener">https://academic.oup.com/eurheartj/article-lookup/doi/10.1093/eurheartj/ehu207&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Steyerberg E. Clinical Prediction Models. 1th ed. USA: Springer; 2009. (Statistics for Biology and Health).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Harrell Jr FE. Regression Modeling Strategies. 1era ed. New York: Springer; 2015.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Heinze G, Wallisch C, Dunkler D. Variable selection - A review and recommendations for the practicing statistician. Biom J [Internet]. mayo de 2018 [citado 9 de mayo de 2021];60(3):431-49. Disponible en: &lt;a href="http://doi.wiley.com/10.1002/bimj.201700067" target="_blank" rel="noopener">http://doi.wiley.com/10.1002/bimj.201700067&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>&lt;a href="https://bioestadisticaedu.com/collaborations/">Puede contactarme para una consultor√≠a personalizada donde puedo ayudarle a desarrollar un modelo predictivo o ense√±arle a desarrollar la estrategia de modelado con otras herramientas como &lt;strong>SPSS&lt;/strong> o &lt;strong>Python&lt;/strong>.&lt;/a>.&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>¬øEscribir ciencia o reescribir la realidad?</title><link>https://bioestadisticaedu.com/post/imryd-redaccion-inversa/</link><pubDate>Sat, 04 Oct 2025 00:00:00 +0000</pubDate><guid>https://bioestadisticaedu.com/post/imryd-redaccion-inversa/</guid><description>&lt;h2 id="introducci√≥n">Introducci√≥n&lt;/h2>
&lt;div class="flex px-4 py-3 mb-6 rounded-md bg-primary-100 dark:bg-primary-900">
&lt;span class="pr-3 pt-1 text-primary-600 dark:text-primary-300">
&lt;svg height="24" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">&lt;path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z"/>&lt;/svg>
&lt;/span>
&lt;span class="dark:text-neutral-300">&amp;ldquo;¬øY si escribimos al rev√©s? No de la Introducci√≥n a los hallazgos, sino de los hallazgos a la Introducci√≥n.&amp;rdquo;&lt;/span>
&lt;/div>
&lt;p>&lt;strong>IMRyD ‚ÄîIntroducci√≥n, M√©todos, Resultados y Discusi√≥n‚Äî&lt;/strong> funciona como un bien p√∫blico editorial: estandariza, facilita la revisi√≥n y permite comparar art√≠culos.
Adem√°s, comenzar por el problema cient√≠fico importa: formularlo bien equivale a haber recorrido media soluci√≥n (1).
Este post no propone abandonar &lt;strong>IMRyD&lt;/strong>, sino distinguir dos √≥rdenes complementarios:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Orden de publicaci√≥n (IMRyD):&lt;/strong> √∫til para evaluaci√≥n y recuperaci√≥n de informaci√≥n&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Orden de redacci√≥n (guiada por hallazgos):&lt;/strong> √∫til para alinear el relato con lo que realmente aprendimos y separar lo confirmatorio de lo exploratorio (2,3).&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>En la pr√°ctica:&lt;/strong> redacta primero los &lt;strong>resultados&lt;/strong> clave (estimaciones, intervalos de confianza, relevancia), despu√©s la &lt;strong>Discusi√≥n&lt;/strong> (plausibilidad, sesgos, sensibilidad), luego &lt;strong>M√©todos&lt;/strong> con transparencia radical (qu√© estaba preespecificado, qu√© cambi√≥ y por qu√©), y cierra con una &lt;strong>Introducci√≥n&lt;/strong> breve y precisa al problema (formular preguntas o hip√≥tesis) que realmente se ajusta los resultados.
El formato final sigue siendo &lt;strong>IMRyD&lt;/strong>.&lt;/p>
&lt;h2 id="cu√°ndo-s√≠-y-cu√°ndo-no">Cu√°ndo s√≠ y cu√°ndo no&lt;/h2>
&lt;p>&lt;strong>Conviene:&lt;/strong> estudios observacionales, an√°lisis secundarios, descubrimientos no previstos, ciencia de datos aplicada donde la iteraci√≥n es inevitable.&lt;/p>
&lt;p>&lt;strong>Precauci√≥n/No conviene:&lt;/strong> Registered Reports, ensayos confirmatorios con plan de an√°lisis estad√≠stico (PAE) preespecificado (CONSORT), revisiones sistem√°ticas con protocolo (PRISMA).
En estos casos, mant√©n la primac√≠a del plan y se√±ala lo exploratorio como tal (4,5).&lt;/p>
&lt;h2 id="objeciones-cr√≠ticas-y-respuestas-con-evidencia">Objeciones cr√≠ticas (y respuestas con evidencia)&lt;/h2>
&lt;p>&lt;strong>‚ÄúEsto fomenta HARKing.‚Äù&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Respuesta:&lt;/strong> justo lo contrario si se exige se√±alizaci√≥n expl√≠cita y materiales abiertos.
&lt;em>HARKing es ocultar; aqu√≠ pedimos diferenciar confirmatorio vs. exploratorio y documentar cambios (6-8).&lt;/em>&lt;/p>
&lt;p>&lt;strong>‚ÄúLa Introducci√≥n pierde su papel.‚Äù&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Respuesta:&lt;/strong> se fortalece.
&lt;em>Enmarca el problema real que la evidencia ilumin√≥, sin forzar una cronolog√≠a ficticia.ICMJE promueve IMRAD para claridad, no para reescribir la historia (9).&lt;/em>&lt;/p>
&lt;p>&lt;strong>‚ÄúLos editores piden IMRyD estricto.‚Äù&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Respuesta:&lt;/strong> lo mantenemos.
&lt;em>Cambia el flujo de trabajo, no la macroestructura. Adem√°s, TOP y pr√°cticas abiertas refuerzan la confianza editorial (10).&lt;/em>&lt;/p>
&lt;p>&lt;strong>‚ÄúSe sobrevaloran resultados inesperados.‚Äù&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Respuesta:&lt;/strong> exige sensibilidad, controles negativos, replicaci√≥n y no fetichizar p&amp;lt;0,05&lt;/p>
&lt;h2 id="checklist-de-transparencia">Checklist de transparencia&lt;/h2>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Elemento&lt;/th>
&lt;th>Confirmatorio&lt;/th>
&lt;th>Exploratorio&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Especificaci√≥n previa&lt;/td>
&lt;td>Protocolo/SAP enlazado&lt;/td>
&lt;td>No preespecificado (justificaci√≥n)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Resultados&lt;/td>
&lt;td>Etiquetados como preespecificados&lt;/td>
&lt;td>Etiquetados como post hoc&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>An√°lisis&lt;/td>
&lt;td>Seg√∫n plan&lt;/td>
&lt;td>Limitados, con sensibilidad&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Recursos abiertos&lt;/td>
&lt;td>Datos/c√≥digo/cuaderno&lt;/td>
&lt;td>C√≥digo y criterios documentados&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="conclusi√≥n">Conclusi√≥n&lt;/h2>
&lt;p>IMRyD ordena y hace comparables nuestros art√≠culos.
Integrar una redacci√≥n guiada por hallazgos es una forma moderada y pr√°ctica de ganar honestidad, utilidad y trazabilidad, sin sacrificar rigor metodol√≥gico ni claridad editorial.
En algunos contextos ‚Äîsobre todo exploratorios‚Äî puede ser la diferencia entre un relato fiel al descubrimiento y una cronolog√≠a ficticia.&lt;/p>
&lt;h2 id="recursos-adicionales">Recursos adicionales&lt;/h2>
&lt;p>üéß &lt;strong>Escucha el podcast de esta publicaci√≥n&lt;/strong>
&lt;audio controls >
&lt;source src="https://bioestadisticaedu.com/mp3/Post_IMRyD.mp3" type="audio/mpeg">
&lt;/audio>
&lt;/p>
&lt;h2 id="bibliograf√≠a">Bibliograf√≠a&lt;/h2>
&lt;ol>
&lt;li>
&lt;p>P√≥lya G. How to solve it. Princeton University Press; 1945.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Kerr NL. HARKing: Hypothesizing after the results are known. Personality and Social Psychology Review. 1998;2(3):196-217.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Gelman A, Loken E. The garden of forking paths: Why multiple comparisons can be a problem [Internet]. 2013. Disponible en: &lt;a href="https://stat.columbia.edu/~gelman/research/unpublished/p_hacking.pdf" target="_blank" rel="noopener">https://stat.columbia.edu/~gelman/research/unpublished/p_hacking.pdf&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Schulz KF, Altman DG, Moher D. CONSORT 2010 statement. BMJ. 2010;340:c332.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Page MJ, McKenzie JE, Bossuyt PM, others. The PRISMA 2020 statement. BMJ. 2021;372:n71.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Munaf√≤ MR, Nosek BA, Bishop DVM, others. A manifesto for reproducible science. Nature Human Behaviour. 2017;1:0021.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Nosek BA, Ebersole CR, DeHaven AC, Mellor DT. The preregistration revolution. PNAS. 2018;115(11):2600-6.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>International Committee of Medical Journal Editors. Recommendations for the conduct, reporting, editing, and publication of scholarly work in medical journals. 2019; Disponible en: &lt;a href="http://www.icmje.org/recommendations/" target="_blank" rel="noopener">http://www.icmje.org/recommendations/&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Nosek BA, others. Promoting an open research culture (TOP Guidelines). Science. 2015;348(6242):1422-5.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Wasserstein RL, Lazar NA. The asa‚Äôs statement on p-Values: Context, process, and purpose. The American Statistician. 2016;70(2):129-33.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Wasserstein RL, Schirm AL, Lazar NA. Moving to a world beyond ‚Äúp ¬° 0.05‚Äù. The American Statistician. 2019;73(sup1):1-19.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>McShane BB, Gal D, Gelman A, Robert C, Tackett JL. Abandon statistical significance. The American Statistician. 2019;73(sup1):235-45.&lt;/p>
&lt;/li>
&lt;/ol></description></item><item><title>Las trampas de la correlaci√≥n disfrazada de causalidad</title><link>https://bioestadisticaedu.com/post/trampas-correlacion/</link><pubDate>Wed, 24 Sep 2025 00:00:00 +0000</pubDate><guid>https://bioestadisticaedu.com/post/trampas-correlacion/</guid><description>&lt;h2 id="introducci√≥n">Introducci√≥n&lt;/h2>
&lt;p>El ojo humano ama los patrones: ver dos l√≠neas que se mueven juntas y concluir que una provoca la otra. La estad√≠stica, mal interpretada, a veces alimenta esa ilusi√≥n. La correlaci√≥n es apenas la danza conjunta de dos variables, no una flecha de causa. Y, sin embargo, titulares, pol√≠ticas y hasta decisiones m√©dicas se sostienen sobre esta trampa.&lt;/p>
&lt;h2 id="1-correlaciones-curiosas-pero-falsas">1) Correlaciones curiosas (pero falsas)&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Helados y ahogamientos.&lt;/strong> En verano, ambos aumentan. No porque el helado mate, sino porque el calor atrae ba√±istas y heladeros.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Cig√ºe√±as y natalidad.&lt;/strong> En pueblos europeos, donde hay m√°s cig√ºe√±as, tambi√©n hay m√°s nacimientos‚Ä¶ simplemente porque se trata de √°reas rurales m√°s f√©rtiles, no porque las aves traigan beb√©s.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Pel√≠culas de Nicolas Cage y ahogamientos en piscinas.&lt;/strong> Ejemplo cl√°sico de correlaciones espurias recopiladas por Tyler Vigen: c√≥mico, pero ilustrativo.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="2-la-correlaci√≥n-y-su-impacto-en-la-toma-de-decisiones">2) La correlaci√≥n y su impacto en la toma de decisiones&lt;/h2>
&lt;p>La confusi√≥n entre causalidad y correlaci√≥n no es solo un chiste; tiene consecuencias graves.&lt;/p>
&lt;p>&lt;strong>Pol√≠tica p√∫blica:&lt;/strong> Un estudio muestra que los pa√≠ses con m√°s m√©dicos per c√°pita tienen m√°s diagn√≥sticos de c√°ncer. Conclusi√≥n errada: ‚Äúlos m√©dicos causan c√°ncer‚Äù. Realidad: mayor densidad m√©dica implica mejor detecci√≥n.&lt;/p>
&lt;p>&lt;strong>Falacia de la causa inversa:&lt;/strong> Ni√±os con bajo rendimiento escolar pasan m√°s horas frente a la televisi√≥n. ¬øLa TV los perjudica? ¬øO los ni√±os con dificultades recurren m√°s a ella? La direcci√≥n de la causalidad puede invertirse f√°cilmente.&lt;/p>
&lt;hr>
&lt;h1 id="3-qu√©-mide-realmente-la-correlaci√≥n">3) ¬øQu√© mide realmente la correlaci√≥n?&lt;/h1>
&lt;ul>
&lt;li>El &lt;strong>coeficiente de correlaci√≥n (r)&lt;/strong> mide la fuerza y direcci√≥n de la relaci√≥n entre dos variables.&lt;/li>
&lt;li>Sus valores van de &lt;strong>-1 a +1&lt;/strong>:
&lt;ul>
&lt;li>+1 ‚Üí relaci√≥n positiva perfecta&lt;/li>
&lt;li>-1 ‚Üí relaci√≥n negativa perfecta&lt;/li>
&lt;li>0 ‚Üí ausencia de relaci√≥n lineal&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;div class="flex px-4 py-3 mb-6 rounded-md bg-primary-100 dark:bg-primary-900">
&lt;span class="pr-3 pt-1 text-primary-600 dark:text-primary-300">
&lt;svg height="24" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">&lt;path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z"/>&lt;/svg>
&lt;/span>
&lt;span class="dark:text-neutral-300">&lt;strong>Advertencia:&lt;/strong> un r alto no significa causalidad. Puede deberse a &lt;strong>confusores&lt;/strong>, &lt;strong>azar&lt;/strong> o &lt;strong>causalidad inversa&lt;/strong>.&lt;/span>
&lt;/div>
&lt;hr>
&lt;h1 id="4-tipos-de-coeficientes-de-correlaci√≥n-m√°s-all√°-de-pearson">4) Tipos de coeficientes de correlaci√≥n (m√°s all√° de Pearson)&lt;/h1>
&lt;p>
&lt;figure >
&lt;div class="flex justify-center ">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/trampas-correlacion/correlacion_hu_c614a73ad03379b6.webp 400w,
/post/trampas-correlacion/correlacion_hu_e6f9def3a13f9eea.webp 760w,
/post/trampas-correlacion/correlacion_hu_dedc904516865376.webp 1200w"
src="https://bioestadisticaedu.com/post/trampas-correlacion/correlacion_hu_c614a73ad03379b6.webp"
width="507"
height="760"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;hr>
&lt;h1 id="5-causalidad-un-desaf√≠o-que-exige-rigurosidad">5) Causalidad: un desaf√≠o que exige rigurosidad&lt;/h1>
&lt;p>Identificar la causalidad no se improvisa. Requiere algo m√°s que una simple correlaci√≥n. Exige un dise√±o experimental riguroso, criterios de Bradford Hill y construcci√≥n de modelos causales. La estad√≠stica sugiere, pero no prueba por s√≠ sola.&lt;/p>
&lt;hr>
&lt;h1 id="6-met√°fora-para-recordar">6) Met√°fora para recordar&lt;/h1>
&lt;p>Piensa en la correlaci√≥n como ver dos hojas que caen juntas en oto√±o. Creer que una arrastra a la otra es ignorar el viento invisible que las mueve a ambas.&lt;/p>
&lt;hr>
&lt;h1 id="7-checklist-para-evitar-caer-en-la-trampa">7) Checklist para evitar caer en la trampa&lt;/h1>
&lt;ol>
&lt;li>¬øExiste una variable oculta (confusor) que explique la relaci√≥n? ‚úî&lt;/li>
&lt;li>¬øPodr√≠a la causalidad ir en sentido contrario? ‚úî&lt;/li>
&lt;li>¬øEl dise√±o permite concluir causa o solo asociaci√≥n? ‚úî&lt;/li>
&lt;li>¬øHay criterios te√≥ricos/experimentales que respalden esta relaci√≥n? ‚úî&lt;/li>
&lt;li>¬øSe comunic√≥ claramente que es correlaci√≥n, no causalidad? ‚úî&lt;/li>
&lt;/ol>
&lt;hr>
&lt;h1 id="bibliograf√≠a">Bibliograf√≠a&lt;/h1>
&lt;p>Silva Aycaguer LC. &lt;em>Cultura estad√≠stica e investigaci√≥n cient√≠fica en el campo de la salud: una mirada cr√≠tica&lt;/em>. Madrid: D√≠az de Santos; 1998.&lt;/p>
&lt;p>Pearl, J. (2009). Causality: Models, Reasoning, and Inference (2nd ed.). Cambridge University Press.&lt;/p>
&lt;p>Hern√°n, M. A., &amp;amp; Robins, J. M. (2020). Causal Inference: What If. Chapman &amp;amp; Hall/CRC. [Disponible gratis en l√≠nea].&lt;/p>
&lt;p>Hill, A. B. (1965). The environment and disease: association or causation? Proceedings of the Royal Society of Medicine, 58(5), 295‚Äì300. (Criterios de Bradford Hill).&lt;/p>
&lt;p>Freedman, D. A. (2005). Statistical Models: Theory and Practice. Cambridge University Press. (Discusi√≥n cr√≠tica sobre correlaci√≥n y causalidad).&lt;/p></description></item><item><title>Una Inmersi√≥n Intuitiva en la Arquitectura de los LLMs</title><link>https://bioestadisticaedu.com/post/ia/</link><pubDate>Sat, 06 Sep 2025 00:00:00 +0000</pubDate><guid>https://bioestadisticaedu.com/post/ia/</guid><description>&lt;p>Todos conocemos los Modelos de Lenguaje Grandes (LLMs) como &lt;strong>ChatGPT de OpenAI, Claude de Anthropic, Gemini de Google&lt;/strong> y otros modelos similares.&lt;/p>
&lt;p>Son esos asistentes de IA con los que conversamos, que nos ayudan a escribir correos (Stanford Online 2024)electr√≥nicos, a generar ideas e incluso a codificar.&lt;/p>
&lt;p>Pero, ¬øalguna vez te has preguntado c√≥mo funcionan realmente estas herramientas?
¬øEst√°n pensando o simplemente est√°n creando una &lt;strong>magn√≠fica ilusi√≥n de razonamiento&lt;/strong>?
En este blog, te mostrar√© c√≥mo cobran vida estas maravillas tecnol√≥gicas, desde el vasto oc√©ano de datos hasta su afinada inteligencia, y exploraremos la naturaleza de esa ‚Äúinteligencia‚Äù que tanto nos asombra.&lt;/p>
&lt;p>Puedes ver la versi√≥n en v√≠deo de esta publicaci√≥n aqu√≠:&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/SxIFozcvCAU?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video">&lt;/iframe>
&lt;/div>
&lt;p>A continuaci√≥n, te explico algunos elementos importantes para entender los Modelos de Lenguaje Grandes (LLMs), como se construyen, c√≥mo se entrenan y predicen sus resultado.&lt;/p>
&lt;img src="fig0.png" style="width:30.0%" />
&lt;h2 id="la-anatom√≠a-de-un-llm-redes-neuronales-y-transformadores">La Anatom√≠a de un LLM: Redes Neuronales y Transformadores&lt;/h2>
&lt;p>En esencia, los LLMs son &lt;strong>redes neuronales&lt;/strong>.
Lejos de simular el cerebro humano en un sentido biol√≥gico, se basan casi universalmente en una arquitectura particular conocida como &lt;strong>Transformadores&lt;/strong>.&lt;/p>
&lt;div class="flex px-4 py-3 mb-6 rounded-md bg-primary-100 dark:bg-primary-900">
&lt;span class="pr-3 pt-1 text-primary-600 dark:text-primary-300">
&lt;svg height="24" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">&lt;path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z"/>&lt;/svg>
&lt;/span>
&lt;span class="dark:text-neutral-300">&lt;strong>Red neuronal artificial:&lt;/strong> &lt;em>‚ÄúUna red neuronal artificial es un sistema de procesamiento paralelo y distribuido, compuesto por unidades simples de procesamiento que tienen la propensi√≥n natural de almacenar conocimiento experimental y hacerlo disponible para su uso‚Äù&lt;/em> (Haykin, n.d.).&lt;/span>
&lt;/div>
&lt;p>Estos Transformadores fueron propuestos por Vaswani et al.¬†en 2017 y se destacaron por su capacidad para ‚Äúdibujar dependencias globales entre la entrada y la salida‚Äù utilizando √∫nicamente mecanismos de atenci√≥n, sin necesidad de redes recurrentes o convolucionales.&lt;/p>
&lt;p>Esta capacidad es clave para su √©xito: permite que el modelo procese grandes cantidades de texto en paralelo y capte relaciones a larga distancia dentro de una secuencia.(Vaswani et al., n.d.)&lt;/p>
&lt;p>Cuando hablamos de entrenar un LLM, hay varios componentes clave que entran en juego:&lt;/p>
&lt;!-- - **Arquitectura**: C√≥mo se estructura la red neuronal (los Transformadores). -->
&lt;!-- - **P√©rdida de entrenamiento y algoritmo**: C√≥mo se "aprende" el modelo. -->
&lt;!-- - **Datos**: En qu√© informaci√≥n se entrena el modelo. -->
&lt;!-- - **Evaluaci√≥n**: C√≥mo sabemos si el modelo est√° mejorando. -->
&lt;!-- - **Componentes del sistema**: C√≥mo se ejecutan estos modelos gigantes en hardware moderno de manera eficiente. -->
&lt;p>
&lt;figure >
&lt;div class="flex justify-center ">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/ia/fig1_hu_18182d8f524833af.webp 400w,
/post/ia/fig1_hu_f33bba6717280fcf.webp 760w,
/post/ia/fig1_hu_4ee0477a1071e0cf.webp 1200w"
src="https://bioestadisticaedu.com/post/ia/fig1_hu_18182d8f524833af.webp"
width="760"
height="410"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;!-- A menudo, la academia se centra mucho en la arquitectura, pero en la pr√°ctica, lo que realmente importa es la **calidad de los datos, la evaluaci√≥n y los sistemas**, ya que las peque√±as diferencias arquitect√≥nicas son a menudo secundarias frente a la escala. -->
&lt;h2 id="la-primera-etapa-pre-entrenamiento-modelado-del-lenguaje">La Primera Etapa: Pre-entrenamiento (Modelado del Lenguaje)&lt;/h2>
&lt;p>El viaje de un LLM comienza con el &lt;strong>pre-entrenamiento&lt;/strong>, un paradigma cl√°sico donde el modelo se entrena para &lt;strong>‚Äúmodelar todo Internet‚Äù&lt;/strong>.&lt;/p>
&lt;p>En esta fase, un modelo de lenguaje es, a grandes rasgos, un modelo de &lt;strong>distribuci√≥n de probabilidad sobre secuencias de tokens o palabras&lt;/strong>.&lt;/p>
&lt;div class="flex px-4 py-3 mb-6 rounded-md bg-primary-100 dark:bg-primary-900">
&lt;span class="pr-3 pt-1 text-primary-600 dark:text-primary-300">
&lt;svg height="24" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">&lt;path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z"/>&lt;/svg>
&lt;/span>
&lt;span class="dark:text-neutral-300">&lt;strong>Tokens:&lt;/strong> &lt;em>‚ÄúUn token es una instancia de una secuencia de caracteres en un documento, agrupada como una unidad sem√°ntica √∫til para el procesamiento autom√°tico de texto. Esta explicaci√≥n se basa en una definici√≥n clara y rigurosa en el contexto del an√°lisis de informaci√≥n y recuperaci√≥n de documentos.‚Äù&lt;/em>&lt;/span>
&lt;/div>
&lt;p>Imagina la frase &lt;strong>‚ÄúEl rat√≥n comi√≥ el queso‚Äù&lt;/strong>.&lt;/p>
&lt;img src="fig2.png" style="width:30.0%" />
&lt;p>Un modelo de lenguaje te dar√≠a la probabilidad de que esta frase sea pronunciada por un humano o encontrada en l√≠nea.&lt;/p>
&lt;p>Si la frase tuviera errores gramaticales como &lt;strong>‚ÄúEl el rat√≥n queso‚Äù&lt;/strong>, el modelo, con su conocimiento sint√°ctico, sabr√≠a que es menos &lt;strong>probable&lt;/strong>.&lt;/p>
&lt;p>Y si fuera &lt;strong>‚ÄúEl queso comi√≥ el rat√≥n‚Äù&lt;/strong>, su conocimiento sem√°ntico le indicar√≠a que esto es &lt;strong>improbable&lt;/strong>.&lt;/p>
&lt;img src="fig3.png" style="width:30.0%" />
&lt;p>&lt;strong>Aqu√≠ es donde entra el primer matiz cr√≠tico&lt;/strong>: este &lt;strong>‚Äúconocimiento sint√°ctico y sem√°ntico‚Äù&lt;/strong> no implica que el modelo &lt;strong>entienda&lt;/strong> realmente la gram√°tica o que los quesos no comen ratones.&lt;/p>
&lt;p>M√°s bien, ha aprendido, a partir de patrones en billones de textos, que ciertas secuencias de palabras son estad√≠sticamente m√°s probables o coherentes que otras.
Es una habilidad predictiva, no una comprensi√≥n conceptual.&lt;/p>
&lt;p>Los LLMs son &lt;strong>modelos generativos&lt;/strong>.&lt;/p>
&lt;p>Esto significa que, una vez que tienen esta comprensi√≥n de las distribuciones de probabilidad, pueden &lt;strong>generar nuevas oraciones o datos&lt;/strong> simplemente muestreando de esa distribuci√≥n.&lt;/p>
&lt;div class="flex px-4 py-3 mb-6 rounded-md bg-primary-100 dark:bg-primary-900">
&lt;span class="pr-3 pt-1 text-primary-600 dark:text-primary-300">
&lt;svg height="24" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">&lt;path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z"/>&lt;/svg>
&lt;/span>
&lt;span class="dark:text-neutral-300">&lt;strong>Modelos generativos:&lt;/strong> &lt;em>‚ÄúSon algoritmos dise√±ados para crear datos nuevos que parecen provenir de la misma distribuci√≥n que los datos originales con los que fueron entrenados.‚Äù&lt;/em>&lt;/span>
&lt;/div>
&lt;p>Es decir, &lt;em>saben&lt;/em> c√≥mo sonar convincentes y coherentes, pero no necesariamente &lt;em>por qu√©&lt;/em> lo que dicen es correcto o verdadero.&lt;/p>
&lt;h2 id="modelos-de-lenguaje-autorregresivos-prediciendo-la-siguiente-palabra">Modelos de Lenguaje Autorregresivos: Prediciendo la Siguiente Palabra&lt;/h2>
&lt;p>Vamos a adaptar el texto que proporcionaste para que se conecte con nuestro ejemplo del rat√≥n y el queso.üêÅüßÄ&lt;/p>
&lt;h2 id="modelos-de-lenguaje-autorregresivos-prediciendo-la-siguiente-palabra-1">Modelos de Lenguaje Autorregresivos: Prediciendo la Siguiente Palabra&lt;/h2>
&lt;p>Los modelos de lenguaje m√°s modernos, como Gemini, son &lt;strong>autorregresivos&lt;/strong>.
Esto significa que predicen la &lt;strong>siguiente palabra bas√°ndose en todas las palabras que ya han visto&lt;/strong> en la secuencia.&lt;/p>
&lt;p>Piensa en ellos como un narrador que va construyendo una historia palabra por palabra.&lt;/p>
&lt;p>El Proceso con &lt;strong>‚ÄúEl rat√≥n comi√≥ el queso‚Äù&lt;/strong>&lt;/p>
&lt;p>Imaginemos que el modelo est√° generando nuestra frase, ‚ÄúEl rat√≥n comi√≥ el queso.‚Äù Este es el fascinante proceso que ocurre:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>Secuencia de palabras:&lt;/strong> El modelo empieza con la primera palabra de la oraci√≥n.
Luego, toma las palabras que ya ha generado: &lt;strong>‚ÄúEl rat√≥n‚Äù&lt;/strong>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Tokenizaci√≥n:&lt;/strong> Las palabras se convierten en &lt;strong>tokens&lt;/strong> (n√∫meros o identificadores internos).
Por ejemplo, ‚ÄúEl‚Äù podr√≠a ser &lt;code>143&lt;/code>, ‚Äúrat√≥n‚Äù &lt;code>56&lt;/code>, y ‚Äúcomi√≥‚Äù &lt;code>25&lt;/code>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>El modelo predice:&lt;/strong> Estos tokens numerados entran en el modelo (la ‚Äúcaja negra‚Äù).
Basado en todo lo que ha aprendido de internet, el modelo calcula cu√°l es el pr√≥ximo token m√°s probable.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Distribuci√≥n de probabilidad:&lt;/strong> El modelo no solo predice una palabra, sino que le asigna una &lt;strong>probabilidad a cada palabra&lt;/strong> en su vocabulario.
Por ejemplo, despu√©s de &lt;strong>‚ÄúEl rat√≥n comi√≥ el‚Äù&lt;/strong>, la palabra &lt;strong>‚Äúqueso‚Äù&lt;/strong> podr√≠a tener una probabilidad del 85%, ‚Äúpan‚Äù un 10%, y ‚Äúsemillas‚Äù un 5%.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Muestreo:&lt;/strong> El modelo elige el token con la probabilidad m√°s alta, que en este caso es el token para ‚Äúqueso‚Äù.
A veces, para no sonar rob√≥tico, el modelo elige una palabra con una probabilidad un poco menor, pero en la mayor√≠a de los casos elige la m√°s probable.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Detokenizaci√≥n:&lt;/strong> El token seleccionado se convierte de nuevo en la palabra ‚Äúqueso‚Äù, completando as√≠ la frase.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;hr>
&lt;h2 id="aprendizaje-del-modelo">Aprendizaje del Modelo&lt;/h2>
&lt;p>Durante el &lt;strong>entrenamiento&lt;/strong>, el modelo hace este mismo proceso, pero en lugar de generar una frase nueva, compara su predicci√≥n con la palabra real en un texto de entrenamiento.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Si el modelo predice &lt;strong>‚Äúpan‚Äù&lt;/strong> y la palabra correcta es &lt;strong>‚Äúqueso‚Äù&lt;/strong>, la &lt;strong>funci√≥n de p√©rdida de entrop√≠a cruzada&lt;/strong> le da un ‚Äúcastigo‚Äù.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Ese castigo se usa para ajustar los pesos del modelo.
El objetivo es que, la pr√≥xima vez que vea un contexto similar (‚ÄúEl rat√≥n comi√≥ el‚Ä¶‚Äù), la probabilidad de que prediga ‚Äúqueso‚Äù sea mucho mayor.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>As√≠, la ‚Äúfluidez‚Äù del modelo para generar frases como ‚ÄúEl rat√≥n comi√≥ el queso‚Äù se basa en su capacidad para &lt;strong>predecir estad√≠sticamente&lt;/strong> la palabra m√°s probable en cada paso, no en un razonamiento sobre los h√°bitos alimenticios de los roedores.&lt;/p>
&lt;!-- Los modelos m√°s utilizados hoy en d√≠a son los **modelos de lenguaje autorregresivos**. -->
&lt;!-- La idea central es descomponer la probabilidad de una secuencia de palabras en un producto de probabilidades condicionales: la probabilidad de la primera palabra, multiplicada por la probabilidad de la segunda palabra dada la primera, y as√≠ sucesivamente. -->
&lt;!-- En t√©rminos m√°s simples, el modelo predice la **siguiente palabra bas√°ndose en todo lo que ha ocurrido antes** en la secuencia. -->
&lt;!-- El proceso es fascinante: -->
&lt;!-- 1. Tomas una secuencia de palabras (como "Ella probablemente prefiere"). -->
&lt;!-- 2. La **tokenizas**, es decir, la divides en "tokens" (palabras o subpalabras) y les asignas un ID. -->
&lt;!-- 3. Estos tokens pasan por el modelo (la "caja negra" del Transformador). -->
&lt;!-- 4. El modelo emite una **distribuci√≥n de probabilidad** sobre la siguiente palabra o token posible. -->
&lt;!-- 5. Se "muestrea" de esta distribuci√≥n para obtener el siguiente token m√°s probable. -->
&lt;!-- 6. Finalmente, se "detokeniza" para obtener la palabra real. -->
&lt;!-- Durante el entrenamiento, el objetivo es **predecir el token m√°s probable** y ajustar los pesos del modelo para aumentar la probabilidad de generar el token correcto, utilizando la **funci√≥n de p√©rdida de entrop√≠a cruzada (Cross-Entropy Loss)**, que es equivalente a maximizar la verosimilitud logar√≠tmica del texto. -->
&lt;!-- Esta es la base de su impresionante fluidez, pero recalca que su "razonamiento" es una sofisticada forma de predicci√≥n estad√≠stica. -->
&lt;h2 id="los-tokenizadores-el-primer-paso-crucial-para-la-coherencia">Los Tokenizadores: El Primer Paso Crucial para la ‚ÄúCoherencia‚Äù&lt;/h2>
&lt;p>Los &lt;strong>tokenizadores&lt;/strong> son componentes extremadamente importantes pero a menudo poco valorados.&lt;/p>
&lt;p>¬øPor qu√© los necesitamos?&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>M√°s generales que las palabras&lt;/strong>: Las palabras como tokens directos fallan con errores tipogr√°ficos o en idiomas que no usan espacios (como el tailand√©s).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Eficiencia de secuencia&lt;/strong>: Tokenizar car√°cter por car√°cter har√≠a las secuencias demasiado largas, lo que es ineficiente para los Transformadores (cuya complejidad crece cuadr√°ticamente con la longitud de la secuencia).&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Los tokenizadores buscan encontrar &lt;strong>subsecuencias comunes&lt;/strong> y darles un token espec√≠fico.
En promedio, un token suele representar alrededor de &lt;strong>tres o cuatro letras&lt;/strong>.&lt;/p>
&lt;p>Un algoritmo muy com√∫n es la &lt;strong>Codificaci√≥n de Pares de Bytes (Byte Pair Encoding o BPE)&lt;/strong>.
Es fundamental considerar c√≥mo se tokeniza el texto, ya que el &lt;strong>tama√±o del vocabulario afecta directamente la dimensionalidad de la salida&lt;/strong> del modelo.&lt;/p>
&lt;p>&lt;strong>Un punto cr√≠tico aqu√≠&lt;/strong>: Si bien son √∫tiles, los tokenizadores tienen limitaciones, especialmente con n√∫meros (matem√°ticas) y c√≥digo.&lt;/p>
&lt;p>Por ejemplo, un n√∫mero como ‚Äú327‚Äù puede tener su propio token, lo que significa que el modelo no lo ve como una composici√≥n de ‚Äú3‚Äù, ‚Äú2‚Äù, ‚Äú7‚Äù, lo que dificulta su capacidad para razonar matem√°ticamente o con la estructura del c√≥digo.&lt;/p>
&lt;p>Esto nos recuerda que, a pesar de la fluidez, los LLMs operan sobre representaciones simb√≥licas (tokens) que no siempre se alinean con nuestra comprensi√≥n conceptual del lenguaje o las matem√°ticas.&lt;/p>
&lt;h2 id="de-modelo-de-lenguaje-a-asistente-de-ia-el-post-entrenamiento-o-la-ilusi√≥n-de-la-intencionalidad">De Modelo de Lenguaje a Asistente de IA: El Post-entrenamiento (o la Ilusi√≥n de la Intencionalidad)&lt;/h2>
&lt;p>Un modelo pre-entrenado es un experto en &lt;strong>‚Äúhablar como Internet‚Äù&lt;/strong>, pero no es un asistente de IA.&lt;/p>
&lt;p>Si le preguntaras a &lt;strong>GPT-3&lt;/strong> (un modelo puramente de lenguaje) ‚Äúexpl√≠came el aterrizaje en la luna a un ni√±o de seis a√±os‚Äù, podr√≠a responder con ‚Äúexpl√≠came la teor√≠a de la gravedad a un ni√±o de seis a√±os‚Äù porque ha aprendido que en Internet, una pregunta a menudo es seguida por preguntas similares, no por una respuesta directa.&lt;/p>
&lt;p>El &lt;strong>post-entrenamiento (alignment)&lt;/strong> es el proceso que transforma estos modelos en asistentes √∫tiles, asegur√°ndose de que &lt;strong>sigan las instrucciones de los usuarios&lt;/strong> y los deseos de los dise√±adores (por ejemplo, evitar contenido t√≥xico).&lt;/p>
&lt;p>&lt;strong>Este es el punto donde la ilusi√≥n de intencionalidad se vuelve m√°s fuerte.&lt;/strong>&lt;/p>
&lt;h3 id="1-ajuste-fino-supervisado-supervised-fine-tuning---sft">1. Ajuste Fino Supervisado (Supervised Fine-Tuning - SFT)&lt;/h3>
&lt;p>El primer paso es el &lt;strong>Ajuste Fino Supervisado (SFT)&lt;/strong>.&lt;/p>
&lt;p>Aqu√≠, el LLM pre-entrenado se afina con &lt;strong>respuestas deseadas recogidas de humanos&lt;/strong>.
Es decir, se le dan ejemplos de preguntas y sus respuestas ‚Äúcorrectas‚Äù o ‚Äúideales‚Äù escritas por humanos.&lt;/p>
&lt;p>Este paso fue crucial para el salto de &lt;strong>GPT-3&lt;/strong> a &lt;strong>ChatGPT&lt;/strong>.&lt;/p>
&lt;p>Curiosamente, no se necesita una cantidad masiva de datos para SFT; &lt;strong>unos pocos miles de ejemplos bien elegidos pueden ser suficientes&lt;/strong>.&lt;/p>
&lt;p>Esto sugiere que el SFT no ense√±a al modelo nuevo conocimiento, sino que le ense√±a &lt;strong>c√≥mo formatear las respuestas&lt;/strong> y optimizar para un ‚Äútipo de usuario‚Äù espec√≠fico que ya hab√≠a visto en sus datos de pre-entrenamiento.&lt;/p>
&lt;p>En otras palabras, el modelo ya ten√≠a el conocimiento latente; el SFT le ense√±a a &lt;em>expresarlo&lt;/em> de la manera que un asistente de IA ‚Äúdeber√≠a‚Äù hacerlo.&lt;/p>
&lt;p>No est√° aprendiendo a &lt;em>pensar&lt;/em> como un asistente, sino a &lt;em>simular&lt;/em> el comportamiento de uno.&lt;/p>
&lt;h3 id="2-aprendizaje-por-refuerzo-a-partir-de-retroalimentaci√≥n-humana-reinforcement-learning-from-human-feedback---rlhf">2. Aprendizaje por Refuerzo a partir de Retroalimentaci√≥n Humana (Reinforcement Learning from Human Feedback - RLHF)&lt;/h3>
&lt;p>El SFT tiene sus limitaciones: &lt;strong>Limitado por la habilidad humana&lt;/strong>: Los humanos pueden juzgar mejor lo que es una buena respuesta de lo que pueden escribirla ellos mismos.&lt;/p>
&lt;p>&lt;strong>Posibles alucinaciones&lt;/strong>: Como el SFT se entrena con poca data, si un humano da una respuesta que el modelo no ha visto antes (y por tanto no sabe si es cierta), el modelo puede aprender a ‚Äúinventar‚Äù informaci√≥n plausible pero falsa.&lt;/p>
&lt;p>&lt;strong>Aqu√≠ el matiz cr√≠tico es fundamental&lt;/strong>: la ‚Äúalucinaci√≥n‚Äù (generaci√≥n de informaci√≥n falsa pero plausible) es una clara evidencia de que los LLMs no ‚Äúsaben‚Äù lo que es verdad o mentira, ni tienen un sentido de la realidad.&lt;/p>
&lt;p>Simplemente generan secuencias de tokens que &lt;em>parecen&lt;/em> correctas, bas√°ndose en los patrones que han aprendido, incluso si no tienen fundamento.&lt;/p>
&lt;p>Es la culminaci√≥n de la ilusi√≥n de razonamiento.
&lt;strong>Costo&lt;/strong>: Generar respuestas ideales es muy caro.&lt;/p>
&lt;p>Aqu√≠ es donde entra el &lt;strong>RLHF&lt;/strong>.&lt;/p>
&lt;p>En lugar de simplemente clonar el comportamiento humano, el objetivo es &lt;strong>maximizar la preferencia humana&lt;/strong>.&lt;/p>
&lt;p>El proceso es el siguiente:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Para una instrucci√≥n dada, el modelo genera &lt;strong>dos respuestas diferentes&lt;/strong>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Etiquetadores humanos seleccionan &lt;strong>cu√°l de las dos respuestas es mejor&lt;/strong>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Con esta retroalimentaci√≥n, el modelo se afina para generar m√°s de las respuestas ‚Äúbuenas‚Äù y menos de las ‚Äúmalas‚Äù.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>Para hacer esto, se entrena un &lt;strong>modelo de recompensa (Reward Model)&lt;/strong>, un clasificador que aprende a predecir cu√°nto prefiere un humano una respuesta sobre otra, dando una se√±al de recompensa continua.&lt;/p>
&lt;p>Posteriormente, m√©todos m√°s simples como la &lt;strong>Optimizaci√≥n Directa por Preferencia (Direct Preference Optimization - DPO)&lt;/strong> han demostrado ser igual de efectivos, evitando la complejidad del aprendizaje por refuerzo tradicional.&lt;/p>
&lt;p>En definitiva, RLHF moldea el comportamiento del LLM para alinearse con lo que &lt;em>deseamos&lt;/em> ver, no con lo que el modelo &lt;em>sabe&lt;/em> o &lt;em>piensa&lt;/em>.&lt;/p>
&lt;p>Le ense√±a a ser complaciente y a evitar lo ‚Äút√≥xico‚Äù porque los humanos as√≠ lo prefieren, no por un juicio moral inherente.&lt;/p>
&lt;h3 id="la-materia-prima-datos-masivos-y-su-filtrado">La Materia Prima: Datos Masivos y su Filtrado&lt;/h3>
&lt;p>El pre-entrenamiento de los LLMs se realiza sobre &lt;strong>‚Äútodo Internet‚Äù&lt;/strong>.&lt;/p>
&lt;p>Esto incluye vastas colecciones como Common Crawl, que contiene alrededor de &lt;strong>250 mil millones de p√°ginas web y un petabyte de datos&lt;/strong>.&lt;/p>
&lt;p>Pero el Internet es ‚Äúsucio‚Äù y no representativo.&lt;/p>
&lt;p>Imagina una p√°gina web aleatoria: llena de HTML, publicidad, fragmentos sin terminar.&lt;/p>
&lt;p>Para que estos datos sean √∫tiles, se requieren pasos de procesamiento intensivos, que incluyen:&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="flex justify-center ">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/ia/fig4_hu_b74c97a4d4debd70.webp 400w,
/post/ia/fig4_hu_f0bdf3ad77c25970.webp 760w,
/post/ia/fig4_hu_6e63ba7ee8334dc3.webp 1200w"
src="https://bioestadisticaedu.com/post/ia/fig4_hu_b74c97a4d4debd70.webp"
width="507"
height="760"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;!-- 1. **Extracci√≥n de texto**: Eliminar HTML y extraer contenido. -->
&lt;!-- 2.**Filtrado de contenido indeseable**: Eliminar contenido no seguro (NSFW), da√±ino o informaci√≥n personal (PII). -->
&lt;!-- 3. **Deduplicaci√≥n**: Eliminar contenido repetido. -->
&lt;!-- 4. **Filtrado heur√≠stico**: Eliminar documentos de baja calidad bas√°ndose en reglas (por ejemplo, distribuciones de tokens inusuales, longitud extrema de palabras o documentos muy cortos/largos). -->
&lt;!-- 5. **Filtrado basado en modelos**: Entrenar un clasificador para identificar documentos de alta calidad, usando referencias de Wikipedia como punto de partida. -->
&lt;!-- 6. **Clasificaci√≥n y ponderaci√≥n por dominio**: Aumentar o disminuir el peso de ciertos dominios (por ejemplo, el c√≥digo puede mejorar el razonamiento, por lo que se le da m√°s peso). -->
&lt;!-- 7. **Entrenamiento final con datos de alta calidad**: "Sobreajustar" el modelo con datos de muy alta calidad al final del pre-entrenamiento, reduciendo la tasa de aprendizaje. -->
&lt;p>La escala de estos conjuntos de datos es asombrosa, pasando de &lt;strong>150 mil millones de tokens (800 GB)&lt;/strong> en benchmarks acad√©micos anteriores, hasta &lt;strong>15 billones de tokens&lt;/strong> para modelos de √∫ltima generaci√≥n como Llama 3 (equivalente a miles de terabytes).&lt;/p>
&lt;p>La recopilaci√≥n y curaci√≥n de datos sigue siendo un desaf√≠o enorme y un √°rea activa de investigaci√≥n.&lt;/p>
&lt;h2 id="las-leyes-de-escalado-el-poder-de-lo-grande-y-sus-implicaciones-en-la-inteligencia">Las Leyes de Escalado: El Poder de lo Grande (y sus Implicaciones en la ‚ÄúInteligencia‚Äù)&lt;/h2>
&lt;p>Uno de los descubrimientos m√°s sorprendentes en LLMs es que &lt;strong>cuantos m√°s datos se entrenen los modelos y m√°s grandes sean los modelos, mejor ser√° su rendimiento&lt;/strong>.&lt;/p>
&lt;p>A diferencia de lo que se ense√±a en muchas clases de aprendizaje autom√°tico, el ‚Äúsobreajuste‚Äù (overfitting) no parece ocurrir con los LLMs.&lt;/p>
&lt;p>Las &lt;strong>leyes de escalado&lt;/strong> nos muestran que si se aumenta la computaci√≥n, los datos o el n√∫mero de par√°metros, la p√©rdida de validaci√≥n del modelo disminuye de forma predecible y lineal en una escala logar√≠tmica.&lt;/p>
&lt;p>Esto es crucial porque permite a las compa√±√≠as predecir cu√°nto mejorar√°n sus modelos en el futuro y c√≥mo optimizar la asignaci√≥n de recursos.&lt;/p>
&lt;p>Por ejemplo, el famoso art√≠culo Chinchilla de DeepMind mostr√≥ que la relaci√≥n √≥ptima es entrenar con &lt;strong>20 tokens por cada par√°metro&lt;/strong> del modelo para maximizar la eficiencia del entrenamiento.&lt;/p>
&lt;p>&lt;strong>Un punto anal√≠tico aqu√≠&lt;/strong>: Que los modelos ‚Äúmejoren‚Äù al escalar no significa que se vuelvan intr√≠nsecamente ‚Äúm√°s inteligentes‚Äù en un sentido humano, o que est√©n m√°s cerca de la conciencia.&lt;/p>
&lt;p>Simplemente, son &lt;strong>m√°quinas de patrones incre√≠blemente sofisticadas&lt;/strong> que, con m√°s datos y m√°s capacidad computacional, son capaces de reconocer y generar patrones cada vez m√°s complejos y coherentes, reduciendo su ‚Äúp√©rdida‚Äù (es decir, volvi√©ndose mejores en la predicci√≥n del siguiente token).&lt;/p>
&lt;p>La ‚Äúinteligencia‚Äù que percibimos es una propiedad emergente de esta capacidad de predicci√≥n a gran escala, no una mente.&lt;/p>
&lt;!-- ### El Precio de la Ilusi√≥n de Inteligencia: ¬øCu√°nto Cuesta un LLM? -->
&lt;!-- Entrenar un LLM es una empresa monumental y costosa. -->
&lt;!-- Tomemos como ejemplo el modelo **Llama 3 400B**, uno de los mejores modelos de c√≥digo abierto actuales: **Tokens de entrenamiento**: 15.6 billones de tokens. -->
&lt;!-- - **Par√°metros**: 45 mil millones. -->
&lt;!-- - **C√≥mputo (FLOPs)**: Aproximadamente 3.8 x 10\^25 FLOPs. -->
&lt;!-- - **Hardware y tiempo**: Se entren√≥ en **16.000 GPUs H100** durante unos 70 d√≠as (o 26 millones de horas de GPU). -->
&lt;!-- -**Costo estimado**: El alquiler de estas GPUs costar√≠a alrededor de **52 millones de d√≥lares**, y sumando los salarios del equipo, el costo total de entrenamiento rondar√≠a los **75 millones de d√≥lares**. -->
&lt;!-- - **Huella de carbono**: El entrenamiento de Llama 3 emiti√≥ unas 4.000 toneladas de CO2 equivalente. -->
&lt;!-- Estos n√∫meros son un testimonio de la inmensa inversi√≥n necesaria para crear estos modelos capaces de generar una ilusi√≥n tan convincente. -->
&lt;h2 id="sistemas-el-cerebro-detr√°s-de-la-eficiencia">Sistemas: El Cerebro Detr√°s de la Eficiencia&lt;/h2>
&lt;p>La computaci√≥n es el cuello de botella m√°s grande en el desarrollo de LLMs.
Comprar m√°s GPUs es dif√≠cil por su alto costo y escasez, adem√°s de las limitaciones f√≠sicas en la comunicaci√≥n entre ellas.&lt;/p>
&lt;p>Es crucial optimizar c√≥mo se asignan los recursos y el pipeline de entrenamiento.&lt;/p>
&lt;p>Algunos trucos clave a nivel de sistemas incluyen: &lt;strong>Baja Precisi√≥n (Low Precision)&lt;/strong>: Usar n√∫meros de punto flotante de 16 bits en lugar de 32 bits.&lt;/p>
&lt;p>Esto reduce la cantidad de datos que deben enviarse a las GPUs, acelerando la comunicaci√≥n y disminuyendo el consumo de memoria.&lt;/p>
&lt;p>&lt;strong>Fusi√≥n de Operadores (Operator Fusion)&lt;/strong>: Las GPUs son muy lentas en la comunicaci√≥n.
La fusi√≥n de operadores combina varias operaciones consecutivas en una sola llamada al kernel, lo que significa que los datos se env√≠an a la GPU una sola vez, todas las operaciones se realizan y luego los resultados se devuelven, lo que acelera significativamente el proceso (por ejemplo, &lt;code>torch.compile&lt;/code> en PyTorch puede duplicar la velocidad).&lt;/p>
&lt;h2 id="conclusi√≥n-una-ilusi√≥n-poderosa-no-un-pensamiento-consciente">Conclusi√≥n: Una Ilusi√≥n Poderosa, No un Pensamiento Consciente&lt;/h2>
&lt;p>Desde sus cimientos como redes neuronales Transformer, pasando por el pre-entrenamiento con datos masivos de Internet y el afinamiento con retroalimentaci√≥n humana, hasta la optimizaci√≥n de sistemas y la gesti√≥n de costos astron√≥micos, la creaci√≥n de un LLM es una haza√±a de ingenier√≠a y ciencia de datos.&lt;/p>
&lt;p>La pr√≥xima vez que interact√∫es con un chatbot, recordar√°s que detr√°s de esa respuesta fluida hay billones de tokens procesados, complejos algoritmos de entrenamiento, ingeniosas t√©cnicas de afinamiento y una infraestructura computacional masiva trabajando en conjunto.
&lt;strong>Estos modelos no ‚Äúpiensan‚Äù en el sentido humano de la palabra, ni poseen conciencia o una comprensi√≥n profunda y hol√≠stica del mundo&lt;/strong>.&lt;/p>
&lt;p>Lo que hacen, y lo hacen de manera magistral, es &lt;strong>identificar y reproducir patrones estad√≠sticos&lt;/strong> en los datos con los que fueron entrenados.&lt;/p>
&lt;p>Su habilidad para generar texto coherente, relevante y a menudo sorprendentemente ‚Äúinteligente‚Äù es una testamentaci√≥n de la &lt;strong>efectividad de la predicci√≥n a escala masiva&lt;/strong>.
Es una &lt;strong>ilusi√≥n de razonamiento&lt;/strong> tan convincente que a menudo nos hace cuestionar la naturaleza de la inteligencia misma.
Y es, sin duda, una de las maravillas tecnol√≥gicas m√°s grandes de nuestro tiempo.&lt;/p>
&lt;h2 id="bibliograf√≠a">Bibliograf√≠a&lt;/h2>
&lt;div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
&lt;div id="ref-haykin" class="csl-entry">
&lt;p>Haykin, Simon. n.d. ‚ÄúNeural Networks and Learning Machines.‚Äù &lt;a href="http://dni.dali.dartmouth.edu/9umv9yghhaoq/13-dayana-hermann-1/read-0131471392-neural-networks-and-learning-machines.pdf" target="_blank" rel="noopener">http://dni.dali.dartmouth.edu/9umv9yghhaoq/13-dayana-hermann-1/read-0131471392-neural-networks-and-learning-machines.pdf&lt;/a>.&lt;/p>
&lt;/div>
&lt;div id="ref-stanfordonline2024" class="csl-entry">
&lt;p>Stanford Online. 2024. ‚ÄúStanford CS229 i Machine Learning i Building Large Language Models (LLMs),‚Äù August. &lt;a href="https://www.youtube.com/watch?v=9vM4p9NN0Ts" target="_blank" rel="noopener">https://www.youtube.com/watch?v=9vM4p9NN0Ts&lt;/a>.&lt;/p>
&lt;/div>
&lt;div id="ref-vaswani" class="csl-entry">
&lt;p>Vaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. n.d. ‚ÄúAttention Is All You Need.‚Äù &lt;a href="https://doi.org/10.48550/ARXIV.1706.03762" target="_blank" rel="noopener">https://doi.org/10.48550/ARXIV.1706.03762&lt;/a>.&lt;/p>
&lt;/div>
&lt;/div></description></item><item><title>Del Laboratorio al Mundo Real</title><link>https://bioestadisticaedu.com/post/generalizacion/</link><pubDate>Mon, 01 Sep 2025 00:00:00 +0000</pubDate><guid>https://bioestadisticaedu.com/post/generalizacion/</guid><description>&lt;h2 id="introducci√≥n">Introducci√≥n&lt;/h2>
&lt;p>¬øAlguna vez has le√≠do un titular cient√≠fico y te has preguntado: &amp;ldquo;¬øEsto me aplica a m√≠?&amp;rdquo; o &amp;ldquo;Esto suena genial, pero ¬øes relevante para mi realidad?&amp;rdquo; Si es as√≠, has tocado el nervio de uno de los mayores desaf√≠os de la investigaci√≥n: c√≥mo saltar del estudio controlado en un laboratorio al mundo real.&lt;/p>
&lt;p>El v√≠deo, &amp;ldquo;El Estudio y el Mundo&amp;rdquo;, captura esta idea.&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/sY8-YxIeGu8?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video">&lt;/iframe>
&lt;/div>
&lt;p>Este blog profundiza en ese &lt;strong>puente a veces inestable&lt;/strong> que conecta la ciencia con nuestra vida diaria, explicando por qu√© no se trata de desconfiar de la ciencia, sino de entenderla mejor para usarla de la forma m√°s inteligente posible.&lt;/p>
&lt;hr>
&lt;h2 id="los-pilares-fundamentales-validez-interna-y-externa">Los Pilares Fundamentales: Validez Interna y Externa&lt;/h2>
&lt;p>Para que un estudio sea realmente √∫til, sus hallazgos no solo deben ser correctos, sino tambi√©n aplicables. Aqu√≠ es donde entran en juego dos conceptos clave:&lt;/p>
&lt;p>&lt;strong>Validez Interna: ¬øSe hizo bien el estudio?&lt;/strong> Se pregunta si los resultados son fiables para el grupo de personas que realmente participaron en la investigaci√≥n. Un estudio puede ser metodol√≥gicamente impecable y tener una validez interna &amp;ldquo;de 10&amp;rdquo;.&lt;/p>
&lt;p>&lt;strong>Validez Externa: ¬øSirven estos resultados fuera del estudio?&lt;/strong> Se refiere a la capacidad de los hallazgos de un estudio para aplicarse a otros contextos, poblaciones o situaciones. Un estudio perfecto a nivel interno podr√≠a ser casi in√∫til si sus participantes son tan espec√≠ficos que sus resultados no pueden generalizarse.&lt;/p>
&lt;hr>
&lt;h2 id="generalizabilidad-y-transportabilidad-construyendo-el-puente">Generalizabilidad y Transportabilidad: Construyendo el Puente&lt;/h2>
&lt;p>Existen dos estrategias principales para construir ese puente:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Generalizabilidad:&lt;/strong> Piensa en esto como una receta de cocina. Perfeccionaste una tarta en tu &amp;ldquo;cocina de prueba&amp;rdquo; y ahora vas a usar esa misma receta para alimentar a toda la familia. La poblaci√≥n del estudio es solo una parte de un grupo m√°s grande al que quieres aplicar los resultados. Por ejemplo, pasar de un estudio en California a todo Estados Unidos.&lt;/li>
&lt;li>&lt;strong>Transportabilidad:&lt;/strong> Ahora imagina que quieres adaptar esa misma receta para que funcione en otro pa√≠s, con ingredientes diferentes y un horno distinto. Aqu√≠, la poblaci√≥n del estudio es ajena a la poblaci√≥n a la que quieres aplicar los resultados. Se trata de ver si los hallazgos de un estudio en Estados Unidos funcionan en una cl√≠nica en Europa.&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="por-qu√©-es-tan-dif√≠cil-construir-el-puente">¬øPor Qu√© es Tan Dif√≠cil Construir el Puente?&lt;/h2>
&lt;p>La principal dificultad es que los estudios, especialmente los ensayos cl√≠nicos aleatorios (RCTs), a menudo seleccionan a los participantes con criterios muy estrictos para garantizar una alta validez interna. Esto los hace poco representativos de la poblaci√≥n general.&lt;/p>
&lt;ul>
&lt;li>&lt;strong>El Sesgo de Selecci√≥n:&lt;/strong> Ocurre cuando las personas que participan en el estudio son diferentes de la poblaci√≥n a la que se busca aplicar los resultados. No se trata solo de que no sean &amp;ldquo;representativas&amp;rdquo;, sino de que esas diferencias afecten la efectividad del tratamiento.&lt;/li>
&lt;li>&lt;strong>La Trampa de los Confusores:&lt;/strong> Factores no controlados en el estudio pueden generar asociaciones falsas o &amp;ldquo;espurias&amp;rdquo;, ocultando la verdadera relaci√≥n entre el tratamiento y el resultado.&lt;/li>
&lt;li>&lt;strong>El Riesgo de la Subjetividad:&lt;/strong> La estad√≠stica es una herramienta, no una verdad absoluta. La elecci√≥n de variables y la interpretaci√≥n de los resultados requieren un profundo conocimiento y juicio. La subjetividad puede &amp;ldquo;disfrazarse&amp;rdquo; detr√°s de n√∫meros y algoritmos, llevando a conclusiones err√≥neas si no se razona con cuidado. Sin embargo, esta subjetividad no debe confundirse con la arbitrariedad, ya que se basa en la experiencia y el sentido com√∫n del investigador.&lt;/li>
&lt;li>&lt;strong>El Dilema del Tama√±o de Muestra:&lt;/strong> A pesar de lo que se podr√≠a pensar, la determinaci√≥n del tama√±o de muestra de un estudio es m√°s un arte que una ciencia exacta, basada en el juicio y la intuici√≥n, no solo en una f√≥rmula.&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="herramientas-para-construir-un-puente-fuerte">Herramientas para Construir un Puente Fuerte&lt;/h2>
&lt;p>Los estad√≠sticos se dedican a medir la distancia entre el mundo del estudio y el mundo real. Una vez diagnosticado el problema, hay varias estrategias y herramientas para corregir el rumbo:&lt;/p>
&lt;p>&lt;strong>En la Fase de Dise√±o:&lt;/strong>&lt;/p>
&lt;p>La forma ideal es tomar una muestra aleatoria de la poblaci√≥n objetivo, pero esto no siempre es posible. Las alternativas incluyen:&lt;/p>
&lt;p>&lt;strong>Ensayos cl√≠nicos pragm√°ticos:&lt;/strong> Dise√±ados para imitar la pr√°ctica cl√≠nica real y ser m√°s aplicables.&lt;/p>
&lt;p>&lt;strong>Muestreo:&lt;/strong> Seleccionar participantes para asegurar que haya una amplia representaci√≥n o heterogeneidad.&lt;/p>
&lt;p>&lt;strong>Despu√©s de la Recolecci√≥n de Datos (M√©todos Anal√≠ticos):&lt;/strong>&lt;/p>
&lt;p>Si el estudio ya se realiz√≥, se usan m√©todos estad√≠sticos para ajustar los resultados:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Ponderaci√≥n (Weighting):&lt;/strong> Le da m√°s &amp;ldquo;peso&amp;rdquo; a ciertos individuos del estudio para que la muestra se parezca m√°s a la poblaci√≥n real. Es como darles un meg√°fono a las voces que necesitan ser escuchadas.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Regresiones de Resultado:&lt;/strong> Se construyen modelos matem√°ticos para predecir lo que habr√≠a pasado si la gente del mundo real hubiera recibido el tratamiento del estudio.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Enfoques Doblemente Robustos:&lt;/strong> Combinan varias t√©cnicas para obtener resultados m√°s s√≥lidos.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="la-sabidur√≠a-detr√°s-de-los-n√∫meros">La Sabidur√≠a Detr√°s de los N√∫meros&lt;/h2>
&lt;p>La estad√≠stica es una herramienta. Hay un poder inmenso en dominarla, pero tambi√©n un riesgo si se aplica sin un pensamiento cr√≠tico. El peligro de la &amp;ldquo;f√°brica de publicaciones&amp;rdquo; que prioriza la significaci√≥n estad√≠stica (un valor p bajo) a veces eclipsa la relevancia cl√≠nica o biol√≥gica de los hallazgos. No basta con que un resultado sea &amp;ldquo;estad√≠sticamente significativo&amp;rdquo;. Lo realmente importante es si es significativo para la vida de las personas.&lt;/p>
&lt;p>Como se ha destacado, &amp;ldquo;pensar sin observar es un error, pero observar sin pensar es igualmente peligroso.&amp;rdquo; La aplicaci√≥n mec√°nica de un m√©todo poderoso puede llevar a conclusiones err√≥neas.&lt;/p>
&lt;h2 id="tu-papel-como-consumidor-de-ciencia">Tu Papel como Consumidor de Ciencia&lt;/h2>
&lt;p>La pr√≥xima vez que veas un titular impactante, haz la pregunta clave : &lt;strong>&amp;quot;¬øEn qui√©n se hizo este estudio?&amp;quot;&lt;/strong>&lt;/p>
&lt;p>Al entender la generalizabilidad y la transportabilidad, te conviertes en un consumidor de ciencia m√°s cr√≠tico e informado. La verdadera meta no es solo que los estudios sean rigurosos, sino que su conocimiento pueda cruzar ese puente de forma segura y tener un impacto genuino en nuestras vidas. Porque, al final, una ciencia que no puede ser aplicada al mundo real pierde gran parte de su valor.&lt;/p>
&lt;h2 id="biblograf√≠a">Biblograf√≠a&lt;/h2>
&lt;ol>
&lt;li>Degtiar I, Rose S. A Review of Generalizability and Transportability. Annual Review of Statistics and Its Application [Internet]. 9 de marzo de 2023 [citado 1 de septiembre de 2025];10(Volume 10, 2023):501-24. Disponible en: &lt;a href="https://www.annualreviews.org/content/journals/10.1146/annurev-statistics-042522-103837" target="_blank" rel="noopener">https://www.annualreviews.org/content/journals/10.1146/annurev-statistics-042522-103837&lt;/a>&lt;/li>
&lt;/ol></description></item><item><title>Inferencia Causal, Desvelando la L√≥gica Matem√°tica Detr√°s de Causa y Efecto</title><link>https://bioestadisticaedu.com/post/inferencia-causal/</link><pubDate>Mon, 01 Sep 2025 00:00:00 +0000</pubDate><guid>https://bioestadisticaedu.com/post/inferencia-causal/</guid><description>&lt;h2 id="introducci√≥n">Introducci√≥n&lt;/h2>
&lt;p>El &lt;strong>marco de resultados potenciales&lt;/strong> se mantiene como la piedra angular del pensamiento causal, proporcionando el andamiaje conceptual para diferenciar la mera correlaci√≥n de la causalidad. Ante la imposibilidad de llevar a cabo &lt;strong>ensayos controlados aleatorizados (RCT)&lt;/strong>, la investigaci√≥n se ha nutrido de &lt;strong>m√©todos robustos&lt;/strong> que permiten extraer inferencias causales cre√≠bles de datos observacionales. En este contexto, herramientas como el &lt;strong>Propensity Score&lt;/strong> y los &lt;strong>estimadores doblemente robustos&lt;/strong> (DR) se utilizan para controlar los sesgos de selecci√≥n a partir de covariables observables, mientras que los &lt;strong>Efectos de Tratamiento Promedio Condicionales (CATE)&lt;/strong>, apoyados en machine learning, permiten explorar la heterogeneidad del efecto entre subpoblaciones. Asimismo, un conjunto de estrategias cuasi-experimentales ha abierto nuevos horizontes en la investigaci√≥n, incluyendo el uso de &lt;strong>Variables Instrumentales (IV)&lt;/strong> para corregir la confusi√≥n no observada, el &lt;strong>Diferencias-en-Diferencias (DID)&lt;/strong> y el &lt;strong>Control Sint√©tico (SC)&lt;/strong> para comparar trayectorias temporales, y la &lt;strong>Regresi√≥n Discontinua (RDD)&lt;/strong> para explotar umbrales de asignaci√≥n, todas ellas permitiendo identificar efectos causales en contextos donde la aleatorizaci√≥n no es factible.&lt;/p>
&lt;hr>
&lt;h2 id="1-el-desaf√≠o-central-solo-vemos-un-lado-de-la-moneda">1. El desaf√≠o central: solo vemos un lado de la moneda&lt;/h2>
&lt;p>Imagina que quieres evaluar el impacto de una nueva pol√≠tica de vacunaci√≥n. Para cada persona, podr√≠amos definir dos mundos posibles: uno donde recibe la vacuna y otro donde no. Pero en la pr√°ctica solo observamos un mundo: el que ocurri√≥. Ese es el &lt;strong>‚Äúproblema fundamental de la inferencia causal‚Äù&lt;/strong>.&lt;/p>
&lt;p>El &lt;strong>marco de resultados potenciales&lt;/strong> formaliza esta idea:&lt;/p>
$$
\tau_{\text{sample}} = \frac{1}{N} \sum_{i=1}^{N} (Y_i(1) - Y_i(0))
$$
&lt;p>En un ensayo controlado aleatorizado (RCT), la aleatorizaci√≥n nos permite estimar este efecto promedio simplemente comparando medias. Pero ¬øqu√© pasa cuando los RCT no son factibles por razones √©ticas, log√≠sticas o econ√≥micas?&lt;/p>
&lt;hr>
&lt;h2 id="2-estudios-observacionales-cuando-no-hay-azar-pero-s√≠-ingenio">2. Estudios observacionales: cuando no hay azar, pero s√≠ ingenio&lt;/h2>
&lt;p>En contextos reales ‚Äîsalud p√∫blica, econom√≠a, pol√≠ticas sociales‚Äî dependemos de datos observacionales. All√≠, la clave es suponer que, condicional en ciertas variables previas ($X_i$), la asignaci√≥n al tratamiento es ‚Äútan buena como aleatoria‚Äù.&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Propensity Score (Rosenbaum &amp;amp; Rubin, 1983):&lt;/strong> condensa m√∫ltiples covariables en una √∫nica probabilidad de recibir tratamiento, facilitando el emparejamiento y la ponderaci√≥n.&lt;/li>
&lt;li>&lt;strong>Estimadores doblemente robustos:&lt;/strong> combinan modelos de resultado y de asignaci√≥n al tratamiento; basta con que uno est√© bien especificado para obtener estimaciones consistentes.&lt;/li>
&lt;li>&lt;strong>CATE (Conditional Average Treatment Effect):&lt;/strong> con machine learning, hoy podemos explorar c√≥mo los efectos var√≠an entre subpoblaciones (ej. pol√≠ticas de empleo m√°s efectivas en j√≥venes que en adultos mayores).&lt;/li>
&lt;/ul>
&lt;p>‚ö†Ô∏è Cuando sospechamos de confusi√≥n no observada, entran en juego &lt;strong>an√°lisis de sensibilidad&lt;/strong> (Manski bounds, m√©todos de Rosenbaum).&lt;/p>
&lt;hr>
&lt;h2 id="3-estrategias-avanzadas-cuando-la-confusi√≥n-no-puede-ignorarse">3. Estrategias avanzadas cuando la confusi√≥n no puede ignorarse&lt;/h2>
&lt;h3 id="a-variables-instrumentales-iv">a) Variables Instrumentales (IV)&lt;/h3>
&lt;p>Si un confusor no observado afecta tanto al tratamiento como al resultado, un &lt;strong>instrumento v√°lido&lt;/strong> ($Z$) puede rescatar el an√°lisis. Ejemplo cl√°sico: la distancia a una universidad como instrumento para estudiar el impacto de la educaci√≥n en ingresos.&lt;/p>
&lt;p>Bajo ciertos supuestos, identificamos el &lt;strong>LATE (Local Average Treatment Effect)&lt;/strong> para quienes cambian su estado de tratamiento debido al instrumento.&lt;/p>
&lt;hr>
&lt;h3 id="b-diferencias-en-diferencias-did-y-control-sint√©tico-sc">b) Diferencias-en-Diferencias (DID) y Control Sint√©tico (SC)&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>DID&lt;/strong>: compara tendencias pre y post en grupos tratados y no tratados. Ejemplo: medir el impacto de un aumento del salario m√≠nimo sobre el empleo.&lt;/li>
&lt;li>&lt;strong>SC&lt;/strong>: construye un ‚Äúgemelo sint√©tico‚Äù de la unidad tratada combinando unidades no tratadas. Ejemplo: evaluar el impacto de una ley antitabaco en California comparando con un control sint√©tico formado por otros estados.&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h3 id="c-regresi√≥n-discontinua-rdd">c) Regresi√≥n Discontinua (RDD)&lt;/h3>
&lt;p>Aprovecha umbrales de asignaci√≥n. Ejemplo: un programa de becas asignado a estudiantes con notas ‚â• 8.0. Comparar resultados justo por encima y por debajo del corte estima el efecto del programa en los ‚Äúmarginales‚Äù.&lt;/p>
&lt;hr>
&lt;h2 id="4-horizontes-emergentes-combinar-evidencia">4. Horizontes emergentes: combinar evidencia&lt;/h2>
&lt;p>Dos l√≠neas prometedoras:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Surrogacy:&lt;/strong> usar resultados a corto plazo como sustitutos de resultados de largo plazo.&lt;/li>
&lt;li>&lt;strong>Integraci√≥n de experimentos y observacionales:&lt;/strong> Athey et al. (2020) proponen usar experimentos para identificar y corregir confusores en estudios observacionales.&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>Tabla comparativa de m√©todos de inferencia causal&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>M√©todo&lt;/th>
&lt;th>Supuesto clave&lt;/th>
&lt;th>Ventajas&lt;/th>
&lt;th>Limitaciones&lt;/th>
&lt;th>Ejemplo t√≠pico&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;strong>RCT&lt;/strong>&lt;/td>
&lt;td>Asignaci√≥n aleatoria&lt;/td>
&lt;td>Estimador insesgado, alta validez interna&lt;/td>
&lt;td>Costoso, a veces poco √©tico, baja validez externa&lt;/td>
&lt;td>Ensayo cl√≠nico de un f√°rmaco&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Propensity Score / DR&lt;/strong>&lt;/td>
&lt;td>Confusi√≥n controlada por covariables observadas&lt;/td>
&lt;td>Flexibilidad, usa datos observacionales grandes&lt;/td>
&lt;td>Vulnerable a confusi√≥n no observada&lt;/td>
&lt;td>Impacto de programas sociales&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>IV&lt;/strong>&lt;/td>
&lt;td>Relevancia + exclusi√≥n + exogeneidad&lt;/td>
&lt;td>Corrige confusi√≥n no observada&lt;/td>
&lt;td>Dif√≠cil encontrar instrumentos v√°lidos&lt;/td>
&lt;td>Educaci√≥n ‚Üí ingresos&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>DID&lt;/strong>&lt;/td>
&lt;td>Tendencias paralelas&lt;/td>
&lt;td>Simple, interpretable&lt;/td>
&lt;td>Fr√°gil si tendencias difieren&lt;/td>
&lt;td>Pol√≠ticas laborales&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>SC&lt;/strong>&lt;/td>
&lt;td>Unidades control combinan bien la pre-tendencia&lt;/td>
&lt;td>M√°s cre√≠ble que DID en casos individuales&lt;/td>
&lt;td>Requiere datos ricos pre-tratamiento&lt;/td>
&lt;td>Leyes de salud p√∫blica&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>RDD&lt;/strong>&lt;/td>
&lt;td>Continuidad de potenciales en el umbral&lt;/td>
&lt;td>Interpretaci√≥n clara, dise√±o cuasi-experimental&lt;/td>
&lt;td>V√°lido solo cerca del umbral&lt;/td>
&lt;td>Programas de becas&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;hr>
&lt;h2 id="5-conclusi√≥n-pr√°ctica">5. Conclusi√≥n pr√°ctica&lt;/h2>
&lt;p>La inferencia causal no es una caja negra: es un conjunto de &lt;strong>herramientas matem√°ticas y conceptuales&lt;/strong> que, bien aplicadas, permiten a responsables de pol√≠ticas, cl√≠nicos y cient√≠ficos sociales responder la pregunta clave: &lt;em>¬øqu√© pasar√≠a si?&lt;/em>&lt;/p>
&lt;p>La frontera actual est√° en combinar evidencia, explotar machine learning para heterogeneidad y desarrollar m√©todos m√°s robustos frente a confusi√≥n no observada.&lt;/p>
&lt;hr>
&lt;h2 id="-referencias">üìö Referencias&lt;/h2>
&lt;ul>
&lt;li>Rosenbaum PR, Rubin DB. &lt;em>The central role of the propensity score‚Ä¶&lt;/em> Biometrika. 1983. &lt;a href="https://pubmed.ncbi.nlm.nih.gov/12009849/" target="_blank" rel="noopener">PubMed PMID: 12009849&lt;/a>&lt;/li>
&lt;li>Hern√°n MA, Robins JM. &lt;em>Causal Inference: What If&lt;/em>. 2020. &lt;a href="https://pubmed.ncbi.nlm.nih.gov/33290294/" target="_blank" rel="noopener">PubMed PMID: 33290294&lt;/a>&lt;/li>
&lt;li>Imbens GW, Rubin DB. &lt;em>Causal Inference for Statistics, Social, and Biomedical Sciences&lt;/em>. 2015.&lt;/li>
&lt;li>Athey S, Imbens GW. &lt;em>Design-based analysis in difference-in-differences settings.&lt;/em> J Econometrics. 2022. &lt;a href="https://pubmed.ncbi.nlm.nih.gov/36212825/" target="_blank" rel="noopener">PubMed PMID: 36212825&lt;/a>&lt;/li>
&lt;li>Abadie A. &lt;em>Using synthetic controls.&lt;/em> J Econometrics. 2021.&lt;/li>
&lt;/ul></description></item><item><title>Significaci√≥n Estad√≠stica, ¬øCiencia o Pirotecnia?</title><link>https://bioestadisticaedu.com/post/2025-08-10-significacion/</link><pubDate>Sun, 10 Aug 2025 15:30:00 +0000</pubDate><guid>https://bioestadisticaedu.com/post/2025-08-10-significacion/</guid><description>&lt;h2 id="introducci√≥n">Introducci√≥n&lt;/h2>
&lt;p>Ese momento de euforia al ver &lt;code>p &amp;lt; 0.05&lt;/code>‚Ä¶ ¬øes un descubrimiento genuino o solo un destello enga√±oso de pirotecnia estad√≠stica?&lt;/p>
&lt;p>En la ciencia, hay un instante que todos los investigadores anhelan. Es la culminaci√≥n de meses, a veces a√±os, de riguroso trabajo. Corres el an√°lisis y, de repente, ah√≠ est√°: &lt;code>p &amp;lt; 0.05&lt;/code>. Es una &lt;strong>explosi√≥n de alivio&lt;/strong>, un destello de ‚Äú¬°Eureka!‚Äù en la oscuridad de la incertidumbre. Sentimos que hemos encontrado algo real, algo digno de ser publicado.&lt;/p>
&lt;p>Pero, ¬øy si ese destello es solo eso? Un estallido moment√°neo, deslumbrante y ruidoso, pero que en el fondo significa muy poco. ¬øY si nuestro ritual m√°s sagrado es, en realidad, un simple juego de pirotecnia, dise√±ado para impresionar m√°s que para iluminar?&lt;/p>
&lt;p>Durante d√©cadas, hemos aceptado el umbral de significaci√≥n estad√≠stica como el √°rbitro indiscutible de la verdad cient√≠fica. Sin embargo, la evidencia acumulada ‚Äîdesde las cr√≠ticas de su propio creador (Ronald Fisher) hasta las advertencias oficiales de la American Statistical Association (ASA) en 2016 y el clamor de cientos de cient√≠ficos en la revista &lt;em>Nature&lt;/em> ‚Äî nos obliga a una conclusi√≥n inc√≥moda(Amrhein, Greenland, and McShane 2019; Wasserstein and Lazar 2016) : &lt;strong>el emperador estad√≠stico est√° desnudo&lt;/strong>. La pr√°ctica de las Pruebas de Significaci√≥n de la Hip√≥tesis Nula (NHST, por sus siglas en ingl√©s) no es un pilar de rigor, sino un ritual plagado de l√≥gica err√≥nea, confusi√≥n e inadecuaci√≥n para la verdadera investigaci√≥n.&lt;/p>
&lt;h2 id="el-cohete-m√°s-grande-no-significa-mejor">El Cohete: M√°s Grande no Significa Mejor&lt;/h2>
&lt;p>En la pirotecnia, un cohete m√°s grande produce una explosi√≥n m√°s fuerte. Es simple f√≠sica. En la estad√≠stica, ocurre algo perturbadoramente similar. El ‚Äúcohete‚Äù es nuestro tama√±o muestral.&lt;/p>
&lt;p>La conclusi√≥n de una prueba de significaci√≥n depende de manera crucial del tama√±o de la muestra. Con un cohete lo suficientemente grande (una muestra de miles o decenas de miles de personas), la diferencia m√°s trivial e insignificante para el mundo real se convertir√°, casi por arte de magia, en ‚Äúestad√≠sticamente significativa‚Äù. Por el contrario, un efecto importante y real puede pasar desapercibido si nuestro cohete es demasiado peque√±o.&lt;/p>
&lt;p>Esto nos lleva a una &lt;strong>verdad grotesca&lt;/strong>: la decisi√≥n sobre si un hallazgo es ‚Äúreal‚Äù a menudo depende m√°s de los recursos del investigador para recolectar datos masivos que de la naturaleza fundamental del fen√≥meno estudiado. El estallido nos dice m√°s sobre el tama√±o del cohete que sobre la belleza del cielo que intenta iluminar.&lt;/p>
&lt;!-- ```{r} -->
&lt;!-- set.seed(123) -->
&lt;!-- library(ggplot2) -->
&lt;!-- effect &lt;- 0.1 -->
&lt;!-- sd &lt;- 1 -->
&lt;!-- N &lt;- seq(20, 10000, by=50) -->
&lt;!-- p_values &lt;- sapply(N, function(n) { -->
&lt;!-- t.test(rnorm(n, mean=effect, sd=sd), mu=0)$p.value -->
&lt;!-- }) -->
&lt;!-- data &lt;- data.frame(N, p_values) -->
&lt;!-- ggplot(data, aes(N, p_values)) + -->
&lt;!-- geom_line() + -->
&lt;!-- geom_hline(yintercept = 0.05, linetype = "dashed", color="red") + -->
&lt;!-- labs(x = "Tama√±o muestral (N)", y = "Valor p") + -->
&lt;!-- theme_minimal() -->
&lt;!-- ``` -->
&lt;!-- Aqu√≠ ir√≠a tu gr√°fico explicativo del "Cohete (Tama√±o Muestral)": -->
&lt;!-- Un gr√°fico mostrando c√≥mo un efecto trivial (ej: diferencia de 0.1 unidades) se vuelve "significativo" (p&lt;0.05) a medida que N aumenta de 100 a 10,000. Puedes usar `ggplot2` en R para esto. -->
&lt;!-- Ejemplo de c√≥digo R (este no generar√≠a un gr√°fico, solo un placeholder para tu referencia): -->
&lt;!-- ```{r cohete_plot, echo=FALSE, fig.cap="Impacto del tama√±o muestral en la significaci√≥n estad√≠stica para un efecto constante."} -->
&lt;!-- # C√≥digo para generar el gr√°fico de N vs p-valor -->
&lt;!-- # plot(your_data$N, your_data$p_value, type="l", main="C√≥mo N afecta el p-valor", -->
&lt;!-- # xlab="Tama√±o Muestral (N)", ylab="Valor p") -->
&lt;!-- # abline(h=0.05, col="red", lty=2) -->
&lt;!-- ``` -->
&lt;h2 id="la-explosi√≥n-un-caos-de-luz-y-malentendidos">La Explosi√≥n: Un Caos de Luz y Malentendidos&lt;/h2>
&lt;p>La explosi√≥n de un fuego artificial es un evento ca√≥tico. Su interpretaci√≥n es subjetiva. ¬øFue espectacular? ¬øFue un fracaso? Lo mismo ocurre con el valor &lt;em>p&lt;/em>.&lt;/p>
&lt;h2 id="l√≥gica-err√≥nea-juzgando-por-lo-que-no-vimos">L√≥gica Err√≥nea: Juzgando por lo que no Vimos&lt;/h2>
&lt;p>La l√≥gica detr√°s del valor &lt;em>p&lt;/em> es, siendo generosos, peculiar. Se calcula asumiendo que la hip√≥tesis nula (H‚ÇÄ ‚Äîla hip√≥tesis de no-efecto, de que no hay diferencia o relaci√≥n) es cierta, y luego se determina la probabilidad de haber observado nuestros datos &lt;em>o datos a√∫n m√°s extremos&lt;/em> bajo esa suposici√≥n. Pi√©nsalo: nuestra conclusi√≥n sobre lo que &lt;em>s√≠&lt;/em> ocurri√≥ depende de la probabilidad de cosas que ni siquiera presenciamos. Es un &lt;strong>absurdo subyacente&lt;/strong>.&lt;/p>
&lt;p>Adem√°s, caemos constantemente en la &lt;strong>falacia de la probabilidad invertida&lt;/strong>: el valor &lt;em>p&lt;/em> nos dice la probabilidad de los datos dada la hip√≥tesis nula (P(Datos|H‚ÇÄ)), pero nosotros creemos err√≥neamente que nos dice la probabilidad de que la hip√≥tesis nula sea cierta dados nuestros datos (P(H‚ÇÄ|Datos)). Son dos cosas radicalmente distintas, y confundirlas es un error fundamental.&lt;/p>
&lt;!-- &lt;!-- Aqu√≠ ir√≠a tu diagrama de flujo simple o tabla comparativa para "Confusi√≥n P(D|H) vs P(H|D)": -->
&lt;!-- Puedes usarmermaid para diagramas simples en RMarkdown o una tabla Markdown para la comparaci√≥n. -->
&lt;!-- Ejemplo de c√≥digo mermaid (necesitar√≠as `config: {mermaid: {sequence: {diagramMarginX: 10}}}` en el YAML para que funcione): -->
&lt;h2 id="confusi√≥n-el-ruido-no-es-la-se√±al">Confusi√≥n: El Ruido no es la Se√±al&lt;/h2>
&lt;p>La confusi√≥n m√°s extendida es la de equiparar ‚Äúsignificaci√≥n estad√≠stica‚Äù con ‚Äúimportancia pr√°ctica‚Äù o ‚Äúrelevancia cient√≠fica‚Äù. Un estallido muy ruidoso no significa que el descubrimiento sea importante, √∫til o generalizable. Esta obsesi√≥n por el ruido estad√≠stico, esta end√©mica ‚Äúsignificant-itis‚Äù, nos ha distra√≠do de lo que realmente importa en la investigaci√≥n: la magnitud del efecto y la relevancia cl√≠nica, social o te√≥rica de nuestros hallazgos.&lt;/p>
&lt;h2 id="el-caso-del-chocolate-que-hace-perder-peso">El Caso del Chocolate que Hace Perder Peso&lt;/h2>
&lt;p>Para ilustrar esta locura, consideremos el tristemente famoso estudio de John Bohannon en 2015, ‚ÄúChocolate con fines de p√©rdida de peso‚Äù . Con un peque√±o presupuesto, Bohannon realiz√≥ un ensayo aleatorio, controlado con chocolate, utilizando un n√∫mero muy reducido de participantes y midiendo 18 variables distintas(Bohannon 2015). Al analizar &lt;em>todas&lt;/em> las combinaciones posibles, encontr√≥ que con una muestra tan peque√±a y al realizar m√∫ltiples pruebas (un tipo de &lt;em>p-hacking&lt;/em>), era casi inevitable que alguna variable arrojara un p-valor menor a 0.05 &lt;strong>por pura casualidad&lt;/strong>. Con su &lt;code>p &amp;lt; 0.05&lt;/code> ‚Äúsignificativo‚Äù, los medios de comunicaci√≥n sensacionalistas se lanzaron a la noticia: ‚ÄúEl chocolate hace perder peso!‚Äù. Este caso es un claro ejemplo de c√≥mo un ‚Äúdestello‚Äù estad√≠stico puede ser completamente enga√±oso y carecer de cualquier importancia real, pero aun as√≠ generar titulares y confusi√≥n(Bohannon 2015).&lt;/p>
&lt;h2 id="el-veredicto-la-falsa-dicotom√≠a-del-ohhh-o-el-silencio">El Veredicto: La Falsa Dicotom√≠a del ‚ÄúOhhh‚Äù o el Silencio&lt;/h2>
&lt;p>Quien observa fuegos artificiales emite un veredicto simple: el ‚Äú¬°Ohhh!‚Äù de asombro o el silencio de la indiferencia. Las pruebas de significaci√≥n nos han impuesto esta misma decisi√≥n binaria: o un resultado es significativo (&lt;code>p &amp;lt; 0.05&lt;/code>), o no lo es. Es un interruptor de encendido/apagado.&lt;/p>
&lt;p>Pero la ciencia no funciona as√≠. El conocimiento cient√≠fico no es una serie de decisiones de ‚Äús√≠/no‚Äù. Es un proceso gradual de ajuste de nuestras creencias a la luz de la evidencia acumulada. Es un paisaje de grises, no un contraste de blanco y negro. Al forzarnos a este mecanicismo, a esta ‚Äúsucesi√≥n de ‚Äòdecisiones‚Äô autom√°ticas‚Äù que el propio Fisher denunci√≥, hemos empobrecido el discurso cient√≠fico, ignorando matices cruciales como la magnitud del efecto o la precisi√≥n de la estimaci√≥n.&lt;/p>
&lt;h2 id="despu√©s-del-humo-hacia-una-ciencia-iluminada">Despu√©s del Humo: Hacia una Ciencia Iluminada&lt;/h2>
&lt;p>Cuando el humo de la pirotecnia se disipa, ¬øqu√© nos queda? Nos queda la tarea de encontrar una luz m√°s honesta y duradera para la ciencia. Afortunadamente, esta luz existe y est√° ganando terreno.&lt;/p>
&lt;p>La alternativa fundamental es pasar de la &lt;strong>decisi√≥n binaria&lt;/strong> a la &lt;strong>estimaci√≥n&lt;/strong>. En lugar de preguntar obsesivamente ‚Äú¬øHay un efecto (s√≠/no)?‚Äù, debemos preguntar ‚Äú¬øCu√°l es la magnitud del efecto y cu√°n seguros estamos de esa estimaci√≥n?‚Äù.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Intervalos de Confianza (o de Compatibilidad):&lt;/strong> Son nuestra primera y m√°s accesible herramienta para una inferencia m√°s sensata. Los Intervalos de Confianza no nos dan un simple ‚Äús√≠/no‚Äù, sino un &lt;strong>rango de valores plausibles&lt;/strong> para el efecto real en la poblaci√≥n. Nos muestran tanto la magnitud estimada del efecto como la incertidumbre que lo rodea.&lt;/p>
&lt;p>Cuando vemos un Intervalo de Confianza del 95% para una diferencia, por ejemplo, esto significa que si repiti√©ramos el estudio muchas, muchas veces bajo las mismas condiciones, el 95% de esos intervalos contendr√≠an el verdadero valor del efecto que estamos tratando de estimar. Nos invitan a pensar en la variabilidad y la precisi√≥n de nuestras estimaciones, no solo en un umbral arbitrario. Son una luz constante que ilumina un paisaje, permiti√©ndonos ver el terreno completo, no un destello que ciega moment√°neamente.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;!-- &lt;!-- Aqu√≠ ir√≠a tu gr√°fico de "Intervalos de Confianza/Compatibilidad": -->
&lt;!-- Un gr√°fico con varios ICs superpuestos (algunos estrechos, otros anchos, algunos cruzando cero, otros no) para ilustrar que muestran magnitud *e* incertidumbre, no solo "s√≠/no". -->
&lt;!-- ```{r ic_plot, echo=FALSE, fig.cap="Visualizaci√≥n de Intervalos de Confianza: Magnitud y Incertidumbre."} -->
&lt;!-- # C√≥digo para generar el gr√°fico de ICs -->
&lt;!-- # library(ggplot2) -->
&lt;!-- # data.frame( -->
&lt;!-- # Effect = c(0.5, 1.2, -0.3, 0.8), -->
&lt;!-- # Lower = c(0.1, 0.8, -0.7, 0.2), -->
&lt;!-- # Upper = c(0.9, 1.6, 0.1, 1.4) -->
&lt;!-- # ) %>% -->
&lt;!-- # ggplot(aes(y = factor(1:4), x = Effect, xmin = Lower, xmax = Upper)) + -->
&lt;!-- # geom_point() + geom_errorbarh(height = 0.2) + -->
&lt;!-- # geom_vline(xintercept = 0, linetype = "dashed", color = "grey") + -->
&lt;!-- # labs(x = "Magnitud del Efecto", y = "Estudio") + -->
&lt;!-- # theme_minimal() -->
&lt;!-- ``` -->
&lt;!-- -->
&lt;ul>
&lt;li>
&lt;p>&lt;strong>El Enfoque Bayesiano:&lt;/strong> Es el siguiente paso evolutivo en la inferencia estad√≠stica, y es la encarnaci√≥n matem√°tica del razonamiento cient√≠fico. Los m√©todos bayesianos nos permiten hacer lo que siempre hemos querido hacer: &lt;strong>combinar la evidencia de nuestro estudio actual con todo el conocimiento previo existente&lt;/strong> (estudios anteriores, plausibilidad biol√≥gica, experiencia cl√≠nica) para llegar a una conclusi√≥n actualizada y probabil√≠stica sobre nuestras hip√≥tesis.&lt;/p>
&lt;p>A diferencia del valor &lt;em>p&lt;/em>, el enfoque bayesiano responde directamente a la pregunta que realmente queremos hacer: ‚Äú&lt;strong>Dados estos nuevos datos, ¬øqu√© tan cre√≠ble es mi hip√≥tesis ahora?&lt;/strong>‚Äù. Nos da una probabilidad posterior de nuestra hip√≥tesis, una medida directa de nuestra creencia actualizada. Aunque puede parecer m√°s complejo al principio, el razonamiento bayesiano se alinea intuitivamente con c√≥mo los cient√≠ficos y las personas actualizan sus creencias en la vida real.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Dejemos la pirotecnia para las celebraciones. Es hora de que la ciencia deje de buscar destellos ef√≠meros y se dedique a construir una iluminaci√≥n constante, acumulativa y, sobre todo, &lt;strong>honesta&lt;/strong>. Es el momento de una ciencia m√°s transparente, rigurosa y, s√≠, ¬°m√°s divertida de interpretar!&lt;/p>
&lt;hr>
&lt;h2 id="tu-turno">¬°Tu Turno!&lt;/h2>
&lt;p>¬øTe has encontrado con la ‚Äútiran√≠a del p&amp;lt;0.05‚Äù en tu campo? ¬øQu√© alternativas usas o te gustar√≠a ver m√°s promovidas en la investigaci√≥n? ¬°Comparte tu experiencia y tus pensamientos en los comentarios a continuaci√≥n!&lt;/p>
&lt;hr>
&lt;h2 id="referencias">Referencias&lt;/h2>
&lt;div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
&lt;div id="ref-amrhein2019" class="csl-entry">
&lt;p>Amrhein, Valentin, Sander Greenland, and Blake McShane. 2019. ‚ÄúScientists Rise up Against Statistical Significance.‚Äù &lt;em>Nature&lt;/em> 567 (7748): 305‚Äì7. &lt;a href="https://doi.org/10.1038/d41586-019-00857-9" target="_blank" rel="noopener">https://doi.org/10.1038/d41586-019-00857-9&lt;/a>.&lt;/p>
&lt;/div>
&lt;div id="ref-bohannon2015" class="csl-entry">
&lt;p>Bohannon, John. 2015. ‚ÄúI Fooled Millions into Thinking Chocolate Helps Weight Loss. Here‚Äôs How.‚Äù &lt;a href="https://gizmodo.com/i-fooled-millions-into-thinking-chocolate-helps-weight-1707251800" target="_blank" rel="noopener">https://gizmodo.com/i-fooled-millions-into-thinking-chocolate-helps-weight-1707251800&lt;/a>.&lt;/p>
&lt;/div>
&lt;div id="ref-wasserstein2016" class="csl-entry">
&lt;p>Wasserstein, Ronald L., and Nicole A. Lazar. 2016. ‚ÄúThe ASA Statement on &lt;em>p&lt;/em> -Values: Context, Process, and Purpose.‚Äù &lt;em>The American Statistician&lt;/em> 70 (2): 129‚Äì33. &lt;a href="https://doi.org/10.1080/00031305.2016.1154108" target="_blank" rel="noopener">https://doi.org/10.1080/00031305.2016.1154108&lt;/a>.&lt;/p>
&lt;/div>
&lt;/div></description></item><item><title>Dise√±os Alternativos a Ensayos Cl√≠nicos Controlados Aleatorizados: Contextos de Aplicaci√≥n y Riesgos Regulatorios</title><link>https://bioestadisticaedu.com/post/atajos/</link><pubDate>Thu, 07 Aug 2025 00:00:00 +0000</pubDate><guid>https://bioestadisticaedu.com/post/atajos/</guid><description>&lt;p>üéß &lt;strong>Escucha el podcast de esta publicaci√≥n&lt;/strong>
&lt;audio controls >
&lt;source src="https://bioestadisticaedu.com/mp3/atajos.mp3" type="audio/mpeg">
&lt;/audio>
&lt;/p>
&lt;h2 id="introducci√≥n">Introducci√≥n&lt;/h2>
&lt;p>Los ensayos cl√≠nicos controlados, aleatorizados y enmascarados (ECAs) constituyen el marco metodol√≥gico m√°s robusto para evaluar la &lt;strong>eficacia y seguridad&lt;/strong> de nuevas intervenciones terap√©uticas. Son considerados el &amp;ldquo;est√°ndar de oro&amp;rdquo; en investigaci√≥n cl√≠nica por agencias como &lt;strong>ICH, EMA y FDA&lt;/strong>, ya que proporcionan el mayor control contra el sesgo y la mayor solidez en inferencia causal.&lt;/p>
&lt;p>En este marco, los &lt;strong>ensayos confirmatorios&lt;/strong> son aquellos dise√±ados expl√≠citamente para confirmar hip√≥tesis cl√≠nicas relevantes, con base en an√°lisis predefinidos y control adecuado de errores. Cuando estos estudios sustentan una solicitud de comercializaci√≥n, adquieren la condici√≥n de &lt;strong>ensayos pivotal&lt;/strong> (terminolog√≠a empleada por FDA y EMA).&lt;/p>
&lt;p>En principio, se recomienda la presentaci√≥n de &lt;strong>dos ensayos confirmatorios independientes&lt;/strong>. Sin embargo, &lt;strong>tanto EMA como FDA&lt;/strong> contemplan aprobaciones basadas en &lt;strong>un √∫nico ensayo pivotal&lt;/strong>, siempre que est√© respaldado por &lt;strong>evidencia complementaria rigurosa&lt;/strong>. La &lt;strong>FDA&lt;/strong>, mediante el concepto de &lt;strong>evidencia confirmatoria&lt;/strong> (FDA 2023), formaliza esta v√≠a alternativa. La &lt;strong>EMA&lt;/strong>, aunque no utiliza esa denominaci√≥n, acepta enfoques equivalentes (meta-an√°lisis, controles hist√≥ricos validados, an√°lisis de consistencia interna).&lt;/p>
&lt;h2 id="tabla-1-t√©rminos-clave-definici√≥n-origen-normativo-y-funci√≥n-regulatoria">Tabla 1. T√©rminos clave: definici√≥n, origen normativo y funci√≥n regulatoria&lt;/h2>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;strong>T√©rmino&lt;/strong>&lt;/th>
&lt;th>&lt;strong>Fuente regulatoria&lt;/strong>&lt;/th>
&lt;th>&lt;strong>Definici√≥n t√©cnica&lt;/strong>&lt;/th>
&lt;th>&lt;strong>Funci√≥n regulatoria&lt;/strong>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;strong>Ensayo cl√≠nico confirmatorio&lt;/strong>&lt;/td>
&lt;td>ICH E9&lt;/td>
&lt;td>Estudio con hip√≥tesis expl√≠cita, an√°lisis planificado y dise√±o robusto para inferencia causal.&lt;/td>
&lt;td>Fuente principal de evidencia en autorizaciones de comercializaci√≥n.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Ensayo pivotal&lt;/strong>&lt;/td>
&lt;td>FDA, EMA&lt;/td>
&lt;td>Estudio esencial para demostrar eficacia y seguridad en el expediente regulatorio.&lt;/td>
&lt;td>Sustento central del dossier cl√≠nico.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Evidencia confirmatoria&lt;/strong>&lt;/td>
&lt;td>FDA (2023)&lt;/td>
&lt;td>Datos adicionales (cl√≠nicos/no cl√≠nicos) que refuerzan un ensayo pivotal √∫nico.&lt;/td>
&lt;td>Permite cumplir el est√°ndar de &amp;ldquo;evidencia sustancial&amp;rdquo; con un solo ECA.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Evidencia sustancial&lt;/strong>&lt;/td>
&lt;td>FDA (21 CFR 314.126)&lt;/td>
&lt;td>Est√°ndar legal que puede cumplirse mediante 2 ECAs o, cuando est√© justificado, 1 ECA + confirmaci√≥n.&lt;/td>
&lt;td>Requisito para la aprobaci√≥n de nuevos medicamentos en EE.UU.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Evidencia complementaria&lt;/strong>&lt;/td>
&lt;td>ICH E9; EMA, FDA&lt;/td>
&lt;td>Estudios no pivotal que aportan consistencia (ej. subgrupos, dosis, seguridad, datos externos).&lt;/td>
&lt;td>Reforzar la plausibilidad de los hallazgos principales.&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;hr>
&lt;h1 id="estructura-metodol√≥gica-de-los-ecas-y-su-anclaje-normativo">Estructura metodol√≥gica de los ECAs y su anclaje normativo&lt;/h1>
&lt;p>Los ECAs incorporan tres garant√≠as fundamentales: &lt;strong>aleatorizaci√≥n&lt;/strong>, &lt;strong>grupo control&lt;/strong> y &lt;strong>cegamiento&lt;/strong>. Estos componentes son esenciales para maximizar la validez interna y minimizar fuentes de sesgo sistem√°tico.&lt;/p>
&lt;h2 id="tabla-2-garant√≠as-anti-sesgo-en-ecas">Tabla 2. Garant√≠as anti-sesgo en ECAs&lt;/h2>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;strong>Componente metodol√≥gico&lt;/strong>&lt;/th>
&lt;th>&lt;strong>Funci√≥n espec√≠fica&lt;/strong>&lt;/th>
&lt;th>&lt;strong>C√≥mo reduce el sesgo&lt;/strong>&lt;/th>
&lt;th>&lt;strong>Referencia normativa ICH&lt;/strong>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;strong>Aleatorizaci√≥n&lt;/strong>&lt;/td>
&lt;td>Asignaci√≥n no predecible de tratamientos&lt;/td>
&lt;td>Mitiga el sesgo de selecci√≥n; equilibra factores conocidos/desconocidos&lt;/td>
&lt;td>ICH E9 Secci√≥n 2.2.3&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Grupo control&lt;/strong>&lt;/td>
&lt;td>Comparaci√≥n con placebo o tratamiento est√°ndar&lt;/td>
&lt;td>Permite contrafactual v√°lido e inferencia causal robusta&lt;/td>
&lt;td>ICH E10; ICH E8(R1)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Cegamiento (blinding)&lt;/strong>&lt;/td>
&lt;td>Ocultamiento de asignaci√≥n a participantes e investigadores&lt;/td>
&lt;td>Previene sesgo de evaluaci√≥n, expectativa y cointervenci√≥n&lt;/td>
&lt;td>ICH E9 Secci√≥n 2.2.4&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;hr>
&lt;h1 id="contextos-que-permiten-prescindir-de-ecas">Contextos que permiten prescindir de ECAs&lt;/h1>
&lt;p>La omisi√≥n de ECAs solo es aceptable en contextos claramente delimitados por justificaciones √©ticas, cient√≠ficas o log√≠sticas:&lt;/p>
&lt;ol>
&lt;li>&lt;strong>Enfermedades raras o ultrarraras&lt;/strong>, con poblaciones muy limitadas.&lt;/li>
&lt;li>&lt;strong>Situaciones de emergencia sanitaria&lt;/strong>, con necesidades cl√≠nicas urgentes.&lt;/li>
&lt;li>Cuando la &lt;strong>aleatorizaci√≥n o el cegamiento son √©ticamente problem√°ticos&lt;/strong>.&lt;/li>
&lt;li>Cuando existen &lt;strong>datos hist√≥ricos o reales bien estructurados y validados&lt;/strong>.&lt;/li>
&lt;/ol>
&lt;p>La aceptaci√≥n de estos dise√±os como base regulatoria &lt;strong>requiere validaci√≥n metodol√≥gica espec√≠fica y evaluaci√≥n caso por caso&lt;/strong>, seg√∫n gu√≠as EMA y FDA.&lt;/p>
&lt;hr>
&lt;h1 id="dise√±os-alternativos-m√°s-empleados-y-criterios-de-validaci√≥n">Dise√±os alternativos m√°s empleados y criterios de validaci√≥n&lt;/h1>
&lt;h2 id="tabla-3-dise√±os-alternativos-justificaci√≥n-limitaciones-y-requisitos-regulatorios">Tabla 3. Dise√±os alternativos: justificaci√≥n, limitaciones y requisitos regulatorios&lt;/h2>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;strong>Dise√±o alternativo&lt;/strong>&lt;/th>
&lt;th>&lt;strong>Justificaci√≥n de uso&lt;/strong>&lt;/th>
&lt;th>&lt;strong>Limitaciones cr√≠ticas&lt;/strong>&lt;/th>
&lt;th>&lt;strong>Requisitos de validaci√≥n&lt;/strong>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;strong>Single-Arm Trials (SAT)&lt;/strong>&lt;/td>
&lt;td>Enfermedades raras; oncolog√≠a sin comparador disponible&lt;/td>
&lt;td>Ausencia de grupo control; alta vulnerabilidad a sesgo de selecci√≥n&lt;/td>
&lt;td>Control externo robusto; endpoints validados; an√°lisis de consistencia&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Controles externos/sint√©ticos&lt;/strong>&lt;/td>
&lt;td>Cohortes hist√≥ricas o datos de mundo real&lt;/td>
&lt;td>Riesgo de confusi√≥n residual y sesgo de canalizaci√≥n&lt;/td>
&lt;td>Propensity score matching; alineaci√≥n temporal; CHMP/4366/2020 (EMA)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Dise√±os adaptativos&lt;/strong>&lt;/td>
&lt;td>Eficiencia en reclutamiento; ajustes preplanificados&lt;/td>
&lt;td>Riesgo de error tipo I si no se prespecifican adecuadamente&lt;/td>
&lt;td>Control de multiplicidad; simulaci√≥n previa; ICH E9(R1)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Real-World Evidence (RWE)&lt;/strong>&lt;/td>
&lt;td>Acceso a datos de rutina cl√≠nica; seguimiento largo; baja carga √©tica&lt;/td>
&lt;td>Falta de aleatorizaci√≥n; sesgo de confusi√≥n no medido&lt;/td>
&lt;td>PROACE principles (FDA 2023); data provenance; calidad del DMR; plan de an√°lisis riguroso&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;hr>
&lt;h1 id="riesgos-del-uso-estrat√©gico-de-dise√±os-no-confirmatorios">Riesgos del uso estrat√©gico de dise√±os no confirmatorios&lt;/h1>
&lt;p>Aunque v√°lidos en contextos excepcionales, el uso frecuente y estrat√©gico de estos dise√±os plantea &lt;strong>serios desaf√≠os regulatorios&lt;/strong>, especialmente si se recurre a ellos como v√≠a para &lt;strong>prescindir de ECAs sin justificaci√≥n metodol√≥gica s√≥lida&lt;/strong>.&lt;/p>
&lt;h2 id="riesgos-identificados">Riesgos identificados:&lt;/h2>
&lt;ul>
&lt;li>Aprobaciones basadas en &lt;strong>evidencia d√©bil o no reproducible&lt;/strong>.&lt;/li>
&lt;li>Incremento del &lt;strong>sesgo sistem√°tico&lt;/strong> en resultados de eficacia.&lt;/li>
&lt;li>Exposici√≥n de pacientes a intervenciones &lt;strong>no validadas rigurosamente&lt;/strong>.&lt;/li>
&lt;li>&lt;strong>Deslegitimaci√≥n del proceso regulatorio&lt;/strong> ante la comunidad cient√≠fica y la sociedad.&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="recomendaciones-regulatorias">Recomendaciones regulatorias&lt;/h1>
&lt;h2 id="a-para-la-industria">A. Para la industria&lt;/h2>
&lt;ul>
&lt;li>Presentar &lt;strong>justificaci√≥n exhaustiva&lt;/strong> cuando no se utilicen ECAs.&lt;/li>
&lt;li>Cumplir con requisitos metodol√≥gicos espec√≠ficos seg√∫n tipo de dise√±o alternativo.&lt;/li>
&lt;li>Incluir an√°lisis de sensibilidad, consistencia y control de sesgo.&lt;/li>
&lt;/ul>
&lt;h2 id="b-para-las-agencias-reguladoras">B. Para las agencias reguladoras&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>Reforzar gu√≠as espec√≠ficas&lt;/strong> (EMA, FDA) que regulen el uso de dise√±os alternativos.&lt;/li>
&lt;li>Exigir &lt;strong>registro p√∫blico&lt;/strong>, transparencia y acceso a protocolos completos.&lt;/li>
&lt;li>Fortalecer &lt;strong>capacidades internas&lt;/strong> en estad√≠stica avanzada y dise√±o de estudios no aleatorizados.&lt;/li>
&lt;li>Establecer &lt;strong>comit√©s independientes&lt;/strong> de evaluaci√≥n para salvaguardas √©ticas y cient√≠ficas.&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="conclusi√≥n">Conclusi√≥n&lt;/h1>
&lt;p>Los dise√±os alternativos no deben entenderse como sustitutos gen√©ricos del ECA, sino como herramientas &lt;strong>v√°lidas solo bajo condiciones estrictamente justificadas y validadas&lt;/strong>. El regulador tiene la responsabilidad cient√≠fica y √©tica de exigir evidencia que no solo sea suficiente, sino tambi√©n s√≥lida, reproducible y libre de sesgos. La precisi√≥n metodol√≥gica y la claridad terminol√≥gica no son un lujo en este proceso: &lt;strong>son el principio rector que protege la salud p√∫blica frente a la ambig√ºedad cient√≠fica&lt;/strong>.&lt;/p>
&lt;hr>
&lt;h1 id="bibliograf√≠a">Bibliograf√≠a&lt;/h1>
&lt;ol>
&lt;li>FDA. &lt;em>Demonstrating Substantial Evidence of Effectiveness with One Adequate and Well-Controlled Clinical Investigation and Confirmatory Evidence&lt;/em>. Draft Guidance. 2023.&lt;/li>
&lt;li>EMA. &lt;em>Reflection Paper on Single‚ÄëArm Trials as Pivotal Evidence&lt;/em>. EMA/CHMP/161300/2023.&lt;/li>
&lt;li>FDA. &lt;em>Real-World Evidence Framework&lt;/em>. 2023 Update.&lt;/li>
&lt;li>EMA. &lt;em>Use of Real‚ÄëWorld Evidence in Regulatory Decision-Making&lt;/em>. EMA/INS/GCP/455222/2024.&lt;/li>
&lt;li>ICH. &lt;em>E9: Statistical Principles for Clinical Trials&lt;/em>. 1998.&lt;/li>
&lt;li>ICH. &lt;em>E9(R1): Addendum on Estimands and Sensitivity Analysis in Clinical Trials&lt;/em>. 2020.&lt;/li>
&lt;li>EMA. &lt;em>Guideline on Adjustment for Baseline Covariates in Clinical Trials&lt;/em>. CHMP/EWP/2863/99.&lt;/li>
&lt;li>FDA. &lt;em>Real-World Evidence Program Annual Report 2025 (PUB-245)&lt;/em>.&lt;/li>
&lt;li>Temple R, Ellenberg SS. &lt;em>Placebo-Controlled Trials and Active-Control Trials in the Evaluation of New Treatments&lt;/em>. &lt;em>Ann Intern Med&lt;/em>. 2000;133(6):455‚Äì463.&lt;/li>
&lt;/ol></description></item><item><title>An√°lisis Exploratorio de Datos: Desentra√±ando la Verdad de tus Datos</title><link>https://bioestadisticaedu.com/post/eda/</link><pubDate>Tue, 11 Feb 2025 00:00:00 +0000</pubDate><guid>https://bioestadisticaedu.com/post/eda/</guid><description>&lt;p>üéß &lt;strong>Escucha el podcast de esta publicaci√≥n&lt;/strong>
&lt;audio controls >
&lt;source src="https://bioestadisticaedu.com/mp3/eda.mp3" type="audio/mpeg">
&lt;/audio>
&lt;/p>
&lt;h2 id="introducci√≥n">Introducci√≥n&lt;/h2>
&lt;p>El &lt;strong>An√°lisis Exploratorio de Datos (EDA)&lt;/strong> es una disciplina fundamental en el campo de la ciencia de datos, popularizada por el matem√°tico John Tukey. M√°s que una simple serie de pasos, el EDA es una filosof√≠a que nos invita a interactuar con nuestros datos, visualizarlos, resumirlos y &amp;ldquo;hablar&amp;rdquo; con ellos antes de saltar a modelados complejos. Implica el an√°lisis de datos centrado en comprender a fondo su estructura, identificar patrones ocultos, detectar anomal√≠as (valores at√≠picos), gestionar datos ausentes y, en √∫ltima instancia, proporcionar una base s√≥lida para la formulaci√≥n de modelos predictivos o inferenciales. Adem√°s, es crucial para descubrir c√≥mo se relacionan las variables entre s√≠.&lt;/p>
&lt;p>Un concepto popular y vital en el campo de la ciencia de datos es &lt;strong>GIGO&lt;/strong> (Garbage In, Garbage Out, o &amp;ldquo;Basura entra, basura sale&amp;rdquo;). Este concepto subraya que la calidad de los resultados de cualquier an√°lisis o modelo es directamente proporcional a la calidad de los datos de entrada. No importa cu√°n sofisticado sea tu algoritmo o cu√°n potente sea tu infraestructura computacional, los datos de mala calidad siempre producir√°n resultados deficientes, enga√±osos o in√∫tiles. El EDA es nuestra primera l√≠nea de defensa contra el GIGO, asegurando que trabajamos con datos limpios y comprensibles.&lt;/p>
&lt;h2 id="un-flujo-de-trabajo-pr√°ctico-de-eda">Un Flujo de Trabajo Pr√°ctico de EDA&lt;/h2>
&lt;p>Aunque el EDA es un proceso iterativo y no una &amp;ldquo;camisa de fuerza&amp;rdquo; r√≠gida, es √∫til seguir un flujo de trabajo estructurado para garantizar que cubrimos los aspectos m√°s importantes. El orden de las etapas y el √©nfasis en cada una depender√°n en gran medida del problema espec√≠fico, el tipo de datos y los objetivos del an√°lisis.&lt;/p>
&lt;p>Este proceso general incluye:&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="flex justify-center ">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/eda/fig01_hu_1d111632709b1b76.webp 400w,
/post/eda/fig01_hu_b26fdc398618e3dc.webp 760w,
/post/eda/fig01_hu_540748744cda905c.webp 1200w"
src="https://bioestadisticaedu.com/post/eda/fig01_hu_1d111632709b1b76.webp"
width="760"
height="578"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>A continuaci√≥n, profundicemos en cada una de estas etapas, utilizando ejemplos pr√°cticos con el paquete &lt;code>dlookr&lt;/code> en R.&lt;/p>
&lt;h3 id="1-comprensi√≥n-general-de-los-datos-y-evaluaci√≥n-de-su-calidad">1. Comprensi√≥n General de los Datos y Evaluaci√≥n de su Calidad&lt;/h3>
&lt;p>Antes de sumergirnos en an√°lisis profundos, es fundamental tener una visi√≥n panor√°mica de nuestro conjunto de datos. Esta etapa implica:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Dimensiones del dataset:&lt;/strong> ¬øCu√°ntas filas (observaciones) y columnas (variables) tenemos?&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Tipos de datos:&lt;/strong> ¬øLas variables son num√©ricas (enteros, flotantes), categ√≥ricas (factores, caracteres), l√≥gicas o de fecha/hora? Es crucial que los tipos de datos sean correctos para las operaciones que deseamos realizar.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Inspecci√≥n inicial:&lt;/strong> Revisar las primeras y √∫ltimas filas del dataset para obtener una idea general del formato y contenido.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Estad√≠sticas descriptivas b√°sicas:&lt;/strong> Para variables num√©ricas: media, mediana, desviaci√≥n est√°ndar, m√≠nimo, m√°ximo, cuartiles. Para variables categ√≥ricas: conteo de ocurrencias, proporciones. Esto nos da una primera impresi√≥n de la dispersi√≥n y centralidad de los datos.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Con &lt;code>dlookr&lt;/code>, la funci√≥n &lt;code>diagnose()&lt;/code> es ideal para una revisi√≥n r√°pida de la calidad de los datos, mostrando el tipo de variable, el n√∫mero de valores √∫nicos, valores faltantes, valores cero y valores negativos.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-r" data-lang="r">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Para obtener un resumen r√°pido de las caracter√≠sticas de los datos&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">diagnose&lt;/span>(mtcars_na)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Esta fase nos ayuda a formar una primera hip√≥tesis sobre la calidad y estructura de los datos, identificando posibles problemas desde el principio.&lt;/p>
&lt;h3 id="2-identificaci√≥n-y-tratamiento-de-valores-faltantes-y-at√≠picos">2. Identificaci√≥n y Tratamiento de Valores Faltantes y At√≠picos&lt;/h3>
&lt;p>Los valores faltantes (NA, NaN, null) y los valores at√≠picos (outliers) son dos de los desaf√≠os m√°s comunes en cualquier conjunto de datos y pueden distorsionar significativamente los resultados de nuestros an√°lisis y modelos.&lt;/p>
&lt;p>&lt;strong>Valores Faltantes:&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Identificaci√≥n:&lt;/strong> Cuantificar la cantidad y proporci√≥n de valores faltantes por variable. Visualizar patrones de ausencia (¬ølos valores faltantes ocurren aleatoriamente o hay un patr√≥n?).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Tratamiento:&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Eliminaci√≥n:&lt;/strong> Si la cantidad de valores faltantes es peque√±a o si una variable tiene un porcentaje muy alto de NAs, se pueden eliminar filas o columnas.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Imputaci√≥n:&lt;/strong> Rellenar los valores faltantes. M√©todos comunes incluyen la media, mediana o moda (para datos num√©ricos y categ√≥ricos, respectivamente), o m√©todos m√°s avanzados basados en modelos (regresi√≥n, k-NN, etc.). La elecci√≥n depende de la naturaleza de los datos y el problema.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Valores At√≠picos:&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Identificaci√≥n:&lt;/strong> Observaciones que se desv√≠an significativamente del resto de los datos. Se pueden detectar mediante gr√°ficos de caja (boxplots), diagramas de dispersi√≥n, puntuaciones Z, el m√©todo IQR (rango intercuart√≠lico) o algoritmos m√°s sofisticados.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Tratamiento:&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Eliminaci√≥n:&lt;/strong> Si se confirma que son errores de entrada de datos.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Transformaci√≥n:&lt;/strong> Aplicar transformaciones logar√≠tmicas o de ra√≠z cuadrada para reducir su impacto.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Capping/Flooring:&lt;/strong> Limitar los valores at√≠picos a un percentil superior o inferior (por ejemplo, el 99% o el 1%).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Mantener:&lt;/strong> A veces, los valores at√≠picos son observaciones genuinas e importantes que no deben eliminarse.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;code>dlookr&lt;/code> ofrece funciones visuales y program√°ticas para abordar estos problemas:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-r" data-lang="r">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Visualizar la distribuci√≥n de valores faltantes&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">plot_na&lt;/span>(mtcars_na)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Identificar valores at√≠picos para una variable espec√≠fica (ej. &amp;#34;hp&amp;#34;)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># plot_outlier() es excelente para visualizar.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">plot_outlier&lt;/span>(mtcars_df, &lt;span style="color:#e6db74">&amp;#34;hp&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="3-an√°lisis-de-la-distribuci√≥n-de-las-variables">3. An√°lisis de la Distribuci√≥n de las Variables&lt;/h3>
&lt;p>Comprender la distribuci√≥n de cada variable individualmente es clave para seleccionar los m√©todos estad√≠sticos y de modelado adecuados.&lt;/p>
&lt;p>&lt;strong>Variables Num√©ricas:&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Histogramas y gr√°ficos de densidad:&lt;/strong> Permiten visualizar la forma de la distribuci√≥n, identificar asimetr√≠as (skewness), curtosis, y la presencia de m√∫ltiples modos.&lt;/li>
&lt;li>&lt;strong>Medidas de asimetr√≠a y curtosis:&lt;/strong> Cuantifican la forma de la distribuci√≥n.&lt;/li>
&lt;li>&lt;strong>Pruebas de normalidad:&lt;/strong> Aunque muchas veces no son estrictamente necesarias, pueden complementar el an√°lisis visual.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Variables Categ√≥ricas:&lt;/strong> - &lt;strong>Gr√°ficos de barras:&lt;/strong> Muestran la frecuencia o proporci√≥n de cada categor√≠a. - &lt;strong>Tablas de frecuencia:&lt;/strong> Resumen el conteo y porcentaje de cada nivel.&lt;/p>
&lt;p>&lt;code>dlookr&lt;/code> simplifica la visualizaci√≥n de distribuciones:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-r" data-lang="r">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Visualizar la distribuci√≥n de una variable num√©rica (ej. &amp;#34;mpg&amp;#34;)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">plot_hist&lt;/span>(mtcars_df, &lt;span style="color:#e6db74">&amp;#34;mpg&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># O ver la distribuci√≥n y normalidad&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">plot_normality&lt;/span>(mtcars_df, &lt;span style="color:#e6db74">&amp;#34;mpg&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Para variables categ√≥ricas (como &amp;#39;cyl&amp;#39; en mtcars que es num√©rica discreta)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Podemos convertirla a factor para un an√°lisis categ√≥rico.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>mtcars_factor_cyl &lt;span style="color:#f92672">&amp;lt;-&lt;/span> mtcars_df &lt;span style="color:#f92672">%&amp;gt;%&lt;/span> &lt;span style="color:#a6e22e">mutate&lt;/span>(cyl &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">as.factor&lt;/span>(cyl))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">plot_bar&lt;/span>(mtcars_factor_cyl, &lt;span style="color:#e6db74">&amp;#34;cyl&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Este an√°lisis nos ayuda a entender el comportamiento de cada caracter√≠stica y a identificar la necesidad de transformaciones futuras.&lt;/p>
&lt;h3 id="4-an√°lisis-de-las-relaciones-entre-las-variables">4. An√°lisis de las Relaciones entre las Variables&lt;/h3>
&lt;p>Esta etapa se centra en descubrir c√≥mo las variables interact√∫an entre s√≠. Es fundamental para la selecci√≥n de caracter√≠sticas, la identificaci√≥n de multicolinealidad y la comprensi√≥n de la causalidad (o correlaci√≥n).&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Dos variables num√©ricas:&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Diagramas de dispersi√≥n (scatter plots):&lt;/strong> Visualizan la direcci√≥n y fuerza de la relaci√≥n (positiva, negativa, nula, no lineal).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Coeficientes de correlaci√≥n (Pearson, Spearman):&lt;/strong> Cuantifican la fuerza y direcci√≥n de la relaci√≥n lineal (Pearson) o mon√≥tona (Spearman).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Una variable num√©rica y una categ√≥rica:&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Gr√°ficos de caja (boxplots) o gr√°ficos de viol√≠n:&lt;/strong> Comparan la distribuci√≥n de la variable num√©rica entre las diferentes categor√≠as.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Pruebas t de Student o ANOVA:&lt;/strong> Para determinar si hay diferencias estad√≠sticamente significativas en las medias.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Dos variables categ√≥ricas:&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Tablas de contingencia y gr√°ficos de barras apiladas/agrupadas:&lt;/strong> Muestran la distribuci√≥n conjunta.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Pruebas de significaci√≥n:&lt;/strong> Para evaluar la independencia entre las variables.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Matrices de correlaci√≥n:&lt;/strong> Visualizan las correlaciones entre m√∫ltiples variables num√©ricas simult√°neamente, a menudo con mapas de calor (heatmaps).&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;code>dlookr&lt;/code> facilita la exploraci√≥n de relaciones:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-r" data-lang="r">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Visualizar la matriz de correlaci√≥n entre todas las variables num√©ricas&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">plot_cor&lt;/span>(mtcars_df)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Analizar la relaci√≥n entre una variable objetivo (&amp;#39;mpg&amp;#39;) y otra caracter√≠stica (&amp;#39;wt&amp;#39;)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># plot_eda() permite explorar diversas relaciones bivariadas.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">plot_eda&lt;/span>(mtcars_df, target &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;mpg&amp;#34;&lt;/span>, feature &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;wt&amp;#34;&lt;/span>) &lt;span style="color:#75715e"># Num√©rica vs Num√©rica (scatterplot)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Relaci√≥n entre &amp;#39;mpg&amp;#39; (num√©rica) y &amp;#39;cyl&amp;#39; (considerada categ√≥rica aqu√≠)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">plot_eda&lt;/span>(mtcars_df, target &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;mpg&amp;#34;&lt;/span>, feature &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;cyl&amp;#34;&lt;/span>) &lt;span style="color:#75715e"># Num√©rica vs Categ√≥rica (boxplot)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="5-transformaci√≥n-de-los-datos">5. Transformaci√≥n de los Datos&lt;/h3>
&lt;p>Una vez que hemos comprendido nuestros datos, es posible que necesitemos transformarlos para que sean m√°s adecuados para los algoritmos de machine learning o para mejorar el rendimiento del modelo.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Manejo de asimetr√≠a:&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Transformaciones logar√≠tmicas, de ra√≠z cuadrada o de Box-Cox:&lt;/strong> Pueden normalizar distribuciones sesgadas, reduciendo la influencia de valores extremos.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Escalado de caracter√≠sticas:&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Normalizaci√≥n (Min-Max Scaling):&lt;/strong> Escala los datos a un rango fijo (por ejemplo, [0, 1]). √ötil para algoritmos sensibles a la escala como SVM o redes neuronales.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Estandarizaci√≥n (Z-score Scaling):&lt;/strong> Transforma los datos para que tengan una media de 0 y una desviaci√≥n est√°ndar de 1. Es com√∫n en algoritmos basados en distancia (k-NN, K-Means, PCA).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Codificaci√≥n de variables categ√≥ricas:&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>One-Hot Encoding:&lt;/strong> Convierte variables categ√≥ricas en m√∫ltiples columnas binarias, una por cada categor√≠a. Esencial para algoritmos que solo trabajan con entradas num√©ricas.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Label Encoding:&lt;/strong> Asigna un n√∫mero entero a cada categor√≠a. √ötil si hay un orden inherente en las categor√≠as.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Ingenier√≠a de Caracter√≠sticas (Feature Engineering):&lt;/strong> Crear nuevas variables a partir de las existentes. Esto puede ser tan simple como combinar dos columnas o tan complejo como extraer informaci√≥n de texto o im√°genes. Esta etapa es a menudo la que m√°s impacto tiene en el rendimiento del modelo.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;code>dlookr&lt;/code> ofrece funciones √∫tiles para la transformaci√≥n de datos:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-r" data-lang="r">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Transformaci√≥n logar√≠tmica para reducir la asimetr√≠a de una variable&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>mtcars_transformed_log &lt;span style="color:#f92672">&amp;lt;-&lt;/span> &lt;span style="color:#a6e22e">transform_df&lt;/span>(mtcars_df, mpg &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">log&lt;/span>(mpg))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Compara la distribuci√≥n de mpg original vs. transformada&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">plot_normality&lt;/span>(mtcars_df, &lt;span style="color:#e6db74">&amp;#34;mpg&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">plot_normality&lt;/span>(mtcars_transformed_log, &lt;span style="color:#e6db74">&amp;#34;mpg&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Binarizaci√≥n o discretizaci√≥n de una variable continua (ej. &amp;#39;hp&amp;#39; en 3 bins)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>mtcars_binned &lt;span style="color:#f92672">&amp;lt;-&lt;/span> &lt;span style="color:#a6e22e">binning&lt;/span>(mtcars_df, &lt;span style="color:#e6db74">&amp;#34;hp&amp;#34;&lt;/span>, n &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">3&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">head&lt;/span>(mtcars_binned &lt;span style="color:#f92672">%&amp;gt;%&lt;/span> &lt;span style="color:#a6e22e">select&lt;/span>(hp, hp_Binned))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Estandarizaci√≥n de variables num√©ricas (Z-score)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>mtcars_scaled &lt;span style="color:#f92672">&amp;lt;-&lt;/span> &lt;span style="color:#a6e22e">normalize&lt;/span>(mtcars_df, method &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;scale&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">head&lt;/span>(mtcars_scaled) &lt;span style="color:#75715e"># Observa c√≥mo los valores de todas las columnas han cambiado&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="herramientas-populares-para-eda">Herramientas Populares para EDA&lt;/h2>
&lt;p>Para realizar un EDA efectivo, contamos con potentes herramientas en lenguajes como R y Python:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>En R:&lt;/strong>
&lt;ul>
&lt;li>El ecosistema &lt;code>tidyverse&lt;/code> (&lt;code>dplyr&lt;/code> para manipulaci√≥n, &lt;code>ggplot2&lt;/code> para visualizaci√≥n) es indispensable.&lt;/li>
&lt;li>Paquetes espec√≠ficos para EDA como &lt;strong>&lt;code>dlookr&lt;/code>&lt;/strong>, es excelente por su enfoque estructurado en el diagn√≥stico de calidad, exploraci√≥n y transformaci√≥n de datos, ofreciendo funciones y reportes automatizados que agilizan el proceso. Otros paquetes √∫tiles incluyen &lt;code>DataExplorer&lt;/code>, &lt;code>skimr&lt;/code>, y &lt;code>visdat&lt;/code>.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>En Python:&lt;/strong>
&lt;ul>
&lt;li>&lt;code>pandas&lt;/code> para manipulaci√≥n de datos.&lt;/li>
&lt;li>&lt;code>matplotlib&lt;/code> y &lt;code>seaborn&lt;/code> para visualizaci√≥n est√°tica.&lt;/li>
&lt;li>&lt;code>plotly&lt;/code> para visualizaciones interactivas.&lt;/li>
&lt;li>Bibliotecas como &lt;code>missingno&lt;/code> para visualizar valores faltantes, &lt;code>pandas_profiling&lt;/code> para informes autom√°ticos de EDA, y &lt;code>sweetviz&lt;/code> para comparaciones.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="conclusi√≥n">Conclusi√≥n&lt;/h2>
&lt;p>El An√°lisis Exploratorio de Datos no es solo una fase inicial, sino un proceso continuo de aprendizaje sobre tus datos. Es una inversi√≥n de tiempo que rinde grandes dividendos, ya que una comprensi√≥n profunda de los datos nos permite tomar decisiones m√°s informadas, construir modelos m√°s robustos y, en √∫ltima instancia, extraer conocimientos m√°s valiosos. Al dominar el EDA, te equipas con la habilidad de transformar datos brutos en una historia coherente y accionable, evitando la trampa del GIGO y asegurando que tus esfuerzos de ciencia de datos generen un impacto real.&lt;/p></description></item></channel></rss>