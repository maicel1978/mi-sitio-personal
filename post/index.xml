<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Blog | BioestadÃ­stica edu</title><link>https://maicel.netlify.app/post/</link><atom:link href="https://maicel.netlify.app/post/index.xml" rel="self" type="application/rss+xml"/><description>Blog</description><generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>es-es</language><lastBuildDate>Sat, 04 Oct 2025 00:00:00 +0000</lastBuildDate><image><url>https://maicel.netlify.app/media/icon_hu_551fbaee136b383e.png</url><title>Blog</title><link>https://maicel.netlify.app/post/</link></image><item><title>Â¿Escribir ciencia o reescribir la realidad?</title><link>https://maicel.netlify.app/post/imryd-redaccion-inversa/</link><pubDate>Sat, 04 Oct 2025 00:00:00 +0000</pubDate><guid>https://maicel.netlify.app/post/imryd-redaccion-inversa/</guid><description>&lt;h1 id="introducciÃ³n">IntroducciÃ³n&lt;/h1>
&lt;div class="flex px-4 py-3 mb-6 rounded-md bg-primary-100 dark:bg-primary-900">
&lt;span class="pr-3 pt-1 text-primary-600 dark:text-primary-300">
&lt;svg height="24" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">&lt;path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z"/>&lt;/svg>
&lt;/span>
&lt;span class="dark:text-neutral-300">&amp;ldquo;Â¿Y si escribimos al revÃ©s? No de la IntroducciÃ³n a los hallazgos, sino de los hallazgos a la IntroducciÃ³n.&amp;rdquo;&lt;/span>
&lt;/div>
&lt;p>&lt;strong>IMRyD â€”IntroducciÃ³n, MÃ©todos, Resultados y DiscusiÃ³nâ€”&lt;/strong> funciona como un bien pÃºblico editorial: estandariza, facilita la revisiÃ³n y permite comparar artÃ­culos.
AdemÃ¡s, comenzar por el problema cientÃ­fico importa: formularlo bien equivale a haber recorrido media soluciÃ³n (1).
Este post no propone abandonar &lt;strong>IMRyD&lt;/strong>, sino distinguir dos Ã³rdenes complementarios:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Orden de publicaciÃ³n (IMRyD):&lt;/strong> Ãºtil para evaluaciÃ³n y recuperaciÃ³n de informaciÃ³n&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Orden de redacciÃ³n (guiada por hallazgos):&lt;/strong> Ãºtil para alinear el relato con lo que realmente aprendimos y separar lo confirmatorio de lo exploratorio (2,3).&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>En la prÃ¡ctica:&lt;/strong> redacta primero los &lt;strong>resultados&lt;/strong> clave (estimaciones, intervalos de confianza, relevancia), despuÃ©s la &lt;strong>DiscusiÃ³n&lt;/strong> (plausibilidad, sesgos, sensibilidad), luego &lt;strong>MÃ©todos&lt;/strong> con transparencia radical (quÃ© estaba preespecificado, quÃ© cambiÃ³ y por quÃ©), y cierra con una &lt;strong>IntroducciÃ³n&lt;/strong> breve y precisa al problema (formular preguntas o hipÃ³tesis) que realmente se ajusta los resultados.
El formato final sigue siendo &lt;strong>IMRyD&lt;/strong>.&lt;/p>
&lt;h1 id="cuÃ¡ndo-sÃ­-y-cuÃ¡ndo-no">CuÃ¡ndo sÃ­ y cuÃ¡ndo no&lt;/h1>
&lt;p>&lt;strong>Conviene:&lt;/strong> estudios observacionales, anÃ¡lisis secundarios, descubrimientos no previstos, ciencia de datos aplicada donde la iteraciÃ³n es inevitable.&lt;/p>
&lt;p>&lt;strong>PrecauciÃ³n/No conviene:&lt;/strong> Registered Reports, ensayos confirmatorios con plan de anÃ¡lisis estadÃ­stico (PAE) preespecificado (CONSORT), revisiones sistemÃ¡ticas con protocolo (PRISMA).
En estos casos, mantÃ©n la primacÃ­a del plan y seÃ±ala lo exploratorio como tal (4,5).&lt;/p>
&lt;h1 id="objeciones-crÃ­ticas-y-respuestas-con-evidencia">Objeciones crÃ­ticas (y respuestas con evidencia)&lt;/h1>
&lt;p>&lt;strong>â€œEsto fomenta HARKing.â€&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Respuesta:&lt;/strong> justo lo contrario si se exige seÃ±alizaciÃ³n explÃ­cita y materiales abiertos.
&lt;em>HARKing es ocultar; aquÃ­ pedimos diferenciar confirmatorio vs. exploratorio y documentar cambios (6-8).&lt;/em>&lt;/p>
&lt;p>&lt;strong>â€œLa IntroducciÃ³n pierde su papel.â€&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Respuesta:&lt;/strong> se fortalece.
&lt;em>Enmarca el problema real que la evidencia iluminÃ³, sin forzar una cronologÃ­a ficticia.ICMJE promueve IMRAD para claridad, no para reescribir la historia (9).&lt;/em>&lt;/p>
&lt;p>&lt;strong>â€œLos editores piden IMRyD estricto.â€&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Respuesta:&lt;/strong> lo mantenemos.
&lt;em>Cambia el flujo de trabajo, no la macroestructura. AdemÃ¡s, TOP y prÃ¡cticas abiertas refuerzan la confianza editorial (10).&lt;/em>&lt;/p>
&lt;p>&lt;strong>â€œSe sobrevaloran resultados inesperados.â€&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Respuesta:&lt;/strong> exige sensibilidad, controles negativos, replicaciÃ³n y no fetichizar p&amp;lt;0,05&lt;/p>
&lt;h1 id="checklist-de-transparencia">Checklist de transparencia&lt;/h1>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Elemento&lt;/th>
&lt;th>Confirmatorio&lt;/th>
&lt;th>Exploratorio&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>EspecificaciÃ³n previa&lt;/td>
&lt;td>Protocolo/SAP enlazado&lt;/td>
&lt;td>No preespecificado (justificaciÃ³n)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Resultados&lt;/td>
&lt;td>Etiquetados como preespecificados&lt;/td>
&lt;td>Etiquetados como post hoc&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>AnÃ¡lisis&lt;/td>
&lt;td>SegÃºn plan&lt;/td>
&lt;td>Limitados, con sensibilidad&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Recursos abiertos&lt;/td>
&lt;td>Datos/cÃ³digo/cuaderno&lt;/td>
&lt;td>CÃ³digo y criterios documentados&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="conclusiÃ³n">ConclusiÃ³n&lt;/h2>
&lt;p>IMRyD ordena y hace comparables nuestros artÃ­culos.
Integrar una redacciÃ³n guiada por hallazgos es una forma moderada y prÃ¡ctica de ganar honestidad, utilidad y trazabilidad, sin sacrificar rigor metodolÃ³gico ni claridad editorial.
En algunos contextos â€”sobre todo exploratoriosâ€” puede ser la diferencia entre un relato fiel al descubrimiento y una cronologÃ­a ficticia.&lt;/p>
&lt;h1 id="recursos-adicionales">Recursos adicionales&lt;/h1>
&lt;p>ðŸŽ§ &lt;strong>Escucha el podcast de esta publicaciÃ³n&lt;/strong>
&lt;audio controls >
&lt;source src="https://maicel.netlify.app/mp3/Post_IMRyD.mp3" type="audio/mpeg">
&lt;/audio>
&lt;/p>
&lt;h1 id="bibliografÃ­a">BibliografÃ­a&lt;/h1>
&lt;ol>
&lt;li>
&lt;p>PÃ³lya G. How to solve it. Princeton University Press; 1945.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Kerr NL. HARKing: Hypothesizing after the results are known. Personality and Social Psychology Review. 1998;2(3):196-217.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Gelman A, Loken E. The garden of forking paths: Why multiple comparisons can be a problem [Internet]. 2013. Disponible en: &lt;a href="https://stat.columbia.edu/~gelman/research/unpublished/p_hacking.pdf" target="_blank" rel="noopener">https://stat.columbia.edu/~gelman/research/unpublished/p_hacking.pdf&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Schulz KF, Altman DG, Moher D. CONSORT 2010 statement. BMJ. 2010;340:c332.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Page MJ, McKenzie JE, Bossuyt PM, others. The PRISMA 2020 statement. BMJ. 2021;372:n71.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>MunafÃ² MR, Nosek BA, Bishop DVM, others. A manifesto for reproducible science. Nature Human Behaviour. 2017;1:0021.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Nosek BA, Ebersole CR, DeHaven AC, Mellor DT. The preregistration revolution. PNAS. 2018;115(11):2600-6.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>International Committee of Medical Journal Editors. Recommendations for the conduct, reporting, editing, and publication of scholarly work in medical journals. 2019; Disponible en: &lt;a href="http://www.icmje.org/recommendations/" target="_blank" rel="noopener">http://www.icmje.org/recommendations/&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Nosek BA, others. Promoting an open research culture (TOP Guidelines). Science. 2015;348(6242):1422-5.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Wasserstein RL, Lazar NA. The asaâ€™s statement on p-Values: Context, process, and purpose. The American Statistician. 2016;70(2):129-33.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Wasserstein RL, Schirm AL, Lazar NA. Moving to a world beyond â€œp Â¡ 0.05â€. The American Statistician. 2019;73(sup1):1-19.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>McShane BB, Gal D, Gelman A, Robert C, Tackett JL. Abandon statistical significance. The American Statistician. 2019;73(sup1):235-45.&lt;/p>
&lt;/li>
&lt;/ol></description></item><item><title>Las trampas de la correlaciÃ³n disfrazada de causalidad</title><link>https://maicel.netlify.app/post/trampas-correlacion/</link><pubDate>Wed, 24 Sep 2025 00:00:00 +0000</pubDate><guid>https://maicel.netlify.app/post/trampas-correlacion/</guid><description>&lt;p>El ojo humano ama los patrones: ver dos lÃ­neas que se mueven juntas y concluir que una provoca la otra. La estadÃ­stica, mal interpretada, a veces alimenta esa ilusiÃ³n. La correlaciÃ³n es apenas la danza conjunta de dos variables, no una flecha de causa. Y, sin embargo, titulares, polÃ­ticas y hasta decisiones mÃ©dicas se sostienen sobre esta trampa.&lt;/p>
&lt;h1 id="1-correlaciones-curiosas-pero-falsas">1) Correlaciones curiosas (pero falsas)&lt;/h1>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Helados y ahogamientos.&lt;/strong> En verano, ambos aumentan. No porque el helado mate, sino porque el calor atrae baÃ±istas y heladeros.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>CigÃ¼eÃ±as y natalidad.&lt;/strong> En pueblos europeos, donde hay mÃ¡s cigÃ¼eÃ±as, tambiÃ©n hay mÃ¡s nacimientosâ€¦ simplemente porque se trata de Ã¡reas rurales mÃ¡s fÃ©rtiles, no porque las aves traigan bebÃ©s.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>PelÃ­culas de Nicolas Cage y ahogamientos en piscinas.&lt;/strong> Ejemplo clÃ¡sico de correlaciones espurias recopiladas por Tyler Vigen: cÃ³mico, pero ilustrativo.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="2-la-correlaciÃ³n-y-su-impacto-en-la-toma-de-decisiones">2) La correlaciÃ³n y su impacto en la toma de decisiones&lt;/h2>
&lt;p>La confusiÃ³n entre causalidad y correlaciÃ³n no es solo un chiste; tiene consecuencias graves.&lt;/p>
&lt;p>&lt;strong>PolÃ­tica pÃºblica:&lt;/strong> Un estudio muestra que los paÃ­ses con mÃ¡s mÃ©dicos per cÃ¡pita tienen mÃ¡s diagnÃ³sticos de cÃ¡ncer. ConclusiÃ³n errada: â€œlos mÃ©dicos causan cÃ¡ncerâ€. Realidad: mayor densidad mÃ©dica implica mejor detecciÃ³n.&lt;/p>
&lt;p>&lt;strong>Falacia de la causa inversa:&lt;/strong> NiÃ±os con bajo rendimiento escolar pasan mÃ¡s horas frente a la televisiÃ³n. Â¿La TV los perjudica? Â¿O los niÃ±os con dificultades recurren mÃ¡s a ella? La direcciÃ³n de la causalidad puede invertirse fÃ¡cilmente.&lt;/p>
&lt;hr>
&lt;h1 id="3-quÃ©-mide-realmente-la-correlaciÃ³n">3) &lt;strong>Â¿QuÃ© mide realmente la correlaciÃ³n?&lt;/strong>&lt;/h1>
&lt;ul>
&lt;li>El &lt;strong>coeficiente de correlaciÃ³n (r)&lt;/strong> mide la fuerza y direcciÃ³n de la relaciÃ³n entre dos variables.&lt;/li>
&lt;li>Sus valores van de &lt;strong>-1 a +1&lt;/strong>:
&lt;ul>
&lt;li>+1 â†’ relaciÃ³n positiva perfecta&lt;/li>
&lt;li>-1 â†’ relaciÃ³n negativa perfecta&lt;/li>
&lt;li>0 â†’ ausencia de relaciÃ³n lineal&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;div class="flex px-4 py-3 mb-6 rounded-md bg-primary-100 dark:bg-primary-900">
&lt;span class="pr-3 pt-1 text-primary-600 dark:text-primary-300">
&lt;svg height="24" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">&lt;path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z"/>&lt;/svg>
&lt;/span>
&lt;span class="dark:text-neutral-300">&lt;strong>Advertencia:&lt;/strong> un r alto no significa causalidad. Puede deberse a &lt;strong>confusores&lt;/strong>, &lt;strong>azar&lt;/strong> o &lt;strong>causalidad inversa&lt;/strong>.&lt;/span>
&lt;/div>
&lt;hr>
&lt;h1 id="4-tipos-de-coeficientes-de-correlaciÃ³n-mÃ¡s-allÃ¡-de-pearson">4) Tipos de coeficientes de correlaciÃ³n (mÃ¡s allÃ¡ de Pearson)&lt;/h1>
&lt;p>
&lt;figure >
&lt;div class="flex justify-center ">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/trampas-correlacion/correlacion_hu_c614a73ad03379b6.webp 400w,
/post/trampas-correlacion/correlacion_hu_e6f9def3a13f9eea.webp 760w,
/post/trampas-correlacion/correlacion_hu_dedc904516865376.webp 1200w"
src="https://maicel.netlify.app/post/trampas-correlacion/correlacion_hu_c614a73ad03379b6.webp"
width="507"
height="760"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;hr>
&lt;h1 id="5-causalidad-un-desafÃ­o-que-exige-rigurosidad">5) &lt;strong>Causalidad:&lt;/strong> un desafÃ­o que exige rigurosidad&lt;/h1>
&lt;p>Identificar la causalidad no se improvisa. Requiere algo mÃ¡s que una simple correlaciÃ³n. Exige un diseÃ±o experimental riguroso, criterios de Bradford Hill y construcciÃ³n de modelos causales. La estadÃ­stica sugiere, pero no prueba por sÃ­ sola.&lt;/p>
&lt;hr>
&lt;h1 id="6-metÃ¡fora-para-recordar">6) MetÃ¡fora para recordar&lt;/h1>
&lt;p>Piensa en la correlaciÃ³n como ver dos hojas que caen juntas en otoÃ±o. Creer que una arrastra a la otra es ignorar el viento invisible que las mueve a ambas.&lt;/p>
&lt;hr>
&lt;h1 id="7-checklist-para-evitar-caer-en-la-trampa">7) Checklist para evitar caer en la trampa&lt;/h1>
&lt;ol>
&lt;li>Â¿Existe una variable oculta (confusor) que explique la relaciÃ³n? âœ”&lt;/li>
&lt;li>Â¿PodrÃ­a la causalidad ir en sentido contrario? âœ”&lt;/li>
&lt;li>Â¿El diseÃ±o permite concluir causa o solo asociaciÃ³n? âœ”&lt;/li>
&lt;li>Â¿Hay criterios teÃ³ricos/experimentales que respalden esta relaciÃ³n? âœ”&lt;/li>
&lt;li>Â¿Se comunicÃ³ claramente que es correlaciÃ³n, no causalidad? âœ”&lt;/li>
&lt;/ol>
&lt;hr>
&lt;h1 id="bibliografÃ­a">BibliografÃ­a&lt;/h1>
&lt;p>Silva Aycaguer LC. &lt;em>Cultura estadÃ­stica e investigaciÃ³n cientÃ­fica en el campo de la salud: una mirada crÃ­tica&lt;/em>. Madrid: DÃ­az de Santos; 1998.&lt;/p>
&lt;p>Pearl, J. (2009). Causality: Models, Reasoning, and Inference (2nd ed.). Cambridge University Press.&lt;/p>
&lt;p>HernÃ¡n, M. A., &amp;amp; Robins, J. M. (2020). Causal Inference: What If. Chapman &amp;amp; Hall/CRC. [Disponible gratis en lÃ­nea].&lt;/p>
&lt;p>Hill, A. B. (1965). The environment and disease: association or causation? Proceedings of the Royal Society of Medicine, 58(5), 295â€“300. (Criterios de Bradford Hill).&lt;/p>
&lt;p>Freedman, D. A. (2005). Statistical Models: Theory and Practice. Cambridge University Press. (DiscusiÃ³n crÃ­tica sobre correlaciÃ³n y causalidad).&lt;/p></description></item><item><title>Una InmersiÃ³n Intuitiva en la Arquitectura de los LLMs</title><link>https://maicel.netlify.app/post/ia/</link><pubDate>Sat, 06 Sep 2025 00:00:00 +0000</pubDate><guid>https://maicel.netlify.app/post/ia/</guid><description>&lt;p>Todos conocemos los Modelos de Lenguaje Grandes (LLMs) como &lt;strong>ChatGPT de OpenAI, Claude de Anthropic, Gemini de Google&lt;/strong> y otros modelos similares.&lt;/p>
&lt;p>Son esos asistentes de IA con los que conversamos, que nos ayudan a escribir correos (Stanford Online 2024)electrÃ³nicos, a generar ideas e incluso a codificar.&lt;/p>
&lt;p>Pero, Â¿alguna vez te has preguntado cÃ³mo funcionan realmente estas herramientas?
Â¿EstÃ¡n pensando o simplemente estÃ¡n creando una &lt;strong>magnÃ­fica ilusiÃ³n de razonamiento&lt;/strong>?
En este blog, te mostrarÃ© cÃ³mo cobran vida estas maravillas tecnolÃ³gicas, desde el vasto ocÃ©ano de datos hasta su afinada inteligencia, y exploraremos la naturaleza de esa â€œinteligenciaâ€ que tanto nos asombra.&lt;/p>
&lt;p>Puedes ver la versiÃ³n en vÃ­deo de esta publicaciÃ³n aquÃ­:&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/SxIFozcvCAU?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video">&lt;/iframe>
&lt;/div>
&lt;p>A continuaciÃ³n, te explico algunos elementos importantes para entender los Modelos de Lenguaje Grandes (LLMs), como se construyen, cÃ³mo se entrenan y predicen sus resultado.&lt;/p>
&lt;img src="fig0.png" style="width:30.0%" />
&lt;h2 id="la-anatomÃ­a-de-un-llm-redes-neuronales-y-transformadores">La AnatomÃ­a de un LLM: Redes Neuronales y Transformadores&lt;/h2>
&lt;p>En esencia, los LLMs son &lt;strong>redes neuronales&lt;/strong>.
Lejos de simular el cerebro humano en un sentido biolÃ³gico, se basan casi universalmente en una arquitectura particular conocida como &lt;strong>Transformadores&lt;/strong>.&lt;/p>
&lt;div class="flex px-4 py-3 mb-6 rounded-md bg-primary-100 dark:bg-primary-900">
&lt;span class="pr-3 pt-1 text-primary-600 dark:text-primary-300">
&lt;svg height="24" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">&lt;path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z"/>&lt;/svg>
&lt;/span>
&lt;span class="dark:text-neutral-300">&lt;strong>Red neuronal artificial:&lt;/strong> &lt;em>â€œUna red neuronal artificial es un sistema de procesamiento paralelo y distribuido, compuesto por unidades simples de procesamiento que tienen la propensiÃ³n natural de almacenar conocimiento experimental y hacerlo disponible para su usoâ€&lt;/em> (Haykin, n.d.).&lt;/span>
&lt;/div>
&lt;p>Estos Transformadores fueron propuestos por Vaswani et al.Â en 2017 y se destacaron por su capacidad para â€œdibujar dependencias globales entre la entrada y la salidaâ€ utilizando Ãºnicamente mecanismos de atenciÃ³n, sin necesidad de redes recurrentes o convolucionales.&lt;/p>
&lt;p>Esta capacidad es clave para su Ã©xito: permite que el modelo procese grandes cantidades de texto en paralelo y capte relaciones a larga distancia dentro de una secuencia.(Vaswani et al., n.d.)&lt;/p>
&lt;p>Cuando hablamos de entrenar un LLM, hay varios componentes clave que entran en juego:&lt;/p>
&lt;!-- - **Arquitectura**: CÃ³mo se estructura la red neuronal (los Transformadores). -->
&lt;!-- - **PÃ©rdida de entrenamiento y algoritmo**: CÃ³mo se "aprende" el modelo. -->
&lt;!-- - **Datos**: En quÃ© informaciÃ³n se entrena el modelo. -->
&lt;!-- - **EvaluaciÃ³n**: CÃ³mo sabemos si el modelo estÃ¡ mejorando. -->
&lt;!-- - **Componentes del sistema**: CÃ³mo se ejecutan estos modelos gigantes en hardware moderno de manera eficiente. -->
&lt;p>
&lt;figure >
&lt;div class="flex justify-center ">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/ia/fig1_hu_18182d8f524833af.webp 400w,
/post/ia/fig1_hu_f33bba6717280fcf.webp 760w,
/post/ia/fig1_hu_4ee0477a1071e0cf.webp 1200w"
src="https://maicel.netlify.app/post/ia/fig1_hu_18182d8f524833af.webp"
width="760"
height="410"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;!-- A menudo, la academia se centra mucho en la arquitectura, pero en la prÃ¡ctica, lo que realmente importa es la **calidad de los datos, la evaluaciÃ³n y los sistemas**, ya que las pequeÃ±as diferencias arquitectÃ³nicas son a menudo secundarias frente a la escala. -->
&lt;h2 id="la-primera-etapa-pre-entrenamiento-modelado-del-lenguaje">La Primera Etapa: Pre-entrenamiento (Modelado del Lenguaje)&lt;/h2>
&lt;p>El viaje de un LLM comienza con el &lt;strong>pre-entrenamiento&lt;/strong>, un paradigma clÃ¡sico donde el modelo se entrena para &lt;strong>â€œmodelar todo Internetâ€&lt;/strong>.&lt;/p>
&lt;p>En esta fase, un modelo de lenguaje es, a grandes rasgos, un modelo de &lt;strong>distribuciÃ³n de probabilidad sobre secuencias de tokens o palabras&lt;/strong>.&lt;/p>
&lt;div class="flex px-4 py-3 mb-6 rounded-md bg-primary-100 dark:bg-primary-900">
&lt;span class="pr-3 pt-1 text-primary-600 dark:text-primary-300">
&lt;svg height="24" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">&lt;path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z"/>&lt;/svg>
&lt;/span>
&lt;span class="dark:text-neutral-300">&lt;strong>Tokens:&lt;/strong> &lt;em>â€œUn token es una instancia de una secuencia de caracteres en un documento, agrupada como una unidad semÃ¡ntica Ãºtil para el procesamiento automÃ¡tico de texto. Esta explicaciÃ³n se basa en una definiciÃ³n clara y rigurosa en el contexto del anÃ¡lisis de informaciÃ³n y recuperaciÃ³n de documentos.â€&lt;/em>&lt;/span>
&lt;/div>
&lt;p>Imagina la frase &lt;strong>â€œEl ratÃ³n comiÃ³ el quesoâ€&lt;/strong>.&lt;/p>
&lt;img src="fig2.png" style="width:30.0%" />
&lt;p>Un modelo de lenguaje te darÃ­a la probabilidad de que esta frase sea pronunciada por un humano o encontrada en lÃ­nea.&lt;/p>
&lt;p>Si la frase tuviera errores gramaticales como &lt;strong>â€œEl el ratÃ³n quesoâ€&lt;/strong>, el modelo, con su conocimiento sintÃ¡ctico, sabrÃ­a que es menos &lt;strong>probable&lt;/strong>.&lt;/p>
&lt;p>Y si fuera &lt;strong>â€œEl queso comiÃ³ el ratÃ³nâ€&lt;/strong>, su conocimiento semÃ¡ntico le indicarÃ­a que esto es &lt;strong>improbable&lt;/strong>.&lt;/p>
&lt;img src="fig3.png" style="width:30.0%" />
&lt;p>&lt;strong>AquÃ­ es donde entra el primer matiz crÃ­tico&lt;/strong>: este &lt;strong>â€œconocimiento sintÃ¡ctico y semÃ¡nticoâ€&lt;/strong> no implica que el modelo &lt;strong>entienda&lt;/strong> realmente la gramÃ¡tica o que los quesos no comen ratones.&lt;/p>
&lt;p>MÃ¡s bien, ha aprendido, a partir de patrones en billones de textos, que ciertas secuencias de palabras son estadÃ­sticamente mÃ¡s probables o coherentes que otras.
Es una habilidad predictiva, no una comprensiÃ³n conceptual.&lt;/p>
&lt;p>Los LLMs son &lt;strong>modelos generativos&lt;/strong>.&lt;/p>
&lt;p>Esto significa que, una vez que tienen esta comprensiÃ³n de las distribuciones de probabilidad, pueden &lt;strong>generar nuevas oraciones o datos&lt;/strong> simplemente muestreando de esa distribuciÃ³n.&lt;/p>
&lt;div class="flex px-4 py-3 mb-6 rounded-md bg-primary-100 dark:bg-primary-900">
&lt;span class="pr-3 pt-1 text-primary-600 dark:text-primary-300">
&lt;svg height="24" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">&lt;path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z"/>&lt;/svg>
&lt;/span>
&lt;span class="dark:text-neutral-300">&lt;strong>Modelos generativos:&lt;/strong> &lt;em>â€œSon algoritmos diseÃ±ados para crear datos nuevos que parecen provenir de la misma distribuciÃ³n que los datos originales con los que fueron entrenados.â€&lt;/em>&lt;/span>
&lt;/div>
&lt;p>Es decir, &lt;em>saben&lt;/em> cÃ³mo sonar convincentes y coherentes, pero no necesariamente &lt;em>por quÃ©&lt;/em> lo que dicen es correcto o verdadero.&lt;/p>
&lt;h2 id="modelos-de-lenguaje-autorregresivos-prediciendo-la-siguiente-palabra">Modelos de Lenguaje Autorregresivos: Prediciendo la Siguiente Palabra&lt;/h2>
&lt;p>Vamos a adaptar el texto que proporcionaste para que se conecte con nuestro ejemplo del ratÃ³n y el queso.ðŸðŸ§€&lt;/p>
&lt;h2 id="modelos-de-lenguaje-autorregresivos-prediciendo-la-siguiente-palabra-1">Modelos de Lenguaje Autorregresivos: Prediciendo la Siguiente Palabra&lt;/h2>
&lt;p>Los modelos de lenguaje mÃ¡s modernos, como Gemini, son &lt;strong>autorregresivos&lt;/strong>.
Esto significa que predicen la &lt;strong>siguiente palabra basÃ¡ndose en todas las palabras que ya han visto&lt;/strong> en la secuencia.&lt;/p>
&lt;p>Piensa en ellos como un narrador que va construyendo una historia palabra por palabra.&lt;/p>
&lt;h2 id="el-proceso-con-el-ratÃ³n-comiÃ³-el-queso">El Proceso con &lt;strong>â€œEl ratÃ³n comiÃ³ el quesoâ€&lt;/strong>&lt;/h2>
&lt;p>Imaginemos que el modelo estÃ¡ generando nuestra frase, â€œEl ratÃ³n comiÃ³ el queso.â€ Este es el fascinante proceso que ocurre:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>Secuencia de palabras:&lt;/strong> El modelo empieza con la primera palabra de la oraciÃ³n.
Luego, toma las palabras que ya ha generado: &lt;strong>â€œEl ratÃ³nâ€&lt;/strong>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>TokenizaciÃ³n:&lt;/strong> Las palabras se convierten en &lt;strong>tokens&lt;/strong> (nÃºmeros o identificadores internos).
Por ejemplo, â€œElâ€ podrÃ­a ser &lt;code>143&lt;/code>, â€œratÃ³nâ€ &lt;code>56&lt;/code>, y â€œcomiÃ³â€ &lt;code>25&lt;/code>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>El modelo predice:&lt;/strong> Estos tokens numerados entran en el modelo (la â€œcaja negraâ€).
Basado en todo lo que ha aprendido de internet, el modelo calcula cuÃ¡l es el prÃ³ximo token mÃ¡s probable.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>DistribuciÃ³n de probabilidad:&lt;/strong> El modelo no solo predice una palabra, sino que le asigna una &lt;strong>probabilidad a cada palabra&lt;/strong> en su vocabulario.
Por ejemplo, despuÃ©s de &lt;strong>â€œEl ratÃ³n comiÃ³ elâ€&lt;/strong>, la palabra &lt;strong>â€œquesoâ€&lt;/strong> podrÃ­a tener una probabilidad del 85%, â€œpanâ€ un 10%, y â€œsemillasâ€ un 5%.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Muestreo:&lt;/strong> El modelo elige el token con la probabilidad mÃ¡s alta, que en este caso es el token para â€œquesoâ€.
A veces, para no sonar robÃ³tico, el modelo elige una palabra con una probabilidad un poco menor, pero en la mayorÃ­a de los casos elige la mÃ¡s probable.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>DetokenizaciÃ³n:&lt;/strong> El token seleccionado se convierte de nuevo en la palabra â€œquesoâ€, completando asÃ­ la frase.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;hr>
&lt;h2 id="aprendizaje-del-modelo">Aprendizaje del Modelo&lt;/h2>
&lt;p>Durante el &lt;strong>entrenamiento&lt;/strong>, el modelo hace este mismo proceso, pero en lugar de generar una frase nueva, compara su predicciÃ³n con la palabra real en un texto de entrenamiento.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Si el modelo predice &lt;strong>â€œpanâ€&lt;/strong> y la palabra correcta es &lt;strong>â€œquesoâ€&lt;/strong>, la &lt;strong>funciÃ³n de pÃ©rdida de entropÃ­a cruzada&lt;/strong> le da un â€œcastigoâ€.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Ese castigo se usa para ajustar los pesos del modelo.
El objetivo es que, la prÃ³xima vez que vea un contexto similar (â€œEl ratÃ³n comiÃ³ elâ€¦â€), la probabilidad de que prediga â€œquesoâ€ sea mucho mayor.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>AsÃ­, la â€œfluidezâ€ del modelo para generar frases como â€œEl ratÃ³n comiÃ³ el quesoâ€ se basa en su capacidad para &lt;strong>predecir estadÃ­sticamente&lt;/strong> la palabra mÃ¡s probable en cada paso, no en un razonamiento sobre los hÃ¡bitos alimenticios de los roedores.&lt;/p>
&lt;!-- Los modelos mÃ¡s utilizados hoy en dÃ­a son los **modelos de lenguaje autorregresivos**. -->
&lt;!-- La idea central es descomponer la probabilidad de una secuencia de palabras en un producto de probabilidades condicionales: la probabilidad de la primera palabra, multiplicada por la probabilidad de la segunda palabra dada la primera, y asÃ­ sucesivamente. -->
&lt;!-- En tÃ©rminos mÃ¡s simples, el modelo predice la **siguiente palabra basÃ¡ndose en todo lo que ha ocurrido antes** en la secuencia. -->
&lt;!-- El proceso es fascinante: -->
&lt;!-- 1. Tomas una secuencia de palabras (como "Ella probablemente prefiere"). -->
&lt;!-- 2. La **tokenizas**, es decir, la divides en "tokens" (palabras o subpalabras) y les asignas un ID. -->
&lt;!-- 3. Estos tokens pasan por el modelo (la "caja negra" del Transformador). -->
&lt;!-- 4. El modelo emite una **distribuciÃ³n de probabilidad** sobre la siguiente palabra o token posible. -->
&lt;!-- 5. Se "muestrea" de esta distribuciÃ³n para obtener el siguiente token mÃ¡s probable. -->
&lt;!-- 6. Finalmente, se "detokeniza" para obtener la palabra real. -->
&lt;!-- Durante el entrenamiento, el objetivo es **predecir el token mÃ¡s probable** y ajustar los pesos del modelo para aumentar la probabilidad de generar el token correcto, utilizando la **funciÃ³n de pÃ©rdida de entropÃ­a cruzada (Cross-Entropy Loss)**, que es equivalente a maximizar la verosimilitud logarÃ­tmica del texto. -->
&lt;!-- Esta es la base de su impresionante fluidez, pero recalca que su "razonamiento" es una sofisticada forma de predicciÃ³n estadÃ­stica. -->
&lt;h2 id="los-tokenizadores-el-primer-paso-crucial-para-la-coherencia">Los Tokenizadores: El Primer Paso Crucial para la â€œCoherenciaâ€&lt;/h2>
&lt;p>Los &lt;strong>tokenizadores&lt;/strong> son componentes extremadamente importantes pero a menudo poco valorados.&lt;/p>
&lt;p>Â¿Por quÃ© los necesitamos?&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>MÃ¡s generales que las palabras&lt;/strong>: Las palabras como tokens directos fallan con errores tipogrÃ¡ficos o en idiomas que no usan espacios (como el tailandÃ©s).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Eficiencia de secuencia&lt;/strong>: Tokenizar carÃ¡cter por carÃ¡cter harÃ­a las secuencias demasiado largas, lo que es ineficiente para los Transformadores (cuya complejidad crece cuadrÃ¡ticamente con la longitud de la secuencia).&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Los tokenizadores buscan encontrar &lt;strong>subsecuencias comunes&lt;/strong> y darles un token especÃ­fico.
En promedio, un token suele representar alrededor de &lt;strong>tres o cuatro letras&lt;/strong>.&lt;/p>
&lt;p>Un algoritmo muy comÃºn es la &lt;strong>CodificaciÃ³n de Pares de Bytes (Byte Pair Encoding o BPE)&lt;/strong>.
Es fundamental considerar cÃ³mo se tokeniza el texto, ya que el &lt;strong>tamaÃ±o del vocabulario afecta directamente la dimensionalidad de la salida&lt;/strong> del modelo.&lt;/p>
&lt;p>&lt;strong>Un punto crÃ­tico aquÃ­&lt;/strong>: Si bien son Ãºtiles, los tokenizadores tienen limitaciones, especialmente con nÃºmeros (matemÃ¡ticas) y cÃ³digo.&lt;/p>
&lt;p>Por ejemplo, un nÃºmero como â€œ327â€ puede tener su propio token, lo que significa que el modelo no lo ve como una composiciÃ³n de â€œ3â€, â€œ2â€, â€œ7â€, lo que dificulta su capacidad para razonar matemÃ¡ticamente o con la estructura del cÃ³digo.&lt;/p>
&lt;p>Esto nos recuerda que, a pesar de la fluidez, los LLMs operan sobre representaciones simbÃ³licas (tokens) que no siempre se alinean con nuestra comprensiÃ³n conceptual del lenguaje o las matemÃ¡ticas.&lt;/p>
&lt;h2 id="de-modelo-de-lenguaje-a-asistente-de-ia-el-post-entrenamiento-o-la-ilusiÃ³n-de-la-intencionalidad">De Modelo de Lenguaje a Asistente de IA: El Post-entrenamiento (o la IlusiÃ³n de la Intencionalidad)&lt;/h2>
&lt;p>Un modelo pre-entrenado es un experto en &lt;strong>â€œhablar como Internetâ€&lt;/strong>, pero no es un asistente de IA.&lt;/p>
&lt;p>Si le preguntaras a &lt;strong>GPT-3&lt;/strong> (un modelo puramente de lenguaje) â€œexplÃ­came el aterrizaje en la luna a un niÃ±o de seis aÃ±osâ€, podrÃ­a responder con â€œexplÃ­came la teorÃ­a de la gravedad a un niÃ±o de seis aÃ±osâ€ porque ha aprendido que en Internet, una pregunta a menudo es seguida por preguntas similares, no por una respuesta directa.&lt;/p>
&lt;p>El &lt;strong>post-entrenamiento (alignment)&lt;/strong> es el proceso que transforma estos modelos en asistentes Ãºtiles, asegurÃ¡ndose de que &lt;strong>sigan las instrucciones de los usuarios&lt;/strong> y los deseos de los diseÃ±adores (por ejemplo, evitar contenido tÃ³xico).&lt;/p>
&lt;p>&lt;strong>Este es el punto donde la ilusiÃ³n de intencionalidad se vuelve mÃ¡s fuerte.&lt;/strong>&lt;/p>
&lt;h2 id="1-ajuste-fino-supervisado-supervised-fine-tuning---sft">1. Ajuste Fino Supervisado (Supervised Fine-Tuning - SFT)&lt;/h2>
&lt;p>El primer paso es el &lt;strong>Ajuste Fino Supervisado (SFT)&lt;/strong>.&lt;/p>
&lt;p>AquÃ­, el LLM pre-entrenado se afina con &lt;strong>respuestas deseadas recogidas de humanos&lt;/strong>.
Es decir, se le dan ejemplos de preguntas y sus respuestas â€œcorrectasâ€ o â€œidealesâ€ escritas por humanos.&lt;/p>
&lt;p>Este paso fue crucial para el salto de &lt;strong>GPT-3&lt;/strong> a &lt;strong>ChatGPT&lt;/strong>.&lt;/p>
&lt;p>Curiosamente, no se necesita una cantidad masiva de datos para SFT; &lt;strong>unos pocos miles de ejemplos bien elegidos pueden ser suficientes&lt;/strong>.&lt;/p>
&lt;p>Esto sugiere que el SFT no enseÃ±a al modelo nuevo conocimiento, sino que le enseÃ±a &lt;strong>cÃ³mo formatear las respuestas&lt;/strong> y optimizar para un â€œtipo de usuarioâ€ especÃ­fico que ya habÃ­a visto en sus datos de pre-entrenamiento.&lt;/p>
&lt;p>En otras palabras, el modelo ya tenÃ­a el conocimiento latente; el SFT le enseÃ±a a &lt;em>expresarlo&lt;/em> de la manera que un asistente de IA â€œdeberÃ­aâ€ hacerlo.&lt;/p>
&lt;p>No estÃ¡ aprendiendo a &lt;em>pensar&lt;/em> como un asistente, sino a &lt;em>simular&lt;/em> el comportamiento de uno.&lt;/p>
&lt;h2 id="2-aprendizaje-por-refuerzo-a-partir-de-retroalimentaciÃ³n-humana-reinforcement-learning-from-human-feedback---rlhf">2. Aprendizaje por Refuerzo a partir de RetroalimentaciÃ³n Humana (Reinforcement Learning from Human Feedback - RLHF)&lt;/h2>
&lt;p>El SFT tiene sus limitaciones: &lt;strong>Limitado por la habilidad humana&lt;/strong>: Los humanos pueden juzgar mejor lo que es una buena respuesta de lo que pueden escribirla ellos mismos.&lt;/p>
&lt;p>&lt;strong>Posibles alucinaciones&lt;/strong>: Como el SFT se entrena con poca data, si un humano da una respuesta que el modelo no ha visto antes (y por tanto no sabe si es cierta), el modelo puede aprender a â€œinventarâ€ informaciÃ³n plausible pero falsa.&lt;/p>
&lt;p>&lt;strong>AquÃ­ el matiz crÃ­tico es fundamental&lt;/strong>: la â€œalucinaciÃ³nâ€ (generaciÃ³n de informaciÃ³n falsa pero plausible) es una clara evidencia de que los LLMs no â€œsabenâ€ lo que es verdad o mentira, ni tienen un sentido de la realidad.&lt;/p>
&lt;p>Simplemente generan secuencias de tokens que &lt;em>parecen&lt;/em> correctas, basÃ¡ndose en los patrones que han aprendido, incluso si no tienen fundamento.&lt;/p>
&lt;p>Es la culminaciÃ³n de la ilusiÃ³n de razonamiento.
&lt;strong>Costo&lt;/strong>: Generar respuestas ideales es muy caro.&lt;/p>
&lt;p>AquÃ­ es donde entra el &lt;strong>RLHF&lt;/strong>.&lt;/p>
&lt;p>En lugar de simplemente clonar el comportamiento humano, el objetivo es &lt;strong>maximizar la preferencia humana&lt;/strong>.&lt;/p>
&lt;p>El proceso es el siguiente:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Para una instrucciÃ³n dada, el modelo genera &lt;strong>dos respuestas diferentes&lt;/strong>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Etiquetadores humanos seleccionan &lt;strong>cuÃ¡l de las dos respuestas es mejor&lt;/strong>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Con esta retroalimentaciÃ³n, el modelo se afina para generar mÃ¡s de las respuestas â€œbuenasâ€ y menos de las â€œmalasâ€.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>Para hacer esto, se entrena un &lt;strong>modelo de recompensa (Reward Model)&lt;/strong>, un clasificador que aprende a predecir cuÃ¡nto prefiere un humano una respuesta sobre otra, dando una seÃ±al de recompensa continua.&lt;/p>
&lt;p>Posteriormente, mÃ©todos mÃ¡s simples como la &lt;strong>OptimizaciÃ³n Directa por Preferencia (Direct Preference Optimization - DPO)&lt;/strong> han demostrado ser igual de efectivos, evitando la complejidad del aprendizaje por refuerzo tradicional.&lt;/p>
&lt;p>En definitiva, RLHF moldea el comportamiento del LLM para alinearse con lo que &lt;em>deseamos&lt;/em> ver, no con lo que el modelo &lt;em>sabe&lt;/em> o &lt;em>piensa&lt;/em>.&lt;/p>
&lt;p>Le enseÃ±a a ser complaciente y a evitar lo â€œtÃ³xicoâ€ porque los humanos asÃ­ lo prefieren, no por un juicio moral inherente.&lt;/p>
&lt;h2 id="la-materia-prima-datos-masivos-y-su-filtrado">La Materia Prima: Datos Masivos y su Filtrado&lt;/h2>
&lt;p>El pre-entrenamiento de los LLMs se realiza sobre &lt;strong>â€œtodo Internetâ€&lt;/strong>.&lt;/p>
&lt;p>Esto incluye vastas colecciones como Common Crawl, que contiene alrededor de &lt;strong>250 mil millones de pÃ¡ginas web y un petabyte de datos&lt;/strong>.&lt;/p>
&lt;p>Pero el Internet es â€œsucioâ€ y no representativo.&lt;/p>
&lt;p>Imagina una pÃ¡gina web aleatoria: llena de HTML, publicidad, fragmentos sin terminar.&lt;/p>
&lt;p>Para que estos datos sean Ãºtiles, se requieren pasos de procesamiento intensivos, que incluyen:&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="flex justify-center ">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/ia/fig4_hu_b74c97a4d4debd70.webp 400w,
/post/ia/fig4_hu_f0bdf3ad77c25970.webp 760w,
/post/ia/fig4_hu_6e63ba7ee8334dc3.webp 1200w"
src="https://maicel.netlify.app/post/ia/fig4_hu_b74c97a4d4debd70.webp"
width="507"
height="760"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;!-- 1. **ExtracciÃ³n de texto**: Eliminar HTML y extraer contenido. -->
&lt;!-- 2.**Filtrado de contenido indeseable**: Eliminar contenido no seguro (NSFW), daÃ±ino o informaciÃ³n personal (PII). -->
&lt;!-- 3. **DeduplicaciÃ³n**: Eliminar contenido repetido. -->
&lt;!-- 4. **Filtrado heurÃ­stico**: Eliminar documentos de baja calidad basÃ¡ndose en reglas (por ejemplo, distribuciones de tokens inusuales, longitud extrema de palabras o documentos muy cortos/largos). -->
&lt;!-- 5. **Filtrado basado en modelos**: Entrenar un clasificador para identificar documentos de alta calidad, usando referencias de Wikipedia como punto de partida. -->
&lt;!-- 6. **ClasificaciÃ³n y ponderaciÃ³n por dominio**: Aumentar o disminuir el peso de ciertos dominios (por ejemplo, el cÃ³digo puede mejorar el razonamiento, por lo que se le da mÃ¡s peso). -->
&lt;!-- 7. **Entrenamiento final con datos de alta calidad**: "Sobreajustar" el modelo con datos de muy alta calidad al final del pre-entrenamiento, reduciendo la tasa de aprendizaje. -->
&lt;p>La escala de estos conjuntos de datos es asombrosa, pasando de &lt;strong>150 mil millones de tokens (800 GB)&lt;/strong> en benchmarks acadÃ©micos anteriores, hasta &lt;strong>15 billones de tokens&lt;/strong> para modelos de Ãºltima generaciÃ³n como Llama 3 (equivalente a miles de terabytes).&lt;/p>
&lt;p>La recopilaciÃ³n y curaciÃ³n de datos sigue siendo un desafÃ­o enorme y un Ã¡rea activa de investigaciÃ³n.&lt;/p>
&lt;h2 id="las-leyes-de-escalado-el-poder-de-lo-grande-y-sus-implicaciones-en-la-inteligencia">Las Leyes de Escalado: El Poder de lo Grande (y sus Implicaciones en la â€œInteligenciaâ€)&lt;/h2>
&lt;p>Uno de los descubrimientos mÃ¡s sorprendentes en LLMs es que &lt;strong>cuantos mÃ¡s datos se entrenen los modelos y mÃ¡s grandes sean los modelos, mejor serÃ¡ su rendimiento&lt;/strong>.&lt;/p>
&lt;p>A diferencia de lo que se enseÃ±a en muchas clases de aprendizaje automÃ¡tico, el â€œsobreajusteâ€ (overfitting) no parece ocurrir con los LLMs.&lt;/p>
&lt;p>Las &lt;strong>leyes de escalado&lt;/strong> nos muestran que si se aumenta la computaciÃ³n, los datos o el nÃºmero de parÃ¡metros, la pÃ©rdida de validaciÃ³n del modelo disminuye de forma predecible y lineal en una escala logarÃ­tmica.&lt;/p>
&lt;p>Esto es crucial porque permite a las compaÃ±Ã­as predecir cuÃ¡nto mejorarÃ¡n sus modelos en el futuro y cÃ³mo optimizar la asignaciÃ³n de recursos.&lt;/p>
&lt;p>Por ejemplo, el famoso artÃ­culo Chinchilla de DeepMind mostrÃ³ que la relaciÃ³n Ã³ptima es entrenar con &lt;strong>20 tokens por cada parÃ¡metro&lt;/strong> del modelo para maximizar la eficiencia del entrenamiento.&lt;/p>
&lt;p>&lt;strong>Un punto analÃ­tico aquÃ­&lt;/strong>: Que los modelos â€œmejorenâ€ al escalar no significa que se vuelvan intrÃ­nsecamente â€œmÃ¡s inteligentesâ€ en un sentido humano, o que estÃ©n mÃ¡s cerca de la conciencia.&lt;/p>
&lt;p>Simplemente, son &lt;strong>mÃ¡quinas de patrones increÃ­blemente sofisticadas&lt;/strong> que, con mÃ¡s datos y mÃ¡s capacidad computacional, son capaces de reconocer y generar patrones cada vez mÃ¡s complejos y coherentes, reduciendo su â€œpÃ©rdidaâ€ (es decir, volviÃ©ndose mejores en la predicciÃ³n del siguiente token).&lt;/p>
&lt;p>La â€œinteligenciaâ€ que percibimos es una propiedad emergente de esta capacidad de predicciÃ³n a gran escala, no una mente.&lt;/p>
&lt;!-- ### El Precio de la IlusiÃ³n de Inteligencia: Â¿CuÃ¡nto Cuesta un LLM? -->
&lt;!-- Entrenar un LLM es una empresa monumental y costosa. -->
&lt;!-- Tomemos como ejemplo el modelo **Llama 3 400B**, uno de los mejores modelos de cÃ³digo abierto actuales: **Tokens de entrenamiento**: 15.6 billones de tokens. -->
&lt;!-- - **ParÃ¡metros**: 45 mil millones. -->
&lt;!-- - **CÃ³mputo (FLOPs)**: Aproximadamente 3.8 x 10\^25 FLOPs. -->
&lt;!-- - **Hardware y tiempo**: Se entrenÃ³ en **16.000 GPUs H100** durante unos 70 dÃ­as (o 26 millones de horas de GPU). -->
&lt;!-- -**Costo estimado**: El alquiler de estas GPUs costarÃ­a alrededor de **52 millones de dÃ³lares**, y sumando los salarios del equipo, el costo total de entrenamiento rondarÃ­a los **75 millones de dÃ³lares**. -->
&lt;!-- - **Huella de carbono**: El entrenamiento de Llama 3 emitiÃ³ unas 4.000 toneladas de CO2 equivalente. -->
&lt;!-- Estos nÃºmeros son un testimonio de la inmensa inversiÃ³n necesaria para crear estos modelos capaces de generar una ilusiÃ³n tan convincente. -->
&lt;h2 id="sistemas-el-cerebro-detrÃ¡s-de-la-eficiencia">Sistemas: El Cerebro DetrÃ¡s de la Eficiencia&lt;/h2>
&lt;p>La computaciÃ³n es el cuello de botella mÃ¡s grande en el desarrollo de LLMs.
Comprar mÃ¡s GPUs es difÃ­cil por su alto costo y escasez, ademÃ¡s de las limitaciones fÃ­sicas en la comunicaciÃ³n entre ellas.&lt;/p>
&lt;p>Es crucial optimizar cÃ³mo se asignan los recursos y el pipeline de entrenamiento.&lt;/p>
&lt;p>Algunos trucos clave a nivel de sistemas incluyen: &lt;strong>Baja PrecisiÃ³n (Low Precision)&lt;/strong>: Usar nÃºmeros de punto flotante de 16 bits en lugar de 32 bits.&lt;/p>
&lt;p>Esto reduce la cantidad de datos que deben enviarse a las GPUs, acelerando la comunicaciÃ³n y disminuyendo el consumo de memoria.&lt;/p>
&lt;p>&lt;strong>FusiÃ³n de Operadores (Operator Fusion)&lt;/strong>: Las GPUs son muy lentas en la comunicaciÃ³n.
La fusiÃ³n de operadores combina varias operaciones consecutivas en una sola llamada al kernel, lo que significa que los datos se envÃ­an a la GPU una sola vez, todas las operaciones se realizan y luego los resultados se devuelven, lo que acelera significativamente el proceso (por ejemplo, &lt;code>torch.compile&lt;/code> en PyTorch puede duplicar la velocidad).&lt;/p>
&lt;h2 id="conclusiÃ³n-una-ilusiÃ³n-poderosa-no-un-pensamiento-consciente">ConclusiÃ³n: Una IlusiÃ³n Poderosa, No un Pensamiento Consciente&lt;/h2>
&lt;p>Desde sus cimientos como redes neuronales Transformer, pasando por el pre-entrenamiento con datos masivos de Internet y el afinamiento con retroalimentaciÃ³n humana, hasta la optimizaciÃ³n de sistemas y la gestiÃ³n de costos astronÃ³micos, la creaciÃ³n de un LLM es una hazaÃ±a de ingenierÃ­a y ciencia de datos.&lt;/p>
&lt;p>La prÃ³xima vez que interactÃºes con un chatbot, recordarÃ¡s que detrÃ¡s de esa respuesta fluida hay billones de tokens procesados, complejos algoritmos de entrenamiento, ingeniosas tÃ©cnicas de afinamiento y una infraestructura computacional masiva trabajando en conjunto.
&lt;strong>Estos modelos no â€œpiensanâ€ en el sentido humano de la palabra, ni poseen conciencia o una comprensiÃ³n profunda y holÃ­stica del mundo&lt;/strong>.&lt;/p>
&lt;p>Lo que hacen, y lo hacen de manera magistral, es &lt;strong>identificar y reproducir patrones estadÃ­sticos&lt;/strong> en los datos con los que fueron entrenados.&lt;/p>
&lt;p>Su habilidad para generar texto coherente, relevante y a menudo sorprendentemente â€œinteligenteâ€ es una testamentaciÃ³n de la &lt;strong>efectividad de la predicciÃ³n a escala masiva&lt;/strong>.
Es una &lt;strong>ilusiÃ³n de razonamiento&lt;/strong> tan convincente que a menudo nos hace cuestionar la naturaleza de la inteligencia misma.
Y es, sin duda, una de las maravillas tecnolÃ³gicas mÃ¡s grandes de nuestro tiempo.&lt;/p>
&lt;h2 id="bibliografÃ­a">BibliografÃ­a&lt;/h2>
&lt;div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
&lt;div id="ref-haykin" class="csl-entry">
&lt;p>Haykin, Simon. n.d. â€œNeural Networks and Learning Machines.â€ &lt;a href="http://dni.dali.dartmouth.edu/9umv9yghhaoq/13-dayana-hermann-1/read-0131471392-neural-networks-and-learning-machines.pdf" target="_blank" rel="noopener">http://dni.dali.dartmouth.edu/9umv9yghhaoq/13-dayana-hermann-1/read-0131471392-neural-networks-and-learning-machines.pdf&lt;/a>.&lt;/p>
&lt;/div>
&lt;div id="ref-stanfordonline2024" class="csl-entry">
&lt;p>Stanford Online. 2024. â€œStanford CS229 i Machine Learning i Building Large Language Models (LLMs),â€ August. &lt;a href="https://www.youtube.com/watch?v=9vM4p9NN0Ts" target="_blank" rel="noopener">https://www.youtube.com/watch?v=9vM4p9NN0Ts&lt;/a>.&lt;/p>
&lt;/div>
&lt;div id="ref-vaswani" class="csl-entry">
&lt;p>Vaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. n.d. â€œAttention Is All You Need.â€ &lt;a href="https://doi.org/10.48550/ARXIV.1706.03762" target="_blank" rel="noopener">https://doi.org/10.48550/ARXIV.1706.03762&lt;/a>.&lt;/p>
&lt;/div>
&lt;/div></description></item><item><title>Del Laboratorio al Mundo Real</title><link>https://maicel.netlify.app/post/generalizacion/</link><pubDate>Mon, 01 Sep 2025 00:00:00 +0000</pubDate><guid>https://maicel.netlify.app/post/generalizacion/</guid><description>&lt;h2 id="del-laboratorio-al-mundo-real-cÃ³mo-la-ciencia-cruza-el-puente-hacia-tu-vida">&lt;strong>Del Laboratorio al Mundo Real: CÃ³mo la Ciencia Cruza el Puente hacia tu Vida&lt;/strong>&lt;/h2>
&lt;p>Â¿Alguna vez has leÃ­do un titular cientÃ­fico y te has preguntado: &amp;ldquo;Â¿Esto me aplica a mÃ­?&amp;rdquo; o &amp;ldquo;Esto suena genial, pero Â¿es relevante para mi realidad?&amp;rdquo; Si es asÃ­, has tocado el nervio de uno de los mayores desafÃ­os de la investigaciÃ³n: cÃ³mo saltar del estudio controlado en un laboratorio al mundo real.&lt;/p>
&lt;p>El vÃ­deo, &amp;ldquo;El Estudio y el Mundo&amp;rdquo;, captura esta idea.&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/sY8-YxIeGu8?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video">&lt;/iframe>
&lt;/div>
&lt;p>Este blog profundiza en ese &lt;strong>puente a veces inestable&lt;/strong> que conecta la ciencia con nuestra vida diaria, explicando por quÃ© no se trata de desconfiar de la ciencia, sino de entenderla mejor para usarla de la forma mÃ¡s inteligente posible.&lt;/p>
&lt;hr>
&lt;h2 id="los-pilares-fundamentales-validez-interna-y-externa">&lt;strong>Los Pilares Fundamentales: Validez Interna y Externa&lt;/strong>&lt;/h2>
&lt;p>Para que un estudio sea realmente Ãºtil, sus hallazgos no solo deben ser correctos, sino tambiÃ©n aplicables. AquÃ­ es donde entran en juego dos conceptos clave:&lt;/p>
&lt;p>&lt;strong>Validez Interna: Â¿Se hizo bien el estudio?&lt;/strong> Se pregunta si los resultados son fiables para el grupo de personas que realmente participaron en la investigaciÃ³n. Un estudio puede ser metodolÃ³gicamente impecable y tener una validez interna &amp;ldquo;de 10&amp;rdquo;.&lt;/p>
&lt;p>&lt;strong>Validez Externa: Â¿Sirven estos resultados fuera del estudio?&lt;/strong> Se refiere a la capacidad de los hallazgos de un estudio para aplicarse a otros contextos, poblaciones o situaciones. Un estudio perfecto a nivel interno podrÃ­a ser casi inÃºtil si sus participantes son tan especÃ­ficos que sus resultados no pueden generalizarse.&lt;/p>
&lt;hr>
&lt;h2 id="generalizabilidad-y-transportabilidad-construyendo-el-puente">&lt;strong>Generalizabilidad y Transportabilidad: Construyendo el Puente&lt;/strong>&lt;/h2>
&lt;p>Existen dos estrategias principales para construir ese puente:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Generalizabilidad:&lt;/strong> Piensa en esto como una receta de cocina. Perfeccionaste una tarta en tu &amp;ldquo;cocina de prueba&amp;rdquo; y ahora vas a usar esa misma receta para alimentar a toda la familia. La poblaciÃ³n del estudio es solo una parte de un grupo mÃ¡s grande al que quieres aplicar los resultados. Por ejemplo, pasar de un estudio en California a todo Estados Unidos.&lt;/li>
&lt;li>&lt;strong>Transportabilidad:&lt;/strong> Ahora imagina que quieres adaptar esa misma receta para que funcione en otro paÃ­s, con ingredientes diferentes y un horno distinto. AquÃ­, la poblaciÃ³n del estudio es ajena a la poblaciÃ³n a la que quieres aplicar los resultados. Se trata de ver si los hallazgos de un estudio en Estados Unidos funcionan en una clÃ­nica en Europa.&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="por-quÃ©-es-tan-difÃ­cil-construir-el-puente">&lt;strong>Â¿Por QuÃ© es Tan DifÃ­cil Construir el Puente?&lt;/strong>&lt;/h2>
&lt;p>La principal dificultad es que los estudios, especialmente los ensayos clÃ­nicos aleatorios (RCTs), a menudo seleccionan a los participantes con criterios muy estrictos para garantizar una alta validez interna. Esto los hace poco representativos de la poblaciÃ³n general.&lt;/p>
&lt;ul>
&lt;li>&lt;strong>El Sesgo de SelecciÃ³n:&lt;/strong> Ocurre cuando las personas que participan en el estudio son diferentes de la poblaciÃ³n a la que se busca aplicar los resultados. No se trata solo de que no sean &amp;ldquo;representativas&amp;rdquo;, sino de que esas diferencias afecten la efectividad del tratamiento.&lt;/li>
&lt;li>&lt;strong>La Trampa de los Confusores:&lt;/strong> Factores no controlados en el estudio pueden generar asociaciones falsas o &amp;ldquo;espurias&amp;rdquo;, ocultando la verdadera relaciÃ³n entre el tratamiento y el resultado.&lt;/li>
&lt;li>&lt;strong>El Riesgo de la Subjetividad:&lt;/strong> La estadÃ­stica es una herramienta, no una verdad absoluta. La elecciÃ³n de variables y la interpretaciÃ³n de los resultados requieren un profundo conocimiento y juicio. La subjetividad puede &amp;ldquo;disfrazarse&amp;rdquo; detrÃ¡s de nÃºmeros y algoritmos, llevando a conclusiones errÃ³neas si no se razona con cuidado. Sin embargo, esta subjetividad no debe confundirse con la arbitrariedad, ya que se basa en la experiencia y el sentido comÃºn del investigador.&lt;/li>
&lt;li>&lt;strong>El Dilema del TamaÃ±o de Muestra:&lt;/strong> A pesar de lo que se podrÃ­a pensar, la determinaciÃ³n del tamaÃ±o de muestra de un estudio es mÃ¡s un arte que una ciencia exacta, basada en el juicio y la intuiciÃ³n, no solo en una fÃ³rmula.&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="herramientas-para-construir-un-puente-fuerte">&lt;strong>Herramientas para Construir un Puente Fuerte&lt;/strong>&lt;/h2>
&lt;p>Los estadÃ­sticos se dedican a medir la distancia entre el mundo del estudio y el mundo real. Una vez diagnosticado el problema, hay varias estrategias y herramientas para corregir el rumbo:&lt;/p>
&lt;p>&lt;strong>En la Fase de DiseÃ±o:&lt;/strong>&lt;/p>
&lt;p>La forma ideal es tomar una muestra aleatoria de la poblaciÃ³n objetivo, pero esto no siempre es posible. Las alternativas incluyen:&lt;/p>
&lt;p>&lt;strong>Ensayos clÃ­nicos pragmÃ¡ticos:&lt;/strong> DiseÃ±ados para imitar la prÃ¡ctica clÃ­nica real y ser mÃ¡s aplicables.&lt;/p>
&lt;p>&lt;strong>Muestreo:&lt;/strong> Seleccionar participantes para asegurar que haya una amplia representaciÃ³n o heterogeneidad.&lt;/p>
&lt;p>&lt;strong>DespuÃ©s de la RecolecciÃ³n de Datos (MÃ©todos AnalÃ­ticos):&lt;/strong>&lt;/p>
&lt;p>Si el estudio ya se realizÃ³, se usan mÃ©todos estadÃ­sticos para ajustar los resultados:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>PonderaciÃ³n (Weighting):&lt;/strong> Le da mÃ¡s &amp;ldquo;peso&amp;rdquo; a ciertos individuos del estudio para que la muestra se parezca mÃ¡s a la poblaciÃ³n real. Es como darles un megÃ¡fono a las voces que necesitan ser escuchadas.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Regresiones de Resultado:&lt;/strong> Se construyen modelos matemÃ¡ticos para predecir lo que habrÃ­a pasado si la gente del mundo real hubiera recibido el tratamiento del estudio.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Enfoques Doblemente Robustos:&lt;/strong> Combinan varias tÃ©cnicas para obtener resultados mÃ¡s sÃ³lidos.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="la-sabidurÃ­a-detrÃ¡s-de-los-nÃºmeros">&lt;strong>La SabidurÃ­a DetrÃ¡s de los NÃºmeros&lt;/strong>&lt;/h2>
&lt;p>La estadÃ­stica es una herramienta. Hay un poder inmenso en dominarla, pero tambiÃ©n un riesgo si se aplica sin un pensamiento crÃ­tico. El peligro de la &amp;ldquo;fÃ¡brica de publicaciones&amp;rdquo; que prioriza la significaciÃ³n estadÃ­stica (un valor p bajo) a veces eclipsa la relevancia clÃ­nica o biolÃ³gica de los hallazgos. No basta con que un resultado sea &amp;ldquo;estadÃ­sticamente significativo&amp;rdquo;. Lo realmente importante es si es significativo para la vida de las personas.&lt;/p>
&lt;p>Como se ha destacado, &amp;ldquo;pensar sin observar es un error, pero observar sin pensar es igualmente peligroso.&amp;rdquo; La aplicaciÃ³n mecÃ¡nica de un mÃ©todo poderoso puede llevar a conclusiones errÃ³neas.&lt;/p>
&lt;h2 id="tu-papel-como-consumidor-de-ciencia">&lt;strong>Tu Papel como Consumidor de Ciencia&lt;/strong>&lt;/h2>
&lt;p>La prÃ³xima vez que veas un titular impactante, haz la pregunta clave : &lt;strong>&amp;quot;Â¿En quiÃ©n se hizo este estudio?&amp;quot;&lt;/strong>&lt;/p>
&lt;p>Al entender la generalizabilidad y la transportabilidad, te conviertes en un consumidor de ciencia mÃ¡s crÃ­tico e informado. La verdadera meta no es solo que los estudios sean rigurosos, sino que su conocimiento pueda cruzar ese puente de forma segura y tener un impacto genuino en nuestras vidas. Porque, al final, una ciencia que no puede ser aplicada al mundo real pierde gran parte de su valor.&lt;/p>
&lt;h2 id="biblografÃ­a">BiblografÃ­a&lt;/h2>
&lt;ol>
&lt;li>Degtiar I, Rose S. A Review of Generalizability and Transportability. Annual Review of Statistics and Its Application [Internet]. 9 de marzo de 2023 [citado 1 de septiembre de 2025];10(Volume 10, 2023):501-24. Disponible en: &lt;a href="https://www.annualreviews.org/content/journals/10.1146/annurev-statistics-042522-103837" target="_blank" rel="noopener">https://www.annualreviews.org/content/journals/10.1146/annurev-statistics-042522-103837&lt;/a>&lt;/li>
&lt;/ol></description></item><item><title>Desvelando la LÃ³gica MatemÃ¡tica DetrÃ¡s de Causa y Efecto</title><link>https://maicel.netlify.app/post/inferencia-causal/</link><pubDate>Mon, 01 Sep 2025 00:00:00 +0000</pubDate><guid>https://maicel.netlify.app/post/inferencia-causal/</guid><description>&lt;h1 id="inferencia-causal-">Inferencia Causal :&lt;/h1>
&lt;p>El &lt;strong>marco de resultados potenciales&lt;/strong> se mantiene como la piedra angular del pensamiento causal, proporcionando el andamiaje conceptual para diferenciar la mera correlaciÃ³n de la causalidad. Ante la imposibilidad de llevar a cabo &lt;strong>ensayos controlados aleatorizados (RCT)&lt;/strong>, la investigaciÃ³n se ha nutrido de &lt;strong>mÃ©todos robustos&lt;/strong> que permiten extraer inferencias causales creÃ­bles de datos observacionales. En este contexto, herramientas como el &lt;strong>Propensity Score&lt;/strong> y los &lt;strong>estimadores doblemente robustos&lt;/strong> (DR) se utilizan para controlar los sesgos de selecciÃ³n a partir de covariables observables, mientras que los &lt;strong>Efectos de Tratamiento Promedio Condicionales (CATE)&lt;/strong>, apoyados en machine learning, permiten explorar la heterogeneidad del efecto entre subpoblaciones. Asimismo, un conjunto de estrategias cuasi-experimentales ha abierto nuevos horizontes en la investigaciÃ³n, incluyendo el uso de &lt;strong>Variables Instrumentales (IV)&lt;/strong> para corregir la confusiÃ³n no observada, el &lt;strong>Diferencias-en-Diferencias (DID)&lt;/strong> y el &lt;strong>Control SintÃ©tico (SC)&lt;/strong> para comparar trayectorias temporales, y la &lt;strong>RegresiÃ³n Discontinua (RDD)&lt;/strong> para explotar umbrales de asignaciÃ³n, todas ellas permitiendo identificar efectos causales en contextos donde la aleatorizaciÃ³n no es factible.&lt;/p>
&lt;hr>
&lt;h2 id="1-el-desafÃ­o-central-solo-vemos-un-lado-de-la-moneda">1. El desafÃ­o central: solo vemos un lado de la moneda&lt;/h2>
&lt;p>Imagina que quieres evaluar el impacto de una nueva polÃ­tica de vacunaciÃ³n. Para cada persona, podrÃ­amos definir dos mundos posibles: uno donde recibe la vacuna y otro donde no. Pero en la prÃ¡ctica solo observamos un mundo: el que ocurriÃ³. Ese es el &lt;strong>â€œproblema fundamental de la inferencia causalâ€&lt;/strong>.&lt;/p>
&lt;p>El &lt;strong>marco de resultados potenciales&lt;/strong> formaliza esta idea:&lt;/p>
$$
\tau_{\text{sample}} = \frac{1}{N} \sum_{i=1}^{N} (Y_i(1) - Y_i(0))
$$
&lt;p>En un ensayo controlado aleatorizado (RCT), la aleatorizaciÃ³n nos permite estimar este efecto promedio simplemente comparando medias. Pero Â¿quÃ© pasa cuando los RCT no son factibles por razones Ã©ticas, logÃ­sticas o econÃ³micas?&lt;/p>
&lt;hr>
&lt;h2 id="2-estudios-observacionales-cuando-no-hay-azar-pero-sÃ­-ingenio">2. Estudios observacionales: cuando no hay azar, pero sÃ­ ingenio&lt;/h2>
&lt;p>En contextos reales â€”salud pÃºblica, economÃ­a, polÃ­ticas socialesâ€” dependemos de datos observacionales. AllÃ­, la clave es suponer que, condicional en ciertas variables previas ($X_i$), la asignaciÃ³n al tratamiento es â€œtan buena como aleatoriaâ€.&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Propensity Score (Rosenbaum &amp;amp; Rubin, 1983):&lt;/strong> condensa mÃºltiples covariables en una Ãºnica probabilidad de recibir tratamiento, facilitando el emparejamiento y la ponderaciÃ³n.&lt;/li>
&lt;li>&lt;strong>Estimadores doblemente robustos:&lt;/strong> combinan modelos de resultado y de asignaciÃ³n al tratamiento; basta con que uno estÃ© bien especificado para obtener estimaciones consistentes.&lt;/li>
&lt;li>&lt;strong>CATE (Conditional Average Treatment Effect):&lt;/strong> con machine learning, hoy podemos explorar cÃ³mo los efectos varÃ­an entre subpoblaciones (ej. polÃ­ticas de empleo mÃ¡s efectivas en jÃ³venes que en adultos mayores).&lt;/li>
&lt;/ul>
&lt;p>âš ï¸ Cuando sospechamos de confusiÃ³n no observada, entran en juego &lt;strong>anÃ¡lisis de sensibilidad&lt;/strong> (Manski bounds, mÃ©todos de Rosenbaum).&lt;/p>
&lt;hr>
&lt;h2 id="3-estrategias-avanzadas-cuando-la-confusiÃ³n-no-puede-ignorarse">3. Estrategias avanzadas cuando la confusiÃ³n no puede ignorarse&lt;/h2>
&lt;h3 id="a-variables-instrumentales-iv">a) Variables Instrumentales (IV)&lt;/h3>
&lt;p>Si un confusor no observado afecta tanto al tratamiento como al resultado, un &lt;strong>instrumento vÃ¡lido&lt;/strong> ($Z$) puede rescatar el anÃ¡lisis. Ejemplo clÃ¡sico: la distancia a una universidad como instrumento para estudiar el impacto de la educaciÃ³n en ingresos.&lt;/p>
&lt;p>Bajo ciertos supuestos, identificamos el &lt;strong>LATE (Local Average Treatment Effect)&lt;/strong> para quienes cambian su estado de tratamiento debido al instrumento.&lt;/p>
&lt;hr>
&lt;h3 id="b-diferencias-en-diferencias-did-y-control-sintÃ©tico-sc">b) Diferencias-en-Diferencias (DID) y Control SintÃ©tico (SC)&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>DID&lt;/strong>: compara tendencias pre y post en grupos tratados y no tratados. Ejemplo: medir el impacto de un aumento del salario mÃ­nimo sobre el empleo.&lt;/li>
&lt;li>&lt;strong>SC&lt;/strong>: construye un â€œgemelo sintÃ©ticoâ€ de la unidad tratada combinando unidades no tratadas. Ejemplo: evaluar el impacto de una ley antitabaco en California comparando con un control sintÃ©tico formado por otros estados.&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h3 id="c-regresiÃ³n-discontinua-rdd">c) RegresiÃ³n Discontinua (RDD)&lt;/h3>
&lt;p>Aprovecha umbrales de asignaciÃ³n. Ejemplo: un programa de becas asignado a estudiantes con notas â‰¥ 8.0. Comparar resultados justo por encima y por debajo del corte estima el efecto del programa en los â€œmarginalesâ€.&lt;/p>
&lt;hr>
&lt;h2 id="4-horizontes-emergentes-combinar-evidencia">4. Horizontes emergentes: combinar evidencia&lt;/h2>
&lt;p>Dos lÃ­neas prometedoras:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Surrogacy:&lt;/strong> usar resultados a corto plazo como sustitutos de resultados de largo plazo.&lt;/li>
&lt;li>&lt;strong>IntegraciÃ³n de experimentos y observacionales:&lt;/strong> Athey et al. (2020) proponen usar experimentos para identificar y corregir confusores en estudios observacionales.&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="-tabla-comparativa-de-mÃ©todos-de-inferencia-causal">ðŸ“Š Tabla comparativa de mÃ©todos de inferencia causal&lt;/h2>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>MÃ©todo&lt;/th>
&lt;th>Supuesto clave&lt;/th>
&lt;th>Ventajas&lt;/th>
&lt;th>Limitaciones&lt;/th>
&lt;th>Ejemplo tÃ­pico&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;strong>RCT&lt;/strong>&lt;/td>
&lt;td>AsignaciÃ³n aleatoria&lt;/td>
&lt;td>Estimador insesgado, alta validez interna&lt;/td>
&lt;td>Costoso, a veces poco Ã©tico, baja validez externa&lt;/td>
&lt;td>Ensayo clÃ­nico de un fÃ¡rmaco&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Propensity Score / DR&lt;/strong>&lt;/td>
&lt;td>ConfusiÃ³n controlada por covariables observadas&lt;/td>
&lt;td>Flexibilidad, usa datos observacionales grandes&lt;/td>
&lt;td>Vulnerable a confusiÃ³n no observada&lt;/td>
&lt;td>Impacto de programas sociales&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>IV&lt;/strong>&lt;/td>
&lt;td>Relevancia + exclusiÃ³n + exogeneidad&lt;/td>
&lt;td>Corrige confusiÃ³n no observada&lt;/td>
&lt;td>DifÃ­cil encontrar instrumentos vÃ¡lidos&lt;/td>
&lt;td>EducaciÃ³n â†’ ingresos&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>DID&lt;/strong>&lt;/td>
&lt;td>Tendencias paralelas&lt;/td>
&lt;td>Simple, interpretable&lt;/td>
&lt;td>FrÃ¡gil si tendencias difieren&lt;/td>
&lt;td>PolÃ­ticas laborales&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>SC&lt;/strong>&lt;/td>
&lt;td>Unidades control combinan bien la pre-tendencia&lt;/td>
&lt;td>MÃ¡s creÃ­ble que DID en casos individuales&lt;/td>
&lt;td>Requiere datos ricos pre-tratamiento&lt;/td>
&lt;td>Leyes de salud pÃºblica&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>RDD&lt;/strong>&lt;/td>
&lt;td>Continuidad de potenciales en el umbral&lt;/td>
&lt;td>InterpretaciÃ³n clara, diseÃ±o cuasi-experimental&lt;/td>
&lt;td>VÃ¡lido solo cerca del umbral&lt;/td>
&lt;td>Programas de becas&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;hr>
&lt;h2 id="5-conclusiÃ³n-prÃ¡ctica">5. ConclusiÃ³n prÃ¡ctica&lt;/h2>
&lt;p>La inferencia causal no es una caja negra: es un conjunto de &lt;strong>herramientas matemÃ¡ticas y conceptuales&lt;/strong> que, bien aplicadas, permiten a responsables de polÃ­ticas, clÃ­nicos y cientÃ­ficos sociales responder la pregunta clave: &lt;em>Â¿quÃ© pasarÃ­a si?&lt;/em>&lt;/p>
&lt;p>La frontera actual estÃ¡ en combinar evidencia, explotar machine learning para heterogeneidad y desarrollar mÃ©todos mÃ¡s robustos frente a confusiÃ³n no observada.&lt;/p>
&lt;hr>
&lt;h2 id="-referencias-recomendadas">ðŸ“š Referencias recomendadas&lt;/h2>
&lt;ul>
&lt;li>Rosenbaum PR, Rubin DB. &lt;em>The central role of the propensity scoreâ€¦&lt;/em> Biometrika. 1983. &lt;a href="https://pubmed.ncbi.nlm.nih.gov/12009849/" target="_blank" rel="noopener">PubMed PMID: 12009849&lt;/a>&lt;/li>
&lt;li>HernÃ¡n MA, Robins JM. &lt;em>Causal Inference: What If&lt;/em>. 2020. &lt;a href="https://pubmed.ncbi.nlm.nih.gov/33290294/" target="_blank" rel="noopener">PubMed PMID: 33290294&lt;/a>&lt;/li>
&lt;li>Imbens GW, Rubin DB. &lt;em>Causal Inference for Statistics, Social, and Biomedical Sciences&lt;/em>. 2015.&lt;/li>
&lt;li>Athey S, Imbens GW. &lt;em>Design-based analysis in difference-in-differences settings.&lt;/em> J Econometrics. 2022. &lt;a href="https://pubmed.ncbi.nlm.nih.gov/36212825/" target="_blank" rel="noopener">PubMed PMID: 36212825&lt;/a>&lt;/li>
&lt;li>Abadie A. &lt;em>Using synthetic controls.&lt;/em> J Econometrics. 2021.&lt;/li>
&lt;/ul></description></item><item><title>SignificaciÃ³n EstadÃ­stica, Â¿Ciencia o Pirotecnia?</title><link>https://maicel.netlify.app/post/2025-08-10-significacion/</link><pubDate>Sun, 10 Aug 2025 15:30:00 +0000</pubDate><guid>https://maicel.netlify.app/post/2025-08-10-significacion/</guid><description>&lt;p>Ese momento de euforia al ver &lt;code>p &amp;lt; 0.05&lt;/code>â€¦ Â¿es un descubrimiento genuino o solo un destello engaÃ±oso de pirotecnia estadÃ­stica?&lt;/p>
&lt;p>En la ciencia, hay un instante que todos los investigadores anhelan. Es la culminaciÃ³n de meses, a veces aÃ±os, de riguroso trabajo. Corres el anÃ¡lisis y, de repente, ahÃ­ estÃ¡: &lt;code>p &amp;lt; 0.05&lt;/code>. Es una &lt;strong>explosiÃ³n de alivio&lt;/strong>, un destello de â€œÂ¡Eureka!â€ en la oscuridad de la incertidumbre. Sentimos que hemos encontrado algo real, algo digno de ser publicado.&lt;/p>
&lt;p>Pero, Â¿y si ese destello es solo eso? Un estallido momentÃ¡neo, deslumbrante y ruidoso, pero que en el fondo significa muy poco. Â¿Y si nuestro ritual mÃ¡s sagrado es, en realidad, un simple juego de pirotecnia, diseÃ±ado para impresionar mÃ¡s que para iluminar?&lt;/p>
&lt;p>Durante dÃ©cadas, hemos aceptado el umbral de significaciÃ³n estadÃ­stica como el Ã¡rbitro indiscutible de la verdad cientÃ­fica. Sin embargo, la evidencia acumulada â€”desde las crÃ­ticas de su propio creador (Ronald Fisher) hasta las advertencias oficiales de la American Statistical Association (ASA) en 2016 y el clamor de cientos de cientÃ­ficos en la revista &lt;em>Nature&lt;/em> â€” nos obliga a una conclusiÃ³n incÃ³moda(Amrhein, Greenland, and McShane 2019; Wasserstein and Lazar 2016) : &lt;strong>el emperador estadÃ­stico estÃ¡ desnudo&lt;/strong>. La prÃ¡ctica de las Pruebas de SignificaciÃ³n de la HipÃ³tesis Nula (NHST, por sus siglas en inglÃ©s) no es un pilar de rigor, sino un ritual plagado de lÃ³gica errÃ³nea, confusiÃ³n e inadecuaciÃ³n para la verdadera investigaciÃ³n.&lt;/p>
&lt;h2 id="el-cohete-mÃ¡s-grande-no-significa-mejor">El Cohete: MÃ¡s Grande no Significa Mejor&lt;/h2>
&lt;p>En la pirotecnia, un cohete mÃ¡s grande produce una explosiÃ³n mÃ¡s fuerte. Es simple fÃ­sica. En la estadÃ­stica, ocurre algo perturbadoramente similar. El â€œcoheteâ€ es nuestro tamaÃ±o muestral.&lt;/p>
&lt;p>La conclusiÃ³n de una prueba de significaciÃ³n depende de manera crucial del tamaÃ±o de la muestra. Con un cohete lo suficientemente grande (una muestra de miles o decenas de miles de personas), la diferencia mÃ¡s trivial e insignificante para el mundo real se convertirÃ¡, casi por arte de magia, en â€œestadÃ­sticamente significativaâ€. Por el contrario, un efecto importante y real puede pasar desapercibido si nuestro cohete es demasiado pequeÃ±o.&lt;/p>
&lt;p>Esto nos lleva a una &lt;strong>verdad grotesca&lt;/strong>: la decisiÃ³n sobre si un hallazgo es â€œrealâ€ a menudo depende mÃ¡s de los recursos del investigador para recolectar datos masivos que de la naturaleza fundamental del fenÃ³meno estudiado. El estallido nos dice mÃ¡s sobre el tamaÃ±o del cohete que sobre la belleza del cielo que intenta iluminar.&lt;/p>
&lt;!-- ```{r} -->
&lt;!-- set.seed(123) -->
&lt;!-- library(ggplot2) -->
&lt;!-- effect &lt;- 0.1 -->
&lt;!-- sd &lt;- 1 -->
&lt;!-- N &lt;- seq(20, 10000, by=50) -->
&lt;!-- p_values &lt;- sapply(N, function(n) { -->
&lt;!-- t.test(rnorm(n, mean=effect, sd=sd), mu=0)$p.value -->
&lt;!-- }) -->
&lt;!-- data &lt;- data.frame(N, p_values) -->
&lt;!-- ggplot(data, aes(N, p_values)) + -->
&lt;!-- geom_line() + -->
&lt;!-- geom_hline(yintercept = 0.05, linetype = "dashed", color="red") + -->
&lt;!-- labs(x = "TamaÃ±o muestral (N)", y = "Valor p") + -->
&lt;!-- theme_minimal() -->
&lt;!-- ``` -->
&lt;!-- AquÃ­ irÃ­a tu grÃ¡fico explicativo del "Cohete (TamaÃ±o Muestral)": -->
&lt;!-- Un grÃ¡fico mostrando cÃ³mo un efecto trivial (ej: diferencia de 0.1 unidades) se vuelve "significativo" (p&lt;0.05) a medida que N aumenta de 100 a 10,000. Puedes usar `ggplot2` en R para esto. -->
&lt;!-- Ejemplo de cÃ³digo R (este no generarÃ­a un grÃ¡fico, solo un placeholder para tu referencia): -->
&lt;!-- ```{r cohete_plot, echo=FALSE, fig.cap="Impacto del tamaÃ±o muestral en la significaciÃ³n estadÃ­stica para un efecto constante."} -->
&lt;!-- # CÃ³digo para generar el grÃ¡fico de N vs p-valor -->
&lt;!-- # plot(your_data$N, your_data$p_value, type="l", main="CÃ³mo N afecta el p-valor", -->
&lt;!-- # xlab="TamaÃ±o Muestral (N)", ylab="Valor p") -->
&lt;!-- # abline(h=0.05, col="red", lty=2) -->
&lt;!-- ``` -->
&lt;h2 id="la-explosiÃ³n-un-caos-de-luz-y-malentendidos">La ExplosiÃ³n: Un Caos de Luz y Malentendidos&lt;/h2>
&lt;p>La explosiÃ³n de un fuego artificial es un evento caÃ³tico. Su interpretaciÃ³n es subjetiva. Â¿Fue espectacular? Â¿Fue un fracaso? Lo mismo ocurre con el valor &lt;em>p&lt;/em>.&lt;/p>
&lt;h2 id="lÃ³gica-errÃ³nea-juzgando-por-lo-que-no-vimos">LÃ³gica ErrÃ³nea: Juzgando por lo que no Vimos&lt;/h2>
&lt;p>La lÃ³gica detrÃ¡s del valor &lt;em>p&lt;/em> es, siendo generosos, peculiar. Se calcula asumiendo que la hipÃ³tesis nula (Hâ‚€ â€”la hipÃ³tesis de no-efecto, de que no hay diferencia o relaciÃ³n) es cierta, y luego se determina la probabilidad de haber observado nuestros datos &lt;em>o datos aÃºn mÃ¡s extremos&lt;/em> bajo esa suposiciÃ³n. PiÃ©nsalo: nuestra conclusiÃ³n sobre lo que &lt;em>sÃ­&lt;/em> ocurriÃ³ depende de la probabilidad de cosas que ni siquiera presenciamos. Es un &lt;strong>absurdo subyacente&lt;/strong>.&lt;/p>
&lt;p>AdemÃ¡s, caemos constantemente en la &lt;strong>falacia de la probabilidad invertida&lt;/strong>: el valor &lt;em>p&lt;/em> nos dice la probabilidad de los datos dada la hipÃ³tesis nula (P(Datos|Hâ‚€)), pero nosotros creemos errÃ³neamente que nos dice la probabilidad de que la hipÃ³tesis nula sea cierta dados nuestros datos (P(Hâ‚€|Datos)). Son dos cosas radicalmente distintas, y confundirlas es un error fundamental.&lt;/p>
&lt;!-- &lt;!-- AquÃ­ irÃ­a tu diagrama de flujo simple o tabla comparativa para "ConfusiÃ³n P(D|H) vs P(H|D)": -->
&lt;!-- Puedes usarmermaid para diagramas simples en RMarkdown o una tabla Markdown para la comparaciÃ³n. -->
&lt;!-- Ejemplo de cÃ³digo mermaid (necesitarÃ­as `config: {mermaid: {sequence: {diagramMarginX: 10}}}` en el YAML para que funcione): -->
&lt;h2 id="confusiÃ³n-el-ruido-no-es-la-seÃ±al">ConfusiÃ³n: El Ruido no es la SeÃ±al&lt;/h2>
&lt;p>La confusiÃ³n mÃ¡s extendida es la de equiparar â€œsignificaciÃ³n estadÃ­sticaâ€ con â€œimportancia prÃ¡cticaâ€ o â€œrelevancia cientÃ­ficaâ€. Un estallido muy ruidoso no significa que el descubrimiento sea importante, Ãºtil o generalizable. Esta obsesiÃ³n por el ruido estadÃ­stico, esta endÃ©mica â€œsignificant-itisâ€, nos ha distraÃ­do de lo que realmente importa en la investigaciÃ³n: la magnitud del efecto y la relevancia clÃ­nica, social o teÃ³rica de nuestros hallazgos.&lt;/p>
&lt;h2 id="el-caso-del-chocolate-que-hace-perder-peso">El Caso del Chocolate que Hace Perder Peso&lt;/h2>
&lt;p>Para ilustrar esta locura, consideremos el tristemente famoso estudio de John Bohannon en 2015, â€œChocolate con fines de pÃ©rdida de pesoâ€ . Con un pequeÃ±o presupuesto, Bohannon realizÃ³ un ensayo aleatorio, controlado con chocolate, utilizando un nÃºmero muy reducido de participantes y midiendo 18 variables distintas(Bohannon 2015). Al analizar &lt;em>todas&lt;/em> las combinaciones posibles, encontrÃ³ que con una muestra tan pequeÃ±a y al realizar mÃºltiples pruebas (un tipo de &lt;em>p-hacking&lt;/em>), era casi inevitable que alguna variable arrojara un p-valor menor a 0.05 &lt;strong>por pura casualidad&lt;/strong>. Con su &lt;code>p &amp;lt; 0.05&lt;/code> â€œsignificativoâ€, los medios de comunicaciÃ³n sensacionalistas se lanzaron a la noticia: â€œEl chocolate hace perder peso!â€. Este caso es un claro ejemplo de cÃ³mo un â€œdestelloâ€ estadÃ­stico puede ser completamente engaÃ±oso y carecer de cualquier importancia real, pero aun asÃ­ generar titulares y confusiÃ³n(Bohannon 2015).&lt;/p>
&lt;h2 id="el-veredicto-la-falsa-dicotomÃ­a-del-ohhh-o-el-silencio">El Veredicto: La Falsa DicotomÃ­a del â€œOhhhâ€ o el Silencio&lt;/h2>
&lt;p>Quien observa fuegos artificiales emite un veredicto simple: el â€œÂ¡Ohhh!â€ de asombro o el silencio de la indiferencia. Las pruebas de significaciÃ³n nos han impuesto esta misma decisiÃ³n binaria: o un resultado es significativo (&lt;code>p &amp;lt; 0.05&lt;/code>), o no lo es. Es un interruptor de encendido/apagado.&lt;/p>
&lt;p>Pero la ciencia no funciona asÃ­. El conocimiento cientÃ­fico no es una serie de decisiones de â€œsÃ­/noâ€. Es un proceso gradual de ajuste de nuestras creencias a la luz de la evidencia acumulada. Es un paisaje de grises, no un contraste de blanco y negro. Al forzarnos a este mecanicismo, a esta â€œsucesiÃ³n de â€˜decisionesâ€™ automÃ¡ticasâ€ que el propio Fisher denunciÃ³, hemos empobrecido el discurso cientÃ­fico, ignorando matices cruciales como la magnitud del efecto o la precisiÃ³n de la estimaciÃ³n.&lt;/p>
&lt;h2 id="despuÃ©s-del-humo-hacia-una-ciencia-iluminada">DespuÃ©s del Humo: Hacia una Ciencia Iluminada&lt;/h2>
&lt;p>Cuando el humo de la pirotecnia se disipa, Â¿quÃ© nos queda? Nos queda la tarea de encontrar una luz mÃ¡s honesta y duradera para la ciencia. Afortunadamente, esta luz existe y estÃ¡ ganando terreno.&lt;/p>
&lt;p>La alternativa fundamental es pasar de la &lt;strong>decisiÃ³n binaria&lt;/strong> a la &lt;strong>estimaciÃ³n&lt;/strong>. En lugar de preguntar obsesivamente â€œÂ¿Hay un efecto (sÃ­/no)?â€, debemos preguntar â€œÂ¿CuÃ¡l es la magnitud del efecto y cuÃ¡n seguros estamos de esa estimaciÃ³n?â€.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Intervalos de Confianza (o de Compatibilidad):&lt;/strong> Son nuestra primera y mÃ¡s accesible herramienta para una inferencia mÃ¡s sensata. Los Intervalos de Confianza no nos dan un simple â€œsÃ­/noâ€, sino un &lt;strong>rango de valores plausibles&lt;/strong> para el efecto real en la poblaciÃ³n. Nos muestran tanto la magnitud estimada del efecto como la incertidumbre que lo rodea.&lt;/p>
&lt;p>Cuando vemos un Intervalo de Confianza del 95% para una diferencia, por ejemplo, esto significa que si repitiÃ©ramos el estudio muchas, muchas veces bajo las mismas condiciones, el 95% de esos intervalos contendrÃ­an el verdadero valor del efecto que estamos tratando de estimar. Nos invitan a pensar en la variabilidad y la precisiÃ³n de nuestras estimaciones, no solo en un umbral arbitrario. Son una luz constante que ilumina un paisaje, permitiÃ©ndonos ver el terreno completo, no un destello que ciega momentÃ¡neamente.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;!-- &lt;!-- AquÃ­ irÃ­a tu grÃ¡fico de "Intervalos de Confianza/Compatibilidad": -->
&lt;!-- Un grÃ¡fico con varios ICs superpuestos (algunos estrechos, otros anchos, algunos cruzando cero, otros no) para ilustrar que muestran magnitud *e* incertidumbre, no solo "sÃ­/no". -->
&lt;!-- ```{r ic_plot, echo=FALSE, fig.cap="VisualizaciÃ³n de Intervalos de Confianza: Magnitud y Incertidumbre."} -->
&lt;!-- # CÃ³digo para generar el grÃ¡fico de ICs -->
&lt;!-- # library(ggplot2) -->
&lt;!-- # data.frame( -->
&lt;!-- # Effect = c(0.5, 1.2, -0.3, 0.8), -->
&lt;!-- # Lower = c(0.1, 0.8, -0.7, 0.2), -->
&lt;!-- # Upper = c(0.9, 1.6, 0.1, 1.4) -->
&lt;!-- # ) %>% -->
&lt;!-- # ggplot(aes(y = factor(1:4), x = Effect, xmin = Lower, xmax = Upper)) + -->
&lt;!-- # geom_point() + geom_errorbarh(height = 0.2) + -->
&lt;!-- # geom_vline(xintercept = 0, linetype = "dashed", color = "grey") + -->
&lt;!-- # labs(x = "Magnitud del Efecto", y = "Estudio") + -->
&lt;!-- # theme_minimal() -->
&lt;!-- ``` -->
&lt;!-- -->
&lt;ul>
&lt;li>
&lt;p>&lt;strong>El Enfoque Bayesiano:&lt;/strong> Es el siguiente paso evolutivo en la inferencia estadÃ­stica, y es la encarnaciÃ³n matemÃ¡tica del razonamiento cientÃ­fico. Los mÃ©todos bayesianos nos permiten hacer lo que siempre hemos querido hacer: &lt;strong>combinar la evidencia de nuestro estudio actual con todo el conocimiento previo existente&lt;/strong> (estudios anteriores, plausibilidad biolÃ³gica, experiencia clÃ­nica) para llegar a una conclusiÃ³n actualizada y probabilÃ­stica sobre nuestras hipÃ³tesis.&lt;/p>
&lt;p>A diferencia del valor &lt;em>p&lt;/em>, el enfoque bayesiano responde directamente a la pregunta que realmente queremos hacer: â€œ&lt;strong>Dados estos nuevos datos, Â¿quÃ© tan creÃ­ble es mi hipÃ³tesis ahora?&lt;/strong>â€. Nos da una probabilidad posterior de nuestra hipÃ³tesis, una medida directa de nuestra creencia actualizada. Aunque puede parecer mÃ¡s complejo al principio, el razonamiento bayesiano se alinea intuitivamente con cÃ³mo los cientÃ­ficos y las personas actualizan sus creencias en la vida real.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Dejemos la pirotecnia para las celebraciones. Es hora de que la ciencia deje de buscar destellos efÃ­meros y se dedique a construir una iluminaciÃ³n constante, acumulativa y, sobre todo, &lt;strong>honesta&lt;/strong>. Es el momento de una ciencia mÃ¡s transparente, rigurosa y, sÃ­, Â¡mÃ¡s divertida de interpretar!&lt;/p>
&lt;hr>
&lt;h2 id="tu-turno">Â¡Tu Turno!&lt;/h2>
&lt;p>Â¿Te has encontrado con la â€œtiranÃ­a del p&amp;lt;0.05â€ en tu campo? Â¿QuÃ© alternativas usas o te gustarÃ­a ver mÃ¡s promovidas en la investigaciÃ³n? Â¡Comparte tu experiencia y tus pensamientos en los comentarios a continuaciÃ³n!&lt;/p>
&lt;hr>
&lt;h2 id="referencias">Referencias&lt;/h2>
&lt;div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
&lt;div id="ref-amrhein2019" class="csl-entry">
&lt;p>Amrhein, Valentin, Sander Greenland, and Blake McShane. 2019. â€œScientists Rise up Against Statistical Significance.â€ &lt;em>Nature&lt;/em> 567 (7748): 305â€“7. &lt;a href="https://doi.org/10.1038/d41586-019-00857-9" target="_blank" rel="noopener">https://doi.org/10.1038/d41586-019-00857-9&lt;/a>.&lt;/p>
&lt;/div>
&lt;div id="ref-bohannon2015" class="csl-entry">
&lt;p>Bohannon, John. 2015. â€œI Fooled Millions into Thinking Chocolate Helps Weight Loss. Hereâ€™s How.â€ &lt;a href="https://gizmodo.com/i-fooled-millions-into-thinking-chocolate-helps-weight-1707251800" target="_blank" rel="noopener">https://gizmodo.com/i-fooled-millions-into-thinking-chocolate-helps-weight-1707251800&lt;/a>.&lt;/p>
&lt;/div>
&lt;div id="ref-wasserstein2016" class="csl-entry">
&lt;p>Wasserstein, Ronald L., and Nicole A. Lazar. 2016. â€œThe ASA Statement on &lt;em>p&lt;/em> -Values: Context, Process, and Purpose.â€ &lt;em>The American Statistician&lt;/em> 70 (2): 129â€“33. &lt;a href="https://doi.org/10.1080/00031305.2016.1154108" target="_blank" rel="noopener">https://doi.org/10.1080/00031305.2016.1154108&lt;/a>.&lt;/p>
&lt;/div>
&lt;/div></description></item><item><title>DiseÃ±os Alternativos a Ensayos ClÃ­nicos Controlados Aleatorizados: Contextos de AplicaciÃ³n y Riesgos Regulatorios</title><link>https://maicel.netlify.app/post/atajos/</link><pubDate>Thu, 07 Aug 2025 00:00:00 +0000</pubDate><guid>https://maicel.netlify.app/post/atajos/</guid><description>&lt;p>ðŸŽ§ &lt;strong>Escucha el podcast de esta publicaciÃ³n&lt;/strong>
&lt;audio controls >
&lt;source src="https://maicel.netlify.app/mp3/atajos.mp3" type="audio/mpeg">
&lt;/audio>
&lt;/p>
&lt;h1 id="introducciÃ³n-fundamentos-de-evidencia-confirmatoria">IntroducciÃ³n: Fundamentos de evidencia confirmatoria&lt;/h1>
&lt;p>Los ensayos clÃ­nicos controlados, aleatorizados y enmascarados (ECAs) constituyen el marco metodolÃ³gico mÃ¡s robusto para evaluar la &lt;strong>eficacia y seguridad&lt;/strong> de nuevas intervenciones terapÃ©uticas. Son considerados el &amp;ldquo;estÃ¡ndar de oro&amp;rdquo; en investigaciÃ³n clÃ­nica por agencias como &lt;strong>ICH, EMA y FDA&lt;/strong>, ya que proporcionan el mayor control contra el sesgo y la mayor solidez en inferencia causal.&lt;/p>
&lt;p>En este marco, los &lt;strong>ensayos confirmatorios&lt;/strong> son aquellos diseÃ±ados explÃ­citamente para confirmar hipÃ³tesis clÃ­nicas relevantes, con base en anÃ¡lisis predefinidos y control adecuado de errores. Cuando estos estudios sustentan una solicitud de comercializaciÃ³n, adquieren la condiciÃ³n de &lt;strong>ensayos pivotal&lt;/strong> (terminologÃ­a empleada por FDA y EMA).&lt;/p>
&lt;p>En principio, se recomienda la presentaciÃ³n de &lt;strong>dos ensayos confirmatorios independientes&lt;/strong>. Sin embargo, &lt;strong>tanto EMA como FDA&lt;/strong> contemplan aprobaciones basadas en &lt;strong>un Ãºnico ensayo pivotal&lt;/strong>, siempre que estÃ© respaldado por &lt;strong>evidencia complementaria rigurosa&lt;/strong>. La &lt;strong>FDA&lt;/strong>, mediante el concepto de &lt;strong>evidencia confirmatoria&lt;/strong> (FDA 2023), formaliza esta vÃ­a alternativa. La &lt;strong>EMA&lt;/strong>, aunque no utiliza esa denominaciÃ³n, acepta enfoques equivalentes (meta-anÃ¡lisis, controles histÃ³ricos validados, anÃ¡lisis de consistencia interna).&lt;/p>
&lt;h2 id="tabla-1-tÃ©rminos-clave-definiciÃ³n-origen-normativo-y-funciÃ³n-regulatoria">Tabla 1. TÃ©rminos clave: definiciÃ³n, origen normativo y funciÃ³n regulatoria&lt;/h2>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;strong>TÃ©rmino&lt;/strong>&lt;/th>
&lt;th>&lt;strong>Fuente regulatoria&lt;/strong>&lt;/th>
&lt;th>&lt;strong>DefiniciÃ³n tÃ©cnica&lt;/strong>&lt;/th>
&lt;th>&lt;strong>FunciÃ³n regulatoria&lt;/strong>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;strong>Ensayo clÃ­nico confirmatorio&lt;/strong>&lt;/td>
&lt;td>ICH E9&lt;/td>
&lt;td>Estudio con hipÃ³tesis explÃ­cita, anÃ¡lisis planificado y diseÃ±o robusto para inferencia causal.&lt;/td>
&lt;td>Fuente principal de evidencia en autorizaciones de comercializaciÃ³n.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Ensayo pivotal&lt;/strong>&lt;/td>
&lt;td>FDA, EMA&lt;/td>
&lt;td>Estudio esencial para demostrar eficacia y seguridad en el expediente regulatorio.&lt;/td>
&lt;td>Sustento central del dossier clÃ­nico.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Evidencia confirmatoria&lt;/strong>&lt;/td>
&lt;td>FDA (2023)&lt;/td>
&lt;td>Datos adicionales (clÃ­nicos/no clÃ­nicos) que refuerzan un ensayo pivotal Ãºnico.&lt;/td>
&lt;td>Permite cumplir el estÃ¡ndar de &amp;ldquo;evidencia sustancial&amp;rdquo; con un solo ECA.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Evidencia sustancial&lt;/strong>&lt;/td>
&lt;td>FDA (21 CFR 314.126)&lt;/td>
&lt;td>EstÃ¡ndar legal que puede cumplirse mediante 2 ECAs o, cuando estÃ© justificado, 1 ECA + confirmaciÃ³n.&lt;/td>
&lt;td>Requisito para la aprobaciÃ³n de nuevos medicamentos en EE.UU.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Evidencia complementaria&lt;/strong>&lt;/td>
&lt;td>ICH E9; EMA, FDA&lt;/td>
&lt;td>Estudios no pivotal que aportan consistencia (ej. subgrupos, dosis, seguridad, datos externos).&lt;/td>
&lt;td>Reforzar la plausibilidad de los hallazgos principales.&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;hr>
&lt;h1 id="estructura-metodolÃ³gica-de-los-ecas-y-su-anclaje-normativo">Estructura metodolÃ³gica de los ECAs y su anclaje normativo&lt;/h1>
&lt;p>Los ECAs incorporan tres garantÃ­as fundamentales: &lt;strong>aleatorizaciÃ³n&lt;/strong>, &lt;strong>grupo control&lt;/strong> y &lt;strong>cegamiento&lt;/strong>. Estos componentes son esenciales para maximizar la validez interna y minimizar fuentes de sesgo sistemÃ¡tico.&lt;/p>
&lt;h2 id="tabla-2-garantÃ­as-anti-sesgo-en-ecas">Tabla 2. GarantÃ­as anti-sesgo en ECAs&lt;/h2>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;strong>Componente metodolÃ³gico&lt;/strong>&lt;/th>
&lt;th>&lt;strong>FunciÃ³n especÃ­fica&lt;/strong>&lt;/th>
&lt;th>&lt;strong>CÃ³mo reduce el sesgo&lt;/strong>&lt;/th>
&lt;th>&lt;strong>Referencia normativa ICH&lt;/strong>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;strong>AleatorizaciÃ³n&lt;/strong>&lt;/td>
&lt;td>AsignaciÃ³n no predecible de tratamientos&lt;/td>
&lt;td>Mitiga el sesgo de selecciÃ³n; equilibra factores conocidos/desconocidos&lt;/td>
&lt;td>ICH E9 SecciÃ³n 2.2.3&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Grupo control&lt;/strong>&lt;/td>
&lt;td>ComparaciÃ³n con placebo o tratamiento estÃ¡ndar&lt;/td>
&lt;td>Permite contrafactual vÃ¡lido e inferencia causal robusta&lt;/td>
&lt;td>ICH E10; ICH E8(R1)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Cegamiento (blinding)&lt;/strong>&lt;/td>
&lt;td>Ocultamiento de asignaciÃ³n a participantes e investigadores&lt;/td>
&lt;td>Previene sesgo de evaluaciÃ³n, expectativa y cointervenciÃ³n&lt;/td>
&lt;td>ICH E9 SecciÃ³n 2.2.4&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;hr>
&lt;h1 id="contextos-que-permiten-prescindir-de-ecas">Contextos que permiten prescindir de ECAs&lt;/h1>
&lt;p>La omisiÃ³n de ECAs solo es aceptable en contextos claramente delimitados por justificaciones Ã©ticas, cientÃ­ficas o logÃ­sticas:&lt;/p>
&lt;ol>
&lt;li>&lt;strong>Enfermedades raras o ultrarraras&lt;/strong>, con poblaciones muy limitadas.&lt;/li>
&lt;li>&lt;strong>Situaciones de emergencia sanitaria&lt;/strong>, con necesidades clÃ­nicas urgentes.&lt;/li>
&lt;li>Cuando la &lt;strong>aleatorizaciÃ³n o el cegamiento son Ã©ticamente problemÃ¡ticos&lt;/strong>.&lt;/li>
&lt;li>Cuando existen &lt;strong>datos histÃ³ricos o reales bien estructurados y validados&lt;/strong>.&lt;/li>
&lt;/ol>
&lt;p>La aceptaciÃ³n de estos diseÃ±os como base regulatoria &lt;strong>requiere validaciÃ³n metodolÃ³gica especÃ­fica y evaluaciÃ³n caso por caso&lt;/strong>, segÃºn guÃ­as EMA y FDA.&lt;/p>
&lt;hr>
&lt;h1 id="diseÃ±os-alternativos-mÃ¡s-empleados-y-criterios-de-validaciÃ³n">DiseÃ±os alternativos mÃ¡s empleados y criterios de validaciÃ³n&lt;/h1>
&lt;h2 id="tabla-3-diseÃ±os-alternativos-justificaciÃ³n-limitaciones-y-requisitos-regulatorios">Tabla 3. DiseÃ±os alternativos: justificaciÃ³n, limitaciones y requisitos regulatorios&lt;/h2>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;strong>DiseÃ±o alternativo&lt;/strong>&lt;/th>
&lt;th>&lt;strong>JustificaciÃ³n de uso&lt;/strong>&lt;/th>
&lt;th>&lt;strong>Limitaciones crÃ­ticas&lt;/strong>&lt;/th>
&lt;th>&lt;strong>Requisitos de validaciÃ³n&lt;/strong>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;strong>Single-Arm Trials (SAT)&lt;/strong>&lt;/td>
&lt;td>Enfermedades raras; oncologÃ­a sin comparador disponible&lt;/td>
&lt;td>Ausencia de grupo control; alta vulnerabilidad a sesgo de selecciÃ³n&lt;/td>
&lt;td>Control externo robusto; endpoints validados; anÃ¡lisis de consistencia&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Controles externos/sintÃ©ticos&lt;/strong>&lt;/td>
&lt;td>Cohortes histÃ³ricas o datos de mundo real&lt;/td>
&lt;td>Riesgo de confusiÃ³n residual y sesgo de canalizaciÃ³n&lt;/td>
&lt;td>Propensity score matching; alineaciÃ³n temporal; CHMP/4366/2020 (EMA)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>DiseÃ±os adaptativos&lt;/strong>&lt;/td>
&lt;td>Eficiencia en reclutamiento; ajustes preplanificados&lt;/td>
&lt;td>Riesgo de error tipo I si no se prespecifican adecuadamente&lt;/td>
&lt;td>Control de multiplicidad; simulaciÃ³n previa; ICH E9(R1)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Real-World Evidence (RWE)&lt;/strong>&lt;/td>
&lt;td>Acceso a datos de rutina clÃ­nica; seguimiento largo; baja carga Ã©tica&lt;/td>
&lt;td>Falta de aleatorizaciÃ³n; sesgo de confusiÃ³n no medido&lt;/td>
&lt;td>PROACE principles (FDA 2023); data provenance; calidad del DMR; plan de anÃ¡lisis riguroso&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;hr>
&lt;h1 id="riesgos-del-uso-estratÃ©gico-de-diseÃ±os-no-confirmatorios">Riesgos del uso estratÃ©gico de diseÃ±os no confirmatorios&lt;/h1>
&lt;p>Aunque vÃ¡lidos en contextos excepcionales, el uso frecuente y estratÃ©gico de estos diseÃ±os plantea &lt;strong>serios desafÃ­os regulatorios&lt;/strong>, especialmente si se recurre a ellos como vÃ­a para &lt;strong>prescindir de ECAs sin justificaciÃ³n metodolÃ³gica sÃ³lida&lt;/strong>.&lt;/p>
&lt;h3 id="riesgos-identificados">Riesgos identificados:&lt;/h3>
&lt;ul>
&lt;li>Aprobaciones basadas en &lt;strong>evidencia dÃ©bil o no reproducible&lt;/strong>.&lt;/li>
&lt;li>Incremento del &lt;strong>sesgo sistemÃ¡tico&lt;/strong> en resultados de eficacia.&lt;/li>
&lt;li>ExposiciÃ³n de pacientes a intervenciones &lt;strong>no validadas rigurosamente&lt;/strong>.&lt;/li>
&lt;li>&lt;strong>DeslegitimaciÃ³n del proceso regulatorio&lt;/strong> ante la comunidad cientÃ­fica y la sociedad.&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="recomendaciones-regulatorias">Recomendaciones regulatorias&lt;/h1>
&lt;h2 id="a-para-la-industria">A. Para la industria&lt;/h2>
&lt;ul>
&lt;li>Presentar &lt;strong>justificaciÃ³n exhaustiva&lt;/strong> cuando no se utilicen ECAs.&lt;/li>
&lt;li>Cumplir con requisitos metodolÃ³gicos especÃ­ficos segÃºn tipo de diseÃ±o alternativo.&lt;/li>
&lt;li>Incluir anÃ¡lisis de sensibilidad, consistencia y control de sesgo.&lt;/li>
&lt;/ul>
&lt;h2 id="b-para-las-agencias-reguladoras">B. Para las agencias reguladoras&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>Reforzar guÃ­as especÃ­ficas&lt;/strong> (EMA, FDA) que regulen el uso de diseÃ±os alternativos.&lt;/li>
&lt;li>Exigir &lt;strong>registro pÃºblico&lt;/strong>, transparencia y acceso a protocolos completos.&lt;/li>
&lt;li>Fortalecer &lt;strong>capacidades internas&lt;/strong> en estadÃ­stica avanzada y diseÃ±o de estudios no aleatorizados.&lt;/li>
&lt;li>Establecer &lt;strong>comitÃ©s independientes&lt;/strong> de evaluaciÃ³n para salvaguardas Ã©ticas y cientÃ­ficas.&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="conclusiÃ³n">ConclusiÃ³n&lt;/h1>
&lt;p>Los diseÃ±os alternativos no deben entenderse como sustitutos genÃ©ricos del ECA, sino como herramientas &lt;strong>vÃ¡lidas solo bajo condiciones estrictamente justificadas y validadas&lt;/strong>. El regulador tiene la responsabilidad cientÃ­fica y Ã©tica de exigir evidencia que no solo sea suficiente, sino tambiÃ©n sÃ³lida, reproducible y libre de sesgos. La precisiÃ³n metodolÃ³gica y la claridad terminolÃ³gica no son un lujo en este proceso: &lt;strong>son el principio rector que protege la salud pÃºblica frente a la ambigÃ¼edad cientÃ­fica&lt;/strong>.&lt;/p>
&lt;hr>
&lt;h1 id="bibliografÃ­a">BibliografÃ­a&lt;/h1>
&lt;ol>
&lt;li>FDA. &lt;em>Demonstrating Substantial Evidence of Effectiveness with One Adequate and Well-Controlled Clinical Investigation and Confirmatory Evidence&lt;/em>. Draft Guidance. 2023.&lt;/li>
&lt;li>EMA. &lt;em>Reflection Paper on Singleâ€‘Arm Trials as Pivotal Evidence&lt;/em>. EMA/CHMP/161300/2023.&lt;/li>
&lt;li>FDA. &lt;em>Real-World Evidence Framework&lt;/em>. 2023 Update.&lt;/li>
&lt;li>EMA. &lt;em>Use of Realâ€‘World Evidence in Regulatory Decision-Making&lt;/em>. EMA/INS/GCP/455222/2024.&lt;/li>
&lt;li>ICH. &lt;em>E9: Statistical Principles for Clinical Trials&lt;/em>. 1998.&lt;/li>
&lt;li>ICH. &lt;em>E9(R1): Addendum on Estimands and Sensitivity Analysis in Clinical Trials&lt;/em>. 2020.&lt;/li>
&lt;li>EMA. &lt;em>Guideline on Adjustment for Baseline Covariates in Clinical Trials&lt;/em>. CHMP/EWP/2863/99.&lt;/li>
&lt;li>FDA. &lt;em>Real-World Evidence Program Annual Report 2025 (PUB-245)&lt;/em>.&lt;/li>
&lt;li>Temple R, Ellenberg SS. &lt;em>Placebo-Controlled Trials and Active-Control Trials in the Evaluation of New Treatments&lt;/em>. &lt;em>Ann Intern Med&lt;/em>. 2000;133(6):455â€“463.&lt;/li>
&lt;/ol></description></item><item><title>AnÃ¡lisis Exploratorio de Datos: DesentraÃ±ando la Verdad de tus Datos</title><link>https://maicel.netlify.app/post/eda/</link><pubDate>Tue, 11 Feb 2025 00:00:00 +0000</pubDate><guid>https://maicel.netlify.app/post/eda/</guid><description>&lt;p>ðŸŽ§ &lt;strong>Escucha el podcast de esta publicaciÃ³n&lt;/strong>
&lt;audio controls >
&lt;source src="https://maicel.netlify.app/mp3/eda.mp3" type="audio/mpeg">
&lt;/audio>
&lt;/p>
&lt;h1 id="introducciÃ³n">IntroducciÃ³n&lt;/h1>
&lt;p>El &lt;strong>AnÃ¡lisis Exploratorio de Datos (EDA)&lt;/strong> es una disciplina fundamental en el campo de la ciencia de datos, popularizada por el matemÃ¡tico John Tukey. MÃ¡s que una simple serie de pasos, el EDA es una filosofÃ­a que nos invita a interactuar con nuestros datos, visualizarlos, resumirlos y &amp;ldquo;hablar&amp;rdquo; con ellos antes de saltar a modelados complejos. Implica el anÃ¡lisis de datos centrado en comprender a fondo su estructura, identificar patrones ocultos, detectar anomalÃ­as (valores atÃ­picos), gestionar datos ausentes y, en Ãºltima instancia, proporcionar una base sÃ³lida para la formulaciÃ³n de modelos predictivos o inferenciales. AdemÃ¡s, es crucial para descubrir cÃ³mo se relacionan las variables entre sÃ­.&lt;/p>
&lt;h2 id="la-regla-de-oro-gigo-garbage-in-garbage-out">La Regla de Oro: GIGO (Garbage In, Garbage Out)&lt;/h2>
&lt;p>Un concepto popular y vital en el campo de la ciencia de datos es &lt;strong>GIGO&lt;/strong> (Garbage In, Garbage Out, o &amp;ldquo;Basura entra, basura sale&amp;rdquo;). Este concepto subraya que la calidad de los resultados de cualquier anÃ¡lisis o modelo es directamente proporcional a la calidad de los datos de entrada. No importa cuÃ¡n sofisticado sea tu algoritmo o cuÃ¡n potente sea tu infraestructura computacional, los datos de mala calidad siempre producirÃ¡n resultados deficientes, engaÃ±osos o inÃºtiles. El EDA es nuestra primera lÃ­nea de defensa contra el GIGO, asegurando que trabajamos con datos limpios y comprensibles.&lt;/p>
&lt;h2 id="un-flujo-de-trabajo-prÃ¡ctico-de-eda">Un Flujo de Trabajo PrÃ¡ctico de EDA&lt;/h2>
&lt;p>Aunque el EDA es un proceso iterativo y no una &amp;ldquo;camisa de fuerza&amp;rdquo; rÃ­gida, es Ãºtil seguir un flujo de trabajo estructurado para garantizar que cubrimos los aspectos mÃ¡s importantes. El orden de las etapas y el Ã©nfasis en cada una dependerÃ¡n en gran medida del problema especÃ­fico, el tipo de datos y los objetivos del anÃ¡lisis.&lt;/p>
&lt;p>Este proceso general incluye:&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="flex justify-center ">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/eda/fig01_hu_1d111632709b1b76.webp 400w,
/post/eda/fig01_hu_b26fdc398618e3dc.webp 760w,
/post/eda/fig01_hu_540748744cda905c.webp 1200w"
src="https://maicel.netlify.app/post/eda/fig01_hu_1d111632709b1b76.webp"
width="760"
height="578"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>A continuaciÃ³n, profundicemos en cada una de estas etapas, utilizando ejemplos prÃ¡cticos con el paquete &lt;code>dlookr&lt;/code> en R.&lt;/p>
&lt;h3 id="1-comprensiÃ³n-general-de-los-datos-y-evaluaciÃ³n-de-su-calidad">1. ComprensiÃ³n General de los Datos y EvaluaciÃ³n de su Calidad&lt;/h3>
&lt;p>Antes de sumergirnos en anÃ¡lisis profundos, es fundamental tener una visiÃ³n panorÃ¡mica de nuestro conjunto de datos. Esta etapa implica:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Dimensiones del dataset:&lt;/strong> Â¿CuÃ¡ntas filas (observaciones) y columnas (variables) tenemos?&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Tipos de datos:&lt;/strong> Â¿Las variables son numÃ©ricas (enteros, flotantes), categÃ³ricas (factores, caracteres), lÃ³gicas o de fecha/hora? Es crucial que los tipos de datos sean correctos para las operaciones que deseamos realizar.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>InspecciÃ³n inicial:&lt;/strong> Revisar las primeras y Ãºltimas filas del dataset para obtener una idea general del formato y contenido.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>EstadÃ­sticas descriptivas bÃ¡sicas:&lt;/strong> Para variables numÃ©ricas: media, mediana, desviaciÃ³n estÃ¡ndar, mÃ­nimo, mÃ¡ximo, cuartiles. Para variables categÃ³ricas: conteo de ocurrencias, proporciones. Esto nos da una primera impresiÃ³n de la dispersiÃ³n y centralidad de los datos.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Con &lt;code>dlookr&lt;/code>, la funciÃ³n &lt;code>diagnose()&lt;/code> es ideal para una revisiÃ³n rÃ¡pida de la calidad de los datos, mostrando el tipo de variable, el nÃºmero de valores Ãºnicos, valores faltantes, valores cero y valores negativos.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-r" data-lang="r">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Para obtener un resumen rÃ¡pido de las caracterÃ­sticas de los datos&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">diagnose&lt;/span>(mtcars_na)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Esta fase nos ayuda a formar una primera hipÃ³tesis sobre la calidad y estructura de los datos, identificando posibles problemas desde el principio.&lt;/p>
&lt;h4 id="2-identificaciÃ³n-y-tratamiento-de-valores-faltantes-y-atÃ­picos">2. IdentificaciÃ³n y Tratamiento de Valores Faltantes y AtÃ­picos&lt;/h4>
&lt;p>Los valores faltantes (NA, NaN, null) y los valores atÃ­picos (outliers) son dos de los desafÃ­os mÃ¡s comunes en cualquier conjunto de datos y pueden distorsionar significativamente los resultados de nuestros anÃ¡lisis y modelos.&lt;/p>
&lt;p>&lt;strong>Valores Faltantes:&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>IdentificaciÃ³n:&lt;/strong> Cuantificar la cantidad y proporciÃ³n de valores faltantes por variable. Visualizar patrones de ausencia (Â¿los valores faltantes ocurren aleatoriamente o hay un patrÃ³n?).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Tratamiento:&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>EliminaciÃ³n:&lt;/strong> Si la cantidad de valores faltantes es pequeÃ±a o si una variable tiene un porcentaje muy alto de NAs, se pueden eliminar filas o columnas.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>ImputaciÃ³n:&lt;/strong> Rellenar los valores faltantes. MÃ©todos comunes incluyen la media, mediana o moda (para datos numÃ©ricos y categÃ³ricos, respectivamente), o mÃ©todos mÃ¡s avanzados basados en modelos (regresiÃ³n, k-NN, etc.). La elecciÃ³n depende de la naturaleza de los datos y el problema.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Valores AtÃ­picos:&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>IdentificaciÃ³n:&lt;/strong> Observaciones que se desvÃ­an significativamente del resto de los datos. Se pueden detectar mediante grÃ¡ficos de caja (boxplots), diagramas de dispersiÃ³n, puntuaciones Z, el mÃ©todo IQR (rango intercuartÃ­lico) o algoritmos mÃ¡s sofisticados.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Tratamiento:&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>EliminaciÃ³n:&lt;/strong> Si se confirma que son errores de entrada de datos.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>TransformaciÃ³n:&lt;/strong> Aplicar transformaciones logarÃ­tmicas o de raÃ­z cuadrada para reducir su impacto.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Capping/Flooring:&lt;/strong> Limitar los valores atÃ­picos a un percentil superior o inferior (por ejemplo, el 99% o el 1%).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Mantener:&lt;/strong> A veces, los valores atÃ­picos son observaciones genuinas e importantes que no deben eliminarse.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;code>dlookr&lt;/code> ofrece funciones visuales y programÃ¡ticas para abordar estos problemas:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-r" data-lang="r">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Visualizar la distribuciÃ³n de valores faltantes&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">plot_na&lt;/span>(mtcars_na)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Identificar valores atÃ­picos para una variable especÃ­fica (ej. &amp;#34;hp&amp;#34;)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># plot_outlier() es excelente para visualizar.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">plot_outlier&lt;/span>(mtcars_df, &lt;span style="color:#e6db74">&amp;#34;hp&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="3-anÃ¡lisis-de-la-distribuciÃ³n-de-las-variables">3. AnÃ¡lisis de la DistribuciÃ³n de las Variables&lt;/h3>
&lt;p>Comprender la distribuciÃ³n de cada variable individualmente es clave para seleccionar los mÃ©todos estadÃ­sticos y de modelado adecuados.&lt;/p>
&lt;p>&lt;strong>Variables NumÃ©ricas:&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Histogramas y grÃ¡ficos de densidad:&lt;/strong> Permiten visualizar la forma de la distribuciÃ³n, identificar asimetrÃ­as (skewness), curtosis, y la presencia de mÃºltiples modos.&lt;/li>
&lt;li>&lt;strong>Medidas de asimetrÃ­a y curtosis:&lt;/strong> Cuantifican la forma de la distribuciÃ³n.&lt;/li>
&lt;li>&lt;strong>Pruebas de normalidad:&lt;/strong> Aunque muchas veces no son estrictamente necesarias, pueden complementar el anÃ¡lisis visual.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Variables CategÃ³ricas:&lt;/strong> - &lt;strong>GrÃ¡ficos de barras:&lt;/strong> Muestran la frecuencia o proporciÃ³n de cada categorÃ­a. - &lt;strong>Tablas de frecuencia:&lt;/strong> Resumen el conteo y porcentaje de cada nivel.&lt;/p>
&lt;p>&lt;code>dlookr&lt;/code> simplifica la visualizaciÃ³n de distribuciones:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-r" data-lang="r">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Visualizar la distribuciÃ³n de una variable numÃ©rica (ej. &amp;#34;mpg&amp;#34;)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">plot_hist&lt;/span>(mtcars_df, &lt;span style="color:#e6db74">&amp;#34;mpg&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># O ver la distribuciÃ³n y normalidad&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">plot_normality&lt;/span>(mtcars_df, &lt;span style="color:#e6db74">&amp;#34;mpg&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Para variables categÃ³ricas (como &amp;#39;cyl&amp;#39; en mtcars que es numÃ©rica discreta)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Podemos convertirla a factor para un anÃ¡lisis categÃ³rico.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>mtcars_factor_cyl &lt;span style="color:#f92672">&amp;lt;-&lt;/span> mtcars_df &lt;span style="color:#f92672">%&amp;gt;%&lt;/span> &lt;span style="color:#a6e22e">mutate&lt;/span>(cyl &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">as.factor&lt;/span>(cyl))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">plot_bar&lt;/span>(mtcars_factor_cyl, &lt;span style="color:#e6db74">&amp;#34;cyl&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Este anÃ¡lisis nos ayuda a entender el comportamiento de cada caracterÃ­stica y a identificar la necesidad de transformaciones futuras.&lt;/p>
&lt;h3 id="4-anÃ¡lisis-de-las-relaciones-entre-las-variables">4. AnÃ¡lisis de las Relaciones entre las Variables&lt;/h3>
&lt;p>Esta etapa se centra en descubrir cÃ³mo las variables interactÃºan entre sÃ­. Es fundamental para la selecciÃ³n de caracterÃ­sticas, la identificaciÃ³n de multicolinealidad y la comprensiÃ³n de la causalidad (o correlaciÃ³n).&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Dos variables numÃ©ricas:&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Diagramas de dispersiÃ³n (scatter plots):&lt;/strong> Visualizan la direcciÃ³n y fuerza de la relaciÃ³n (positiva, negativa, nula, no lineal).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Coeficientes de correlaciÃ³n (Pearson, Spearman):&lt;/strong> Cuantifican la fuerza y direcciÃ³n de la relaciÃ³n lineal (Pearson) o monÃ³tona (Spearman).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Una variable numÃ©rica y una categÃ³rica:&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>GrÃ¡ficos de caja (boxplots) o grÃ¡ficos de violÃ­n:&lt;/strong> Comparan la distribuciÃ³n de la variable numÃ©rica entre las diferentes categorÃ­as.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Pruebas t de Student o ANOVA:&lt;/strong> Para determinar si hay diferencias estadÃ­sticamente significativas en las medias.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Dos variables categÃ³ricas:&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Tablas de contingencia y grÃ¡ficos de barras apiladas/agrupadas:&lt;/strong> Muestran la distribuciÃ³n conjunta.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Pruebas de significaciÃ³n:&lt;/strong> Para evaluar la independencia entre las variables.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Matrices de correlaciÃ³n:&lt;/strong> Visualizan las correlaciones entre mÃºltiples variables numÃ©ricas simultÃ¡neamente, a menudo con mapas de calor (heatmaps).&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;code>dlookr&lt;/code> facilita la exploraciÃ³n de relaciones:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-r" data-lang="r">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Visualizar la matriz de correlaciÃ³n entre todas las variables numÃ©ricas&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">plot_cor&lt;/span>(mtcars_df)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Analizar la relaciÃ³n entre una variable objetivo (&amp;#39;mpg&amp;#39;) y otra caracterÃ­stica (&amp;#39;wt&amp;#39;)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># plot_eda() permite explorar diversas relaciones bivariadas.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">plot_eda&lt;/span>(mtcars_df, target &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;mpg&amp;#34;&lt;/span>, feature &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;wt&amp;#34;&lt;/span>) &lt;span style="color:#75715e"># NumÃ©rica vs NumÃ©rica (scatterplot)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># RelaciÃ³n entre &amp;#39;mpg&amp;#39; (numÃ©rica) y &amp;#39;cyl&amp;#39; (considerada categÃ³rica aquÃ­)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">plot_eda&lt;/span>(mtcars_df, target &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;mpg&amp;#34;&lt;/span>, feature &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;cyl&amp;#34;&lt;/span>) &lt;span style="color:#75715e"># NumÃ©rica vs CategÃ³rica (boxplot)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="5-transformaciÃ³n-de-los-datos">5. TransformaciÃ³n de los Datos&lt;/h3>
&lt;p>Una vez que hemos comprendido nuestros datos, es posible que necesitemos transformarlos para que sean mÃ¡s adecuados para los algoritmos de machine learning o para mejorar el rendimiento del modelo.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Manejo de asimetrÃ­a:&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Transformaciones logarÃ­tmicas, de raÃ­z cuadrada o de Box-Cox:&lt;/strong> Pueden normalizar distribuciones sesgadas, reduciendo la influencia de valores extremos.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Escalado de caracterÃ­sticas:&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>NormalizaciÃ³n (Min-Max Scaling):&lt;/strong> Escala los datos a un rango fijo (por ejemplo, [0, 1]). Ãštil para algoritmos sensibles a la escala como SVM o redes neuronales.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>EstandarizaciÃ³n (Z-score Scaling):&lt;/strong> Transforma los datos para que tengan una media de 0 y una desviaciÃ³n estÃ¡ndar de 1. Es comÃºn en algoritmos basados en distancia (k-NN, K-Means, PCA).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>CodificaciÃ³n de variables categÃ³ricas:&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>One-Hot Encoding:&lt;/strong> Convierte variables categÃ³ricas en mÃºltiples columnas binarias, una por cada categorÃ­a. Esencial para algoritmos que solo trabajan con entradas numÃ©ricas.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Label Encoding:&lt;/strong> Asigna un nÃºmero entero a cada categorÃ­a. Ãštil si hay un orden inherente en las categorÃ­as.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>IngenierÃ­a de CaracterÃ­sticas (Feature Engineering):&lt;/strong> Crear nuevas variables a partir de las existentes. Esto puede ser tan simple como combinar dos columnas o tan complejo como extraer informaciÃ³n de texto o imÃ¡genes. Esta etapa es a menudo la que mÃ¡s impacto tiene en el rendimiento del modelo.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;code>dlookr&lt;/code> ofrece funciones Ãºtiles para la transformaciÃ³n de datos:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-r" data-lang="r">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># TransformaciÃ³n logarÃ­tmica para reducir la asimetrÃ­a de una variable&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>mtcars_transformed_log &lt;span style="color:#f92672">&amp;lt;-&lt;/span> &lt;span style="color:#a6e22e">transform_df&lt;/span>(mtcars_df, mpg &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">log&lt;/span>(mpg))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Compara la distribuciÃ³n de mpg original vs. transformada&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">plot_normality&lt;/span>(mtcars_df, &lt;span style="color:#e6db74">&amp;#34;mpg&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">plot_normality&lt;/span>(mtcars_transformed_log, &lt;span style="color:#e6db74">&amp;#34;mpg&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># BinarizaciÃ³n o discretizaciÃ³n de una variable continua (ej. &amp;#39;hp&amp;#39; en 3 bins)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>mtcars_binned &lt;span style="color:#f92672">&amp;lt;-&lt;/span> &lt;span style="color:#a6e22e">binning&lt;/span>(mtcars_df, &lt;span style="color:#e6db74">&amp;#34;hp&amp;#34;&lt;/span>, n &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">3&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">head&lt;/span>(mtcars_binned &lt;span style="color:#f92672">%&amp;gt;%&lt;/span> &lt;span style="color:#a6e22e">select&lt;/span>(hp, hp_Binned))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># EstandarizaciÃ³n de variables numÃ©ricas (Z-score)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>mtcars_scaled &lt;span style="color:#f92672">&amp;lt;-&lt;/span> &lt;span style="color:#a6e22e">normalize&lt;/span>(mtcars_df, method &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;scale&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">head&lt;/span>(mtcars_scaled) &lt;span style="color:#75715e"># Observa cÃ³mo los valores de todas las columnas han cambiado&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="herramientas-populares-para-eda">Herramientas Populares para EDA&lt;/h2>
&lt;p>Para realizar un EDA efectivo, contamos con potentes herramientas en lenguajes como R y Python:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>En R:&lt;/strong>
&lt;ul>
&lt;li>El ecosistema &lt;code>tidyverse&lt;/code> (&lt;code>dplyr&lt;/code> para manipulaciÃ³n, &lt;code>ggplot2&lt;/code> para visualizaciÃ³n) es indispensable.&lt;/li>
&lt;li>Paquetes especÃ­ficos para EDA como &lt;strong>&lt;code>dlookr&lt;/code>&lt;/strong>, es excelente por su enfoque estructurado en el diagnÃ³stico de calidad, exploraciÃ³n y transformaciÃ³n de datos, ofreciendo funciones y reportes automatizados que agilizan el proceso. Otros paquetes Ãºtiles incluyen &lt;code>DataExplorer&lt;/code>, &lt;code>skimr&lt;/code>, y &lt;code>visdat&lt;/code>.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>En Python:&lt;/strong>
&lt;ul>
&lt;li>&lt;code>pandas&lt;/code> para manipulaciÃ³n de datos.&lt;/li>
&lt;li>&lt;code>matplotlib&lt;/code> y &lt;code>seaborn&lt;/code> para visualizaciÃ³n estÃ¡tica.&lt;/li>
&lt;li>&lt;code>plotly&lt;/code> para visualizaciones interactivas.&lt;/li>
&lt;li>Bibliotecas como &lt;code>missingno&lt;/code> para visualizar valores faltantes, &lt;code>pandas_profiling&lt;/code> para informes automÃ¡ticos de EDA, y &lt;code>sweetviz&lt;/code> para comparaciones.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="conclusiÃ³n">ConclusiÃ³n&lt;/h2>
&lt;p>El AnÃ¡lisis Exploratorio de Datos no es solo una fase inicial, sino un proceso continuo de aprendizaje sobre tus datos. Es una inversiÃ³n de tiempo que rinde grandes dividendos, ya que una comprensiÃ³n profunda de los datos nos permite tomar decisiones mÃ¡s informadas, construir modelos mÃ¡s robustos y, en Ãºltima instancia, extraer conocimientos mÃ¡s valiosos. Al dominar el EDA, te equipas con la habilidad de transformar datos brutos en una historia coherente y accionable, evitando la trampa del GIGO y asegurando que tus esfuerzos de ciencia de datos generen un impacto real.&lt;/p></description></item><item><title>CÃ³mo entrenar y validar un modelo de predicciÃ³n clÃ­nica</title><link>https://maicel.netlify.app/post/como-entrenar-y-validar-modelo-prediccion-clinica/</link><pubDate>Thu, 08 Feb 2024 00:00:00 +0000</pubDate><guid>https://maicel.netlify.app/post/como-entrenar-y-validar-modelo-prediccion-clinica/</guid><description>&lt;p>Si usted es Investigador en Salud o, peor aÃºn, estudiante de posgrado, maestrÃ­a o doctorado en el campo de las ciencias biomÃ©dicas&amp;hellip; &lt;strong>Â¡bienvenido al club del estrÃ©s!&lt;/strong>&lt;/p>
&lt;p>Seguro que usted estÃ¡ enfocado en desarrollar esos geniales &lt;strong>modelos de predicciÃ³n clÃ­nica&lt;/strong> para el &lt;strong>diagnÃ³stico&lt;/strong> o el &lt;strong>pronÃ³stico&lt;/strong>. Y es casi seguro que ha llegado a esa fase donde la metodologÃ­a se siente como un muro de ladrillos. Un dÃ­a estÃ¡s bien, y al siguiente te das cuenta de que no sabes quÃ© pasos seguir, quÃ© software usar, o lo peor: si tu modelo servirÃ¡ para algo mÃ¡s allÃ¡ de llenar un repositorio de tesis.&lt;/p>
&lt;p>Lo digo sin tapujos: esa frase lapidaria de &lt;strong>&amp;lsquo;Ese valor tan alto de la Curva Roc y la ausencia de mÃ©tricas de calibraciÃ³n&amp;rsquo;&lt;/strong> puede significar que tu modelo tiene el famoso &lt;strong>sÃ­ndrome del &amp;ldquo;sobreajuste&amp;rdquo;&lt;/strong>. En otras palabras, funciona espectacularmente bien&amp;hellip; solo para la muestra que lo creÃ³.&lt;/p>
&lt;p>Es una locura, Â¿verdad? Mientras las tesis de alto nivel giran en torno a crear estos modelos de predicciÃ³n clÃ­nica, los cursos de BioestadÃ­stica (Â¡incluida la especialidad!) pasan de puntillas por el tema. Hay una brecha gigantesca, y la ansiedad de tener que aprenderlo todo YA es real. Pero respira. Este post es tu chaleco salvavidas: tu Traductor MetodolÃ³gico no oficial y (casi) libre de lÃ¡grimas. Yo mismo pasÃ© por ese infierno metodolÃ³gico en mi tesis de doctorado, asÃ­ que no solo doy consejos: comparto la experiencia de quien ya quemÃ³ sus pestaÃ±as por ti.&lt;/p>
&lt;p>Olvida el cÃ³digo complejo y enrevesado. AquÃ­ nos enfocamos en la lÃ³gica esencial para construir un modelo predictivo robusto y fiable. Desglosaremos el proceso paso a paso, quitÃ¡ndole el miedo a la estadÃ­stica con un &lt;strong>CÃ³digo PrÃ¡ctico en R&lt;/strong>. Empezaremos con la &lt;strong>Estrategia de Modelado&lt;/strong>; el cÃ³digo vendrÃ¡ despuÃ©s. &lt;strong>Â¡Empecemos!&lt;/strong>&lt;/p>
&lt;h1 id="estrategia-de-modelado">Estrategia de modelado&lt;/h1>
&lt;p>Contar con una estrategia de modelado adecuada es esencial para desarrollar y validar modelos de predicciÃ³n. En este artÃ­culo exploraremos las siete etapas clave propuestas por Ewout Steyerberg en su trabajo (1).&lt;/p>
&lt;h2 id="1-definiciÃ³n-del-problema-e-inspecciÃ³n-de-datos">1. DefiniciÃ³n del problema e inspecciÃ³n de datos&lt;/h2>
&lt;p>El primer paso en cualquier proyecto de modelado es &lt;strong>definir claramente el problema de investigaciÃ³n&lt;/strong> y seleccionar la &lt;strong>variable de resultado&lt;/strong> adecuada.&lt;/p>
&lt;div class="flex px-4 py-3 mb-6 rounded-md bg-primary-100 dark:bg-primary-900">
&lt;span class="pr-3 pt-1 text-primary-600 dark:text-primary-300">
&lt;svg height="24" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">&lt;path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z"/>&lt;/svg>
&lt;/span>
&lt;span class="dark:text-neutral-300">La &lt;strong>variable de resultado&lt;/strong> debe definirse con precisiÃ³n: especifica &lt;strong>quÃ© evento se predice&lt;/strong>, &lt;strong>cÃ³mo y cuÃ¡ndo se mide&lt;/strong>, y el &lt;strong>horizonte temporal de predicciÃ³n&lt;/strong> (por ejemplo, mortalidad a 30 dÃ­as). Indica ademÃ¡s el mÃ©todo de evaluaciÃ³n y si hubo &lt;strong>cegamiento&lt;/strong> respecto a los predictores, para garantizar coherencia y validez del modelo.&lt;/span>
&lt;/div>
&lt;p>Durante esta fase, tambiÃ©n realizamos un anÃ¡lisis exploratorio de datos (EDA) para comprender las caracterÃ­sticas de las variables y detectar posibles problemas, como &lt;strong>datos atÃ­picos&lt;/strong> o &lt;strong>valores faltantes&lt;/strong>.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-r" data-lang="r">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># bibliotecas&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">library&lt;/span>(rms) &lt;span style="color:#75715e"># El alma de la metodologÃ­a &lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">library&lt;/span>(pROC) &lt;span style="color:#75715e"># ROC confiable&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">library&lt;/span>(ggplot2)&lt;span style="color:#75715e"># GrÃ¡ficos publicaciÃ³n&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">library&lt;/span>(missRanger)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">library&lt;/span>(mlbench)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">library&lt;/span>(dplyr)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">library&lt;/span>(conflicted)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">set.seed&lt;/span>(&lt;span style="color:#ae81ff">123&lt;/span>) &lt;span style="color:#75715e"># para reproducibilidad&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># DATOS: &lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">data&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;PimaIndiansDiabetes&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>datos &lt;span style="color:#f92672">&amp;lt;-&lt;/span> PimaIndiansDiabetes
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># predictores&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>vars_clinicas &lt;span style="color:#f92672">&amp;lt;-&lt;/span> &lt;span style="color:#a6e22e">c&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;glucose&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;pressure&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;triceps&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;insulin&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;mass&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># PASO CRÃTICO: Transformacion de datos&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>datos &lt;span style="color:#f92672">&amp;lt;-&lt;/span> datos &lt;span style="color:#f92672">%&amp;gt;%&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Reemplaza 0 por NA solo en las columnas especificadas en vars_clinicas&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">mutate&lt;/span>(&lt;span style="color:#a6e22e">across&lt;/span>(&lt;span style="color:#a6e22e">all_of&lt;/span>(vars_clinicas), &lt;span style="color:#f92672">~&lt;/span> &lt;span style="color:#a6e22e">ifelse&lt;/span>(.x &lt;span style="color:#f92672">==&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#66d9ef">NA&lt;/span>, .x))) &lt;span style="color:#f92672">%&amp;gt;%&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Luego aplica missRanger al dataset completo (o se puede focalizar si se desea)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">missRanger&lt;/span>()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># CONFIGURACIÃ“N RMS (NO OMITIR)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>dd &lt;span style="color:#f92672">&amp;lt;-&lt;/span> &lt;span style="color:#a6e22e">datadist&lt;/span>(datos)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">options&lt;/span>(datadist &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;dd&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="2-codificaciÃ³n-de-las-variables-predictoras">2. CodificaciÃ³n de las variables predictoras&lt;/h2>
&lt;p>La &lt;strong>codificaciÃ³n&lt;/strong> adecuada de las &lt;strong>variables predictoras&lt;/strong> es fundamental para construir modelos robustos.&lt;/p>
&lt;p>Es probable que debas utilizar tÃ©cnicas como la agrupaciÃ³n de categorÃ­as poco frecuentes y la creaciÃ³n de predictores resÃºmenes para simplificar informaciÃ³n correlacionada. Si el algoritmo seleccionado es la &lt;strong>regresiÃ³n logÃ­stica&lt;/strong>, es posible que le haga falta aplicar tÃ©cnicas como los &lt;strong>splines cÃºbicos restringidos&lt;/strong> para relajar el supuesto de linealidad entre la variable dependiente y el resultado.&lt;/p>
&lt;div class="flex px-4 py-3 mb-6 rounded-md bg-primary-100 dark:bg-primary-900">
&lt;span class="pr-3 pt-1 text-primary-600 dark:text-primary-300">
&lt;svg height="24" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">&lt;path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z"/>&lt;/svg>
&lt;/span>
&lt;span class="dark:text-neutral-300">Cada variable predictora debe definirse con su mÃ©todo de mediciÃ³n y momento. Las variables continuas deben reportarse con sus unidades; si se categorizan, debe justificarse los puntos de corte. Las variables categÃ³ricas deben listar todas sus categorÃ­as y especificar la categorÃ­a de referencia. El modelo final debe presentar la codificaciÃ³n completa utilizada para cada predictor.&lt;/span>
&lt;/div>
&lt;p>ðŸ’¡ &lt;strong>Tip:&lt;/strong> Dicotomizar predictores cuantitativos (por ejemplo, transformar una variable continua como la edad o la presiÃ³n arterial en una variable binaria, como â€œâ‰¥65 aÃ±os = 1â€ y â€œ&amp;lt;65 = 0â€) es considerada una mala prÃ¡ctica metodolÃ³gica por pÃ©rdida de informaciÃ³n, menos poder estadÃ­stico, puntos de corte arbitrarios y riesgo de sobreajuste.&lt;/p>
&lt;h2 id="3-especificaciÃ³n-del-tipo-de-modelo">3 .EspecificaciÃ³n del tipo de modelo&lt;/h2>
&lt;p>En esta etapa se define la estructura formal del modelo, lo que incluye el tipo de relaciÃ³n entre variables (p. ej., lineal, no lineal) y, de manera crucial, la selecciÃ³n de los predictores finales que lo integrarÃ¡n.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="flex justify-center ">
&lt;div class="w-100" >&lt;img alt="" srcset="
/post/como-entrenar-y-validar-modelo-prediccion-clinica/modelos_elecion_hu_8c0e0341cce17729.webp 400w,
/post/como-entrenar-y-validar-modelo-prediccion-clinica/modelos_elecion_hu_7b91ac5dc10d2f43.webp 760w,
/post/como-entrenar-y-validar-modelo-prediccion-clinica/modelos_elecion_hu_e3e07ff54d991fd6.webp 1200w"
src="https://maicel.netlify.app/post/como-entrenar-y-validar-modelo-prediccion-clinica/modelos_elecion_hu_8c0e0341cce17729.webp"
width="760"
height="507"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>La elecciÃ³n de predictores no debe basarse en la aplicaciÃ³n mecÃ¡nica de mÃ©todos algorÃ­tmicos como la &lt;strong>RegresiÃ³n Paso a Paso (RPP)&lt;/strong>, ya que suelen producir modelos inestables y sobreajustados, especialmente en contextos biomÃ©dicos y sociales. En su lugar, se recomienda:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Priorizar el &lt;strong>juicio clÃ­nico, la revisiÃ³n sistemÃ¡tica de la literatura y la experiencia previa.&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Evitar la preselecciÃ³n de variables basada Ãºnicamente en valores &lt;em>p&lt;/em> de anÃ¡lisis bivariados.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Optar por un conjunto reducido de predictores clÃ­nicamente relevantes definidos a priori, o incluir todos los candidatos en el modelo multivariable inicial sin filtrado estadÃ­stico previo.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="4-estimaciÃ³n-del-modelo">4. EstimaciÃ³n del Modelo&lt;/h2>
&lt;p>Una vez especificado el modelo (es decir, definidos los predictores y la estructura funcional), el paso de estimaciÃ³n tiene como objetivo calcular los coeficientes o parÃ¡metros que mejor se ajusten a los datos de entrenamiento.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-r" data-lang="r">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">#MODELO: PREDICTORES POR FISIOPATOLOGÃA, NO p-valores&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>modelo &lt;span style="color:#f92672">&amp;lt;-&lt;/span> &lt;span style="color:#a6e22e">lrm&lt;/span>(diabetes &lt;span style="color:#f92672">~&lt;/span> &lt;span style="color:#a6e22e">rcs&lt;/span>(glucose, &lt;span style="color:#ae81ff">3&lt;/span>) &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">rcs&lt;/span>(mass, &lt;span style="color:#ae81ff">3&lt;/span>) &lt;span style="color:#f92672">+&lt;/span> age &lt;span style="color:#f92672">+&lt;/span> pregnant &lt;span style="color:#f92672">+&lt;/span> pedigree,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> data &lt;span style="color:#f92672">=&lt;/span> datos,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> x &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">TRUE&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> y &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">TRUE&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>En modelos de regresiÃ³n, esto implica tÃ­picamente el uso de mÃ©todos como la &lt;strong>mÃ¡xima verosimilitud&lt;/strong>. Sin embargo, cuando el nÃºmero de eventos es limitado o el de predictores es alto, el riesgo de sobreajuste es elevado, lo que genera predicciones extremas y poco generalizables. Para mitigarlo, se emplean tÃ©cnicas de &lt;strong>regularizaciÃ³n, penalizaciÃ³n o shrinkage&lt;/strong>, que ajustan los coeficientes hacia cero para mejorar la estabilidad y la calibraciÃ³n en nuevas poblaciones.&lt;/p>
&lt;p>El objetivo final no es maximizar el rendimiento aparente en la muestra de desarrollo, sino obtener un modelo con &lt;strong>predicciones estables, bien calibradas y clÃ­nicamente Ãºtiles&lt;/strong>.&lt;/p>
&lt;div class="flex px-4 py-3 mb-6 rounded-md bg-primary-100 dark:bg-primary-900">
&lt;span class="pr-3 pt-1 text-primary-600 dark:text-primary-300">
&lt;svg height="24" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">&lt;path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z"/>&lt;/svg>
&lt;/span>
&lt;span class="dark:text-neutral-300">Es recomendable aplicar siempre una validaciÃ³n interna (como bootstrapping o cross-validation) para cuantificar y corregir el optimismo en las mÃ©tricas de rendimiento. La ecuaciÃ³n final del modelo debe presentarse de forma completa â€”incluyendo todos los coeficientes, el intercepto y, si corresponde, la supervivencia basalâ€”, reportando mÃ©tricas de calibraciÃ³n y discriminaciÃ³n con sus intervalos de confianza.&lt;/span>
&lt;/div>
&lt;h2 id="5-evaluaciÃ³n-del-rendimiento-del-modelo">5. EvaluaciÃ³n del Rendimiento del Modelo&lt;/h2>
&lt;p>Una vez desarrollado el modelo, es esencial cuantificar su capacidad predictiva antes de su validaciÃ³n. Esta evaluaciÃ³n se centra en tres aspectos clave:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>CalibraciÃ³n:&lt;/strong> Mide la concordancia entre las probabilidades predichas y las observadas. Por ejemplo, Â¿un 10% de riesgo predicho se corresponde con un 10% de eventos observados? Se evalÃºa visualmente con curvas de calibraciÃ³n y cuantitativamente con parÃ¡metros como el intercepto (A, calibraciÃ³n-in-the-large) y la pendiente de calibraciÃ³n (B).&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-r" data-lang="r">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># calibrate(): Bootstrap para evaluar y corregir la calibraciÃ³n&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>cal_boot &lt;span style="color:#f92672">&amp;lt;-&lt;/span> &lt;span style="color:#a6e22e">calibrate&lt;/span>(modelo, method &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;boot&amp;#34;&lt;/span>, B &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">200&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># GRÃFICOS DE SUPERVIVENCIA &lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">plot&lt;/span>(cal_boot, main &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;Probabilidasde predichas vs observadas&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">abline&lt;/span>(&lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, lty &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">2&lt;/span>, col &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;red&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;img src="https://maicel.netlify.app/post/como-entrenar-y-validar-modelo-prediccion-clinica/index_files/figure-html/calibracion-1.png" width="672" style="display: block; margin: auto;" />
&lt;ul>
&lt;li>&lt;strong>DiscriminaciÃ³n:&lt;/strong> EvalÃºa la capacidad del modelo para distinguir entre pacientes que experimentan el evento y aquellos que no. La mÃ©trica mÃ¡s comÃºn es el estadÃ­stico C (o AUC-ROC), que representa la probabilidad de que un paciente con el evento tenga una puntuaciÃ³n de riesgo mÃ¡s alta que uno sin Ã©l.&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-r" data-lang="r">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># validate(): Bootstrap para estimar el optimismo y corregir mÃ©tricas de discriminaciÃ³n&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>val_boot &lt;span style="color:#f92672">&amp;lt;-&lt;/span> &lt;span style="color:#a6e22e">validate&lt;/span>(modelo, method &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;boot&amp;#34;&lt;/span>, B &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">200&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>roc_obj &lt;span style="color:#f92672">&amp;lt;-&lt;/span> &lt;span style="color:#a6e22e">roc&lt;/span>(datos&lt;span style="color:#f92672">$&lt;/span>diabetes, &lt;span style="color:#a6e22e">predict&lt;/span>(modelo, type &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;fitted&amp;#34;&lt;/span>))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">plot&lt;/span>(roc_obj,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> main &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">paste&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;AUC =&amp;#34;&lt;/span>, &lt;span style="color:#a6e22e">round&lt;/span>(&lt;span style="color:#a6e22e">auc&lt;/span>(roc_obj), &lt;span style="color:#ae81ff">3&lt;/span>)),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> col &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;blue&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> legacy.axes &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">TRUE&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;img src="https://maicel.netlify.app/post/como-entrenar-y-validar-modelo-prediccion-clinica/index_files/figure-html/discriminacion-1.png" width="672" style="display: block; margin: auto;" />
&lt;ul>
&lt;li>&lt;strong>Utilidad ClÃ­nica:&lt;/strong> Determina si el modelo es Ãºtil para la toma de decisiones. El anÃ¡lisis de curvas de decisiÃ³n y el Beneficio Neto (NB) permiten evaluar si el uso del modelo conduce a mejores resultados clÃ­nicos netos en comparaciÃ³n con estrategias alternativas (como tratar a todos o a ninguno).&lt;/li>
&lt;/ul>
&lt;h2 id="6-evaluaciÃ³n-de-la-validez-del-modelo">6. EvaluaciÃ³n de la Validez del Modelo&lt;/h2>
&lt;p>La evaluaciÃ³n del rendimiento en los datos de desarrollo suele ser optimista. Por ello, es crucial evaluar la validez del modelo en datos no utilizados para su construcciÃ³n, un proceso que se divide en:&lt;/p>
&lt;p>&lt;strong>ValidaciÃ³n Interna:&lt;/strong> EvalÃºa la reproducibilidad del modelo, es decir, su rendimiento en mÃºltiples muestras de la misma poblaciÃ³n subyacente. TÃ©cnicas como el bootstrapping o la validaciÃ³n cruzada son superiores a la divisiÃ³n simple de la muestra, ya que cuantifican y corrigen el optimismo en las mÃ©tricas de rendimiento sin reducir el tamaÃ±o de la muestra de desarrollo.&lt;/p>
&lt;p>&lt;strong>ValidaciÃ³n Externa:&lt;/strong> Es la prueba definitiva de la generalizabilidad o transportabilidad del modelo. Consiste en aplicar el modelo a una poblaciÃ³n completamente independiente, lo que puede incluir:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>ValidaciÃ³n Temporal:&lt;/strong> Usar pacientes reclutados en un perÃ­odo posterior.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>ValidaciÃ³n GeogrÃ¡fica:&lt;/strong> Aplicar el modelo en pacientes de otros centros u hospitales.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>ValidaciÃ³n Fuerte:&lt;/strong> Probar el modelo en un entorno clÃ­nico o una poblaciÃ³n con caracterÃ­sticas diferentes a las originales.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Este paso es fundamental para confirmar que el modelo mantiene su calibraciÃ³n, discriminaciÃ³n y utilidad clÃ­nica en la prÃ¡ctica real.&lt;/p>
&lt;h2 id="7-presentaciÃ³n-del-modelo">7. PresentaciÃ³n del modelo&lt;/h2>
&lt;p>La presentaciÃ³n efectiva es crucial para la adopciÃ³n clÃ­nica. Un modelo perfecto es inÃºtil si los mÃ©dicos no pueden interpretarlo fÃ¡cilmente. Considera:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Nomogramas&lt;/strong>: Ideales para uso rÃ¡pido en consulta&lt;/li>
&lt;li>&lt;strong>Aplicaciones web/mÃ³viles&lt;/strong>: Para integraciÃ³n en flujos de trabajo clÃ­nicos&lt;/li>
&lt;li>&lt;strong>Puntuaciones de riesgo&lt;/strong>: Simplificadas para triaje rÃ¡pido&lt;/li>
&lt;li>&lt;strong>DocumentaciÃ³n clara&lt;/strong>: Incluyendo limitaciones y casos de uso&lt;/li>
&lt;/ul>
&lt;p>Recuerda: la transparencia en la presentaciÃ³n favorece la confianza clÃ­nica.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-r" data-lang="r">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># NOMOGRAMA: EL TEST DE USABILIDAD CLÃNICA &lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>nom &lt;span style="color:#f92672">&amp;lt;-&lt;/span> &lt;span style="color:#a6e22e">nomogram&lt;/span>(modelo, fun &lt;span style="color:#f92672">=&lt;/span> plogis, funlabel &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;Riesgo Diabetes&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">plot&lt;/span>(nom)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;img src="https://maicel.netlify.app/post/como-entrenar-y-validar-modelo-prediccion-clinica/index_files/figure-html/prersentacion-1.png" width="672" style="display: block; margin: auto;" />
&lt;!-- ## ðŸ› ï¸ EL KIT DE SUPERVIVENCIA (Tu Script) -->
&lt;!-- [Descarga el script completo] -->
&lt;p>Â¿Has aplicado estas tÃ©cnicas en tus proyectos de Machine Learning? Â¿QuÃ© estrategias usas para entrenar y validar tus modelos? DÃ©jame tus comentarios ðŸ’¬: comparte tus experiencias, dificultades o tips contigo. Â¡Juntos podemos enriquecer este conocimiento!&lt;/p>
&lt;h1 id="bibliografÃ­a">BibliografÃ­a&lt;/h1>
&lt;ol>
&lt;li>Steyerberg EW, Vergouwe Y. Towards better clinical prediction models: seven steps for development and an ABCD for validation. European Heart Journal [Internet]. 1 de agosto de 2014 [citado 9 de mayo de 2021];35(29):1925-31. Disponible en: &lt;a href="https://academic.oup.com/eurheartj/article-lookup/doi/10.1093/eurheartj/ehu207" target="_blank" rel="noopener">https://academic.oup.com/eurheartj/article-lookup/doi/10.1093/eurheartj/ehu207&lt;/a>&lt;/li>
&lt;/ol></description></item></channel></rss>