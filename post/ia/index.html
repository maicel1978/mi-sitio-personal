<!doctype html><html lang=es-es dir=ltr data-wc-theme-default=system><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=generator content="Hugo Blox Builder 0.3.1"><meta name=author content="Maicel"><meta name=description content="Todos conocemos los Modelos de Lenguaje Grandes (LLMs) como ChatGPT de OpenAI, Claude de Anthropic, Gemini de Google y otros modelos similares.
Son esos asistentes de IA con los que conversamos, que nos ayudan a escribir correos (Stanford Online 2024)electr√≥nicos, a generar ideas e incluso a codificar.
"><link rel=alternate hreflang=es-es href=https://maicel.netlify.app/post/ia/><link rel=stylesheet href=/css/themes/sky.min.css><link href=/dist/wc.min.40d365a5c94bd94585e708f7c92e5782e00a8d8eefc348f5d2f21a80bb7783c8.css rel=stylesheet><script>window.hbb={defaultTheme:document.documentElement.dataset.wcThemeDefault,setDarkTheme:()=>{document.documentElement.classList.add("dark"),document.documentElement.style.colorScheme="dark"},setLightTheme:()=>{document.documentElement.classList.remove("dark"),document.documentElement.style.colorScheme="light"}},console.debug(`Default Hugo Blox Builder theme is ${window.hbb.defaultTheme}`),"wc-color-theme"in localStorage?localStorage.getItem("wc-color-theme")==="dark"?window.hbb.setDarkTheme():window.hbb.setLightTheme():(window.hbb.defaultTheme==="dark"?window.hbb.setDarkTheme():window.hbb.setLightTheme(),window.hbb.defaultTheme==="system"&&(window.matchMedia("(prefers-color-scheme: dark)").matches?window.hbb.setDarkTheme():window.hbb.setLightTheme()))</script><script>document.addEventListener("DOMContentLoaded",function(){let e=document.querySelectorAll("li input[type='checkbox'][disabled]");e.forEach(e=>{e.parentElement.parentElement.classList.add("task-list")});const t=document.querySelectorAll(".task-list li");t.forEach(e=>{let t=Array.from(e.childNodes).filter(e=>e.nodeType===3&&e.textContent.trim().length>1);if(t.length>0){const n=document.createElement("label");t[0].after(n),n.appendChild(e.querySelector("input[type='checkbox']")),n.appendChild(t[0])}})})</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-VN0YPKYGX4"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}function trackOutboundLink(e,t){gtag("event","click",{event_category:"outbound",event_label:e,transport_type:"beacon",event_callback:function(){t!=="_blank"&&(document.location=e)}}),console.debug("Outbound link clicked: "+e)}function onClickCallback(e){if(e.target.tagName!=="A"||e.target.host===window.location.host)return;trackOutboundLink(e.target,e.target.getAttribute("target"))}gtag("js",new Date),gtag("config","G-VN0YPKYGX4",{}),gtag("set",{cookie_flags:"SameSite=None;Secure"}),document.addEventListener("click",onClickCallback,!1)</script><link rel=icon type=image/png href=/media/icon_hu_b45ae4411cf43192.png><link rel=apple-touch-icon type=image/png href=/media/icon_hu_1f7e870b5f23a0ce.png><link rel=canonical href=https://maicel.netlify.app/post/ia/><meta property="twitter:card" content="summary_large_image"><meta property="twitter:site" content="@GetResearchDev"><meta property="twitter:creator" content="@GetResearchDev"><meta property="og:site_name" content="Bioestad√≠stica edu"><meta property="og:url" content="https://maicel.netlify.app/post/ia/"><meta property="og:title" content="Una Inmersi√≥n Intuitiva en la Arquitectura de los LLMs | Bioestad√≠stica edu"><meta property="og:description" content="Todos conocemos los Modelos de Lenguaje Grandes (LLMs) como ChatGPT de OpenAI, Claude de Anthropic, Gemini de Google y otros modelos similares.
Son esos asistentes de IA con los que conversamos, que nos ayudan a escribir correos (Stanford Online 2024)electr√≥nicos, a generar ideas e incluso a codificar."><meta property="og:image" content="https://maicel.netlify.app/post/ia/featured.png"><meta property="twitter:image" content="https://maicel.netlify.app/post/ia/featured.png"><meta property="og:locale" content="es-es"><meta property="article:published_time" content="2025-09-06T00:00:00+00:00"><meta property="article:modified_time" content="2025-09-06T00:00:00+00:00"><title>Una Inmersi√≥n Intuitiva en la Arquitectura de los LLMs | Bioestad√≠stica edu</title><style>@font-face{font-family:inter var;font-style:normal;font-weight:100 900;font-display:swap;src:url(/dist/font/Inter.var.woff2)format(woff2)}</style><link type=text/css rel=stylesheet href=/dist/pagefind/pagefind-ui.be766eb419317a14ec769d216e9779bfe8f3737c80e780f4ba0dafb57a41a482.css integrity="sha256-vnZutBkxehTsdp0hbpd5v+jzc3yA54D0ug2vtXpBpII="><script src=/dist/pagefind/pagefind-ui.87693d7c6f2b3b347ce359d0ede762c033419f0a32b22ce508c335a81d841f1b.js integrity="sha256-h2k9fG8rOzR841nQ7ediwDNBnwoysizlCMM1qB2EHxs="></script><script>window.hbb.pagefind={baseUrl:"/"}</script><style>html.dark{--pagefind-ui-primary:#eeeeee;--pagefind-ui-text:#eeeeee;--pagefind-ui-background:#152028;--pagefind-ui-border:#152028;--pagefind-ui-tag:#152028}</style><script>window.addEventListener("DOMContentLoaded",e=>{new PagefindUI({element:"#search",showSubResults:!0,baseUrl:window.hbb.pagefind.baseUrl,bundlePath:window.hbb.pagefind.baseUrl+"pagefind/"})}),document.addEventListener("DOMContentLoaded",()=>{let e=document.getElementById("search"),t=document.getElementById("search_toggle");t&&t.addEventListener("click",()=>{if(e.classList.toggle("hidden"),e.querySelector("input").value="",e.querySelector("input").focus(),!e.classList.contains("hidden")){let t=document.querySelector(".pagefind-ui__search-clear");t&&!t.hasAttribute("listenerOnClick")&&(t.setAttribute("listenerOnClick","true"),t.addEventListener("click",()=>{e.classList.toggle("hidden")}))}})})</script><script defer src=/js/hugo-blox-es.min.e6965f872775fcb889e784756e346e58af6799db6f12e6c21a12272f7d3b1c1e.js integrity="sha256-5pZfhyd1/LiJ54R1bjRuWK9nmdtvEubCGhInL307HB4="></script></head><body class="dark:bg-hb-dark dark:text-white page-wrapper" id=top><div id=page-bg></div><div class="page-header sticky top-0 z-30"><header id=site-header class=header><nav class="navbar px-3 flex justify-left"><div class="order-0 h-100"><a class=navbar-brand href=/ title="Bioestad√≠stica edu">Maicel Monzon</a></div><input id=nav-toggle type=checkbox class=hidden>
<label for=nav-toggle class="order-3 cursor-pointer flex items-center lg:hidden text-dark dark:text-white lg:order-1"><svg id="show-button" class="h-6 fill-current block" viewBox="0 0 20 20"><title>Open Menu</title><path d="M0 3h20v2H0V3zm0 6h20v2H0V9zm0 6h20v2H0V0z"/></svg><svg id="hide-button" class="h-6 fill-current hidden" viewBox="0 0 20 20"><title>Close Menu</title><polygon points="11 9 22 9 22 11 11 11 11 22 9 22 9 11 -2 11 -2 9 9 9 9 -2 11 -2" transform="rotate(45 10 10)"/></svg></label><ul id=nav-menu class="navbar-nav order-3 hidden lg:flex w-full pb-6 lg:order-1 lg:w-auto lg:space-x-2 lg:pb-0 xl:space-x-8 justify-left"><li class=nav-item><a class=nav-link href=/>Biograf√≠a</a></li><li class=nav-item><a class=nav-link href=/#papers>Publicaciones</a></li><li class=nav-item><a class=nav-link href=/#talks>Conferencias</a></li><li class=nav-item><a class=nav-link href=/#news>Noticias</a></li><li class=nav-item><a class=nav-link href=/experience/>Experiencia</a></li><li class=nav-item><a class=nav-link href=/projects/>Proyectos</a></li><li class=nav-item><a class=nav-link href=/teaching/>Docencia</a></li><li class=nav-item><a class=nav-link href=/subscribe/>Suscr√≠bete</a></li></ul><div class="order-1 ml-auto flex items-center md:order-2 lg:ml-0"><button aria-label=search class="text-black hover:text-primary inline-block px-3 text-xl dark:text-white" id=search_toggle><svg height="16" width="16" viewBox="0 0 512 512" fill="currentcolor"><path d="M416 208c0 45.9-14.9 88.3-40 122.7L502.6 457.4c12.5 12.5 12.5 32.8.0 45.3s-32.8 12.5-45.3.0L330.7 376c-34.4 25.2-76.8 40-122.7 40C93.1 416 0 322.9.0 208S93.1.0 208 0 416 93.1 416 208zM208 352a144 144 0 100-288 144 144 0 100 288z"/></svg></button><div class="px-3 text-black hover:text-primary-700 dark:text-white dark:hover:text-primary-300
[&.active]:font-bold [&.active]:text-black/90 dark:[&.active]:text-white"><button class="theme-toggle mt-1" accesskey=t title=appearance><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="dark:hidden"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="dark:block [&:not(dark)]:hidden"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div></nav></header><div id=search class="hidden p-3"></div></div><div class="page-body my-10"><div class="mx-auto flex max-w-screen-xl"><aside class="hb-sidebar-container max-lg:[transform:translate3d(0,-100%,0)] lg:hidden xl:block"><div class="px-4 pt-4 lg:hidden"></div><div class="hb-scrollbar lg:h-[calc(100vh-var(--navbar-height))]"><ul class="flex flex-col gap-1 lg:hidden"><li><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/subscribe/>Suscr√≠bete a Nuestro Contenido</a></li><li class=open><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/post/>Blog
<span data-hb-sidebar-toggle><svg fill="none" viewBox="0 0 24 24" stroke="currentcolor" class="h-[18px] min-w-[18px] rounded-sm p-0.5 hover:bg-gray-800/5 dark:hover:bg-gray-100/5"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" class="origin-center transition-transform rtl:-rotate-180"/></svg></span></a><div class="ltr:pr-0 overflow-hidden"><ul class=hb-sidebar-list><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/post/imryd-redaccion-inversa/>¬øEscribir ciencia o reescribir la realidad?</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/post/trampas-correlacion/>Las trampas de la correlaci√≥n disfrazada de causalidad</a></li><li class="flex flex-col open"><a class="hb-sidebar-custom-link
sidebar-active-item bg-primary-100 font-semibold text-primary-800 dark:bg-primary-300 dark:text-primary-900" href=/post/ia/>Una Inmersi√≥n Intuitiva en la Arquitectura de los LLMs</a><ul class=hb-sidebar-mobile-toc><li><a href=#la-anatom%c3%ada-de-un-llm-redes-neuronales-y-transformadores class=hb-docs-link>La Anatom√≠a de un LLM: Redes Neuronales y Transformadores</a></li><li><a href=#la-primera-etapa-pre-entrenamiento-modelado-del-lenguaje class=hb-docs-link>La Primera Etapa: Pre-entrenamiento (Modelado del Lenguaje)</a></li><li><a href=#modelos-de-lenguaje-autorregresivos-prediciendo-la-siguiente-palabra class=hb-docs-link>Modelos de Lenguaje Autorregresivos: Prediciendo la Siguiente Palabra</a></li><li><a href=#modelos-de-lenguaje-autorregresivos-prediciendo-la-siguiente-palabra-1 class=hb-docs-link>Modelos de Lenguaje Autorregresivos: Prediciendo la Siguiente Palabra</a></li><li><a href=#el-proceso-con-el-rat%c3%b3n-comi%c3%b3-el-queso class=hb-docs-link>El Proceso con &lt;strong>‚ÄúEl rat√≥n comi√≥ el queso‚Äù&lt;/strong></a></li><li><a href=#aprendizaje-del-modelo class=hb-docs-link>Aprendizaje del Modelo</a></li><li><a href=#los-tokenizadores-el-primer-paso-crucial-para-la-coherencia class=hb-docs-link>Los Tokenizadores: El Primer Paso Crucial para la ‚ÄúCoherencia‚Äù</a></li><li><a href=#de-modelo-de-lenguaje-a-asistente-de-ia-el-post-entrenamiento-o-la-ilusi%c3%b3n-de-la-intencionalidad class=hb-docs-link>De Modelo de Lenguaje a Asistente de IA: El Post-entrenamiento (o la Ilusi√≥n de la Intencionalidad)</a></li><li><a href=#1-ajuste-fino-supervisado-supervised-fine-tuning---sft class=hb-docs-link>1. Ajuste Fino Supervisado (Supervised Fine-Tuning - SFT)</a></li><li><a href=#2-aprendizaje-por-refuerzo-a-partir-de-retroalimentaci%c3%b3n-humana-reinforcement-learning-from-human-feedback---rlhf class=hb-docs-link>2. Aprendizaje por Refuerzo a partir de Retroalimentaci√≥n Humana (Reinforcement Learning from Human Feedback - RLHF)</a></li><li><a href=#la-materia-prima-datos-masivos-y-su-filtrado class=hb-docs-link>La Materia Prima: Datos Masivos y su Filtrado</a></li><li><a href=#las-leyes-de-escalado-el-poder-de-lo-grande-y-sus-implicaciones-en-la-inteligencia class=hb-docs-link>Las Leyes de Escalado: El Poder de lo Grande (y sus Implicaciones en la ‚ÄúInteligencia‚Äù)</a></li><li><a href=#sistemas-el-cerebro-detr%c3%a1s-de-la-eficiencia class=hb-docs-link>Sistemas: El Cerebro Detr√°s de la Eficiencia</a></li><li><a href=#conclusi%c3%b3n-una-ilusi%c3%b3n-poderosa-no-un-pensamiento-consciente class=hb-docs-link>Conclusi√≥n: Una Ilusi√≥n Poderosa, No un Pensamiento Consciente</a></li><li><a href=#bibliograf%c3%ada class=hb-docs-link>Bibliograf√≠a</a></li></ul></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/post/generalizacion/>Del Laboratorio al Mundo Real</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/post/m-s-all-del-rct-en-salud-p-blica-y-epidemiolog-a/>Desvelando la L√≥gica Matem√°tica Detr√°s de Causa y Efecto</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/post/2025-08-10-significacion/>Ciencia o Pirotecnia: Por Qu√© la 'Significaci√≥n Estad√≠stica' Nos Ciega con Falsos Destellos</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/post/atajos/>Dise√±os Alternativos a Ensayos Cl√≠nicos Controlados Aleatorizados: Contextos de Aplicaci√≥n y Riesgos Regulatorios</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/post/eda/>An√°lisis Exploratorio de Datos: Desentra√±ando la Verdad de tus Datos</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/post/como-entrenar-y-validar-un-modelo-de-machine-learnig/>Como entrenar y validar un modelo de machine learnig</a></li></ul></div></li><li><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/project/>Projects
<span data-hb-sidebar-toggle><svg fill="none" viewBox="0 0 24 24" stroke="currentcolor" class="h-[18px] min-w-[18px] rounded-sm p-0.5 hover:bg-gray-800/5 dark:hover:bg-gray-100/5"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" class="origin-center transition-transform rtl:-rotate-180"/></svg></span></a><div class="ltr:pr-0 overflow-hidden"><ul class=hb-sidebar-list><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/project/simed-simulacion-medica-en-linea/>SIMED: Simulaci√≥n M√©dica en L√≠nea para el Aprendizaje del Proceso de Atenci√≥n</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/project/plate-to-policy-real-time-ai-driven-insights-for-smarter-food-fortification/>MacroScope AI: Real-Time Nutrition Insights for Smarter Food Systems</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/project/covidcencecapk/>CovidCencecAPK</a></li></ul></div></li><li><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/teaching/>Teaching
<span data-hb-sidebar-toggle><svg fill="none" viewBox="0 0 24 24" stroke="currentcolor" class="h-[18px] min-w-[18px] rounded-sm p-0.5 hover:bg-gray-800/5 dark:hover:bg-gray-100/5"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" class="origin-center transition-transform rtl:-rotate-180"/></svg></span></a><div class="ltr:pr-0 overflow-hidden"><ul class=hb-sidebar-list><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/teaching/introducci-n-a-los-dise-os-explicativos-experimentales/>Introducci√≥n a los dise√±os explicativos experimentales</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/teaching/conferencia-introducci-n-al-an-lisis-estad-stico-en-ensayos-cl-nicos/>Conferencia Introducci√≥n al an√°lisis estad√≠stico en ensayos cl√≠nicos</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/teaching/tutorial-an-lisis-de-fortificaci-n-de-alimentos-con-hces-y-r/>Tutorial: An√°lisis de Fortificaci√≥n de Alimentos con HCES y R</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/teaching/r/>An√°lisis de datos en fortificaci√≥n de alimentos a gran escala con R. Una Introducci√≥n Pr√°ctica</a></li></ul></div></li><li><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/event/>Recent & Upcoming Talks
<span data-hb-sidebar-toggle><svg fill="none" viewBox="0 0 24 24" stroke="currentcolor" class="h-[18px] min-w-[18px] rounded-sm p-0.5 hover:bg-gray-800/5 dark:hover:bg-gray-100/5"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" class="origin-center transition-transform rtl:-rotate-180"/></svg></span></a><div class="ltr:pr-0 overflow-hidden"><ul class=hb-sidebar-list><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/event/example/>üëã Curso de An√°lisis de Datos en Fortificaci√≥n de Alimentos con R. Una Introducci√≥n Pr√°ctica</a></li></ul></div></li><li><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/projects/>Projects</a></li><li><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/experience/>Experience</a></li><li><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/>Publications
<span data-hb-sidebar-toggle><svg fill="none" viewBox="0 0 24 24" stroke="currentcolor" class="h-[18px] min-w-[18px] rounded-sm p-0.5 hover:bg-gray-800/5 dark:hover:bg-gray-100/5"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" class="origin-center transition-transform rtl:-rotate-180"/></svg></span></a><div class="ltr:pr-0 overflow-hidden"><ul class=hb-sidebar-list><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/journal-article/>Estado en la investigaci√≥n sobre modelos de predicci√≥n de la severidad en confirmados de la Covid-19.</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/preprint/>Identificaci√≥n de pacientes de bajo riesgo de severidad en confirmados de la COVID-19. Cuba. A√±os 2020-2021</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/2025-09-23-modelo-sir-para-epidemias-persistencia-en-el-tiempo-y-nuevos-retos-en-la-era-de-la-inform-tica-y-las-pandemias/>Modelo SIR para epidemias: Persistencia en el tiempo y nuevos retos en la era de la Inform√°tica y las pandemias.</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/2025-09-23-plagio-en-art-culos-de-investigaci-n-en-revistas-biom-dicas-cubanas-2016/>Plagio en art√≠culos de investigaci√≥n en revistas biom√©dicas cubanas. 2016</a></li></ul></div></li></ul><div class="max-xl:hidden h-0 w-64 shrink-0"></div></div></aside><nav class="hb-toc order-last hidden w-64 shrink-0 xl:block print:hidden px-4" aria-label="table of contents"><div class="hb-scrollbar text-sm [hyphens:auto] sticky top-16 overflow-y-auto pr-4 pt-6 max-h-[calc(100vh-var(--navbar-height)-env(safe-area-inset-bottom))] -mr-4 rtl:-ml-4"><p class="mb-4 font-semibold tracking-tight">En esta p√°gina</p><ul><li class="my-2 scroll-my-6 scroll-py-6"><a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#la-anatom%c3%ada-de-un-llm-redes-neuronales-y-transformadores>La Anatom√≠a de un LLM: Redes Neuronales y Transformadores</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#la-primera-etapa-pre-entrenamiento-modelado-del-lenguaje>La Primera Etapa: Pre-entrenamiento (Modelado del Lenguaje)</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#modelos-de-lenguaje-autorregresivos-prediciendo-la-siguiente-palabra>Modelos de Lenguaje Autorregresivos: Prediciendo la Siguiente Palabra</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#modelos-de-lenguaje-autorregresivos-prediciendo-la-siguiente-palabra-1>Modelos de Lenguaje Autorregresivos: Prediciendo la Siguiente Palabra</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#el-proceso-con-el-rat%c3%b3n-comi%c3%b3-el-queso>El Proceso con ‚ÄúEl rat√≥n comi√≥ el queso‚Äù</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#aprendizaje-del-modelo>Aprendizaje del Modelo</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#los-tokenizadores-el-primer-paso-crucial-para-la-coherencia>Los Tokenizadores: El Primer Paso Crucial para la ‚ÄúCoherencia‚Äù</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#de-modelo-de-lenguaje-a-asistente-de-ia-el-post-entrenamiento-o-la-ilusi%c3%b3n-de-la-intencionalidad>De Modelo de Lenguaje a Asistente de IA: El Post-entrenamiento (o la Ilusi√≥n de la Intencionalidad)</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#1-ajuste-fino-supervisado-supervised-fine-tuning---sft>1. Ajuste Fino Supervisado (Supervised Fine-Tuning - SFT)</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#2-aprendizaje-por-refuerzo-a-partir-de-retroalimentaci%c3%b3n-humana-reinforcement-learning-from-human-feedback---rlhf>2. Aprendizaje por Refuerzo a partir de Retroalimentaci√≥n Humana (Reinforcement Learning from Human Feedback - RLHF)</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#la-materia-prima-datos-masivos-y-su-filtrado>La Materia Prima: Datos Masivos y su Filtrado</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#las-leyes-de-escalado-el-poder-de-lo-grande-y-sus-implicaciones-en-la-inteligencia>Las Leyes de Escalado: El Poder de lo Grande (y sus Implicaciones en la ‚ÄúInteligencia‚Äù)</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#sistemas-el-cerebro-detr%c3%a1s-de-la-eficiencia>Sistemas: El Cerebro Detr√°s de la Eficiencia</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#conclusi%c3%b3n-una-ilusi%c3%b3n-poderosa-no-un-pensamiento-consciente>Conclusi√≥n: Una Ilusi√≥n Poderosa, No un Pensamiento Consciente</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#bibliograf%c3%ada>Bibliograf√≠a</a></li></ul>
    
    
  </div></nav><article class="w-full break-words flex min-h-[calc(100vh-var(--navbar-height))] min-w-0 justify-center pb-8 pr-[calc(env(safe-area-inset-right)-1.5rem)]"><main class="w-full min-w-0 max-w-6xl px-6 pt-4 md:px-12"><h1 class="mt-2 text-4xl font-bold tracking-tight text-slate-900 dark:text-slate-100">Una Inmersi√≥n Intuitiva en la Arquitectura de los LLMs</h1><div class="mt-4 mb-16"><div class="text-gray-500 dark:text-gray-300 text-sm flex items-center flex-wrap gap-y-2"><span class=mr-1>sept. 6, 2025</span><span class=mx-1>¬∑</span><div class="group inline-flex items-center text-current gap-x-1.5 mx-1"><img src=/author/maicel/avatar_hu_ea70620c12b21ae4.webp alt=Maicel class="inline-block h-4 w-4 rounded-full border border-current" loading=lazy><div>Maicel</div></div><span class=mx-1>¬∑</span>
<span class=mx-1>13 min de lectura</span></div><div class=mt-3></div></div><div class="article-header article-container featured-image-wrapper mt-4 mb-16" style=max-width:720px;max-height:1080px><div style=position:relative><img src=/post/ia/featured_hu_fe822641f03c14b.webp width=720 height=1080 alt class=featured-image></div></div><div class="prose prose-slate lg:prose-xl dark:prose-invert"><p>Todos conocemos los Modelos de Lenguaje Grandes (LLMs) como <strong>ChatGPT de OpenAI, Claude de Anthropic, Gemini de Google</strong> y otros modelos similares.</p><p>Son esos asistentes de IA con los que conversamos, que nos ayudan a escribir correos (Stanford Online 2024)electr√≥nicos, a generar ideas e incluso a codificar.</p><p>Pero, ¬øalguna vez te has preguntado c√≥mo funcionan realmente estas herramientas?
¬øEst√°n pensando o simplemente est√°n creando una <strong>magn√≠fica ilusi√≥n de razonamiento</strong>?
En este blog, te mostrar√© c√≥mo cobran vida estas maravillas tecnol√≥gicas, desde el vasto oc√©ano de datos hasta su afinada inteligencia, y exploraremos la naturaleza de esa ‚Äúinteligencia‚Äù que tanto nos asombra.</p><p>Puedes ver la versi√≥n en v√≠deo de esta publicaci√≥n aqu√≠:</p><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden><iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen loading=eager referrerpolicy=strict-origin-when-cross-origin src="https://www.youtube.com/embed/SxIFozcvCAU?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0" style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 title="YouTube video"></iframe></div><p>A continuaci√≥n, te explico algunos elementos importantes para entender los Modelos de Lenguaje Grandes (LLMs), como se construyen, c√≥mo se entrenan y predicen sus resultado.</p><img src=fig0.png style=width:30%><h2 id=la-anatom√≠a-de-un-llm-redes-neuronales-y-transformadores>La Anatom√≠a de un LLM: Redes Neuronales y Transformadores</h2><p>En esencia, los LLMs son <strong>redes neuronales</strong>.
Lejos de simular el cerebro humano en un sentido biol√≥gico, se basan casi universalmente en una arquitectura particular conocida como <strong>Transformadores</strong>.</p><div class="flex px-4 py-3 mb-6 rounded-md bg-primary-100 dark:bg-primary-900"><span class="pr-3 pt-1 text-primary-600 dark:text-primary-300"><svg height="24" viewBox="0 0 24 24"><path fill="none" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="m11.25 11.25.041-.02a.75.75.0 011.063.852l-.708 2.836a.75.75.0 001.063.853l.041-.021M21 12A9 9 0 113 12a9 9 0 0118 0m-9-3.75h.008v.008H12z"/></svg>
</span><span class=dark:text-neutral-300><strong>Red neuronal artificial:</strong> <em>‚ÄúUna red neuronal artificial es un sistema de procesamiento paralelo y distribuido, compuesto por unidades simples de procesamiento que tienen la propensi√≥n natural de almacenar conocimiento experimental y hacerlo disponible para su uso‚Äù</em> (Haykin, n.d.).</span></div><p>Estos Transformadores fueron propuestos por Vaswani et al.¬†en 2017 y se destacaron por su capacidad para ‚Äúdibujar dependencias globales entre la entrada y la salida‚Äù utilizando √∫nicamente mecanismos de atenci√≥n, sin necesidad de redes recurrentes o convolucionales.</p><p>Esta capacidad es clave para su √©xito: permite que el modelo procese grandes cantidades de texto en paralelo y capte relaciones a larga distancia dentro de una secuencia.(Vaswani et al., n.d.)</p><p>Cuando hablamos de entrenar un LLM, hay varios componentes clave que entran en juego:</p><p><figure><div class="flex justify-center"><div class=w-100><img alt srcset="/post/ia/fig1_hu_18182d8f524833af.webp 400w,
/post/ia/fig1_hu_f33bba6717280fcf.webp 760w,
/post/ia/fig1_hu_4ee0477a1071e0cf.webp 1200w" src=/post/ia/fig1_hu_18182d8f524833af.webp width=760 height=410 loading=lazy data-zoomable></div></div></figure></p><h2 id=la-primera-etapa-pre-entrenamiento-modelado-del-lenguaje>La Primera Etapa: Pre-entrenamiento (Modelado del Lenguaje)</h2><p>El viaje de un LLM comienza con el <strong>pre-entrenamiento</strong>, un paradigma cl√°sico donde el modelo se entrena para <strong>‚Äúmodelar todo Internet‚Äù</strong>.</p><p>En esta fase, un modelo de lenguaje es, a grandes rasgos, un modelo de <strong>distribuci√≥n de probabilidad sobre secuencias de tokens o palabras</strong>.</p><div class="flex px-4 py-3 mb-6 rounded-md bg-primary-100 dark:bg-primary-900"><span class="pr-3 pt-1 text-primary-600 dark:text-primary-300"><svg height="24" viewBox="0 0 24 24"><path fill="none" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="m11.25 11.25.041-.02a.75.75.0 011.063.852l-.708 2.836a.75.75.0 001.063.853l.041-.021M21 12A9 9 0 113 12a9 9 0 0118 0m-9-3.75h.008v.008H12z"/></svg>
</span><span class=dark:text-neutral-300><strong>Tokens:</strong> <em>‚ÄúUn token es una instancia de una secuencia de caracteres en un documento, agrupada como una unidad sem√°ntica √∫til para el procesamiento autom√°tico de texto. Esta explicaci√≥n se basa en una definici√≥n clara y rigurosa en el contexto del an√°lisis de informaci√≥n y recuperaci√≥n de documentos.‚Äù</em></span></div><p>Imagina la frase <strong>‚ÄúEl rat√≥n comi√≥ el queso‚Äù</strong>.</p><img src=fig2.png style=width:30%><p>Un modelo de lenguaje te dar√≠a la probabilidad de que esta frase sea pronunciada por un humano o encontrada en l√≠nea.</p><p>Si la frase tuviera errores gramaticales como <strong>‚ÄúEl el rat√≥n queso‚Äù</strong>, el modelo, con su conocimiento sint√°ctico, sabr√≠a que es menos <strong>probable</strong>.</p><p>Y si fuera <strong>‚ÄúEl queso comi√≥ el rat√≥n‚Äù</strong>, su conocimiento sem√°ntico le indicar√≠a que esto es <strong>improbable</strong>.</p><img src=fig3.png style=width:30%><p><strong>Aqu√≠ es donde entra el primer matiz cr√≠tico</strong>: este <strong>‚Äúconocimiento sint√°ctico y sem√°ntico‚Äù</strong> no implica que el modelo <strong>entienda</strong> realmente la gram√°tica o que los quesos no comen ratones.</p><p>M√°s bien, ha aprendido, a partir de patrones en billones de textos, que ciertas secuencias de palabras son estad√≠sticamente m√°s probables o coherentes que otras.
Es una habilidad predictiva, no una comprensi√≥n conceptual.</p><p>Los LLMs son <strong>modelos generativos</strong>.</p><p>Esto significa que, una vez que tienen esta comprensi√≥n de las distribuciones de probabilidad, pueden <strong>generar nuevas oraciones o datos</strong> simplemente muestreando de esa distribuci√≥n.</p><div class="flex px-4 py-3 mb-6 rounded-md bg-primary-100 dark:bg-primary-900"><span class="pr-3 pt-1 text-primary-600 dark:text-primary-300"><svg height="24" viewBox="0 0 24 24"><path fill="none" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="m11.25 11.25.041-.02a.75.75.0 011.063.852l-.708 2.836a.75.75.0 001.063.853l.041-.021M21 12A9 9 0 113 12a9 9 0 0118 0m-9-3.75h.008v.008H12z"/></svg>
</span><span class=dark:text-neutral-300><strong>Modelos generativos:</strong> <em>‚ÄúSon algoritmos dise√±ados para crear datos nuevos que parecen provenir de la misma distribuci√≥n que los datos originales con los que fueron entrenados.‚Äù</em></span></div><p>Es decir, <em>saben</em> c√≥mo sonar convincentes y coherentes, pero no necesariamente <em>por qu√©</em> lo que dicen es correcto o verdadero.</p><h2 id=modelos-de-lenguaje-autorregresivos-prediciendo-la-siguiente-palabra>Modelos de Lenguaje Autorregresivos: Prediciendo la Siguiente Palabra</h2><p>Vamos a adaptar el texto que proporcionaste para que se conecte con nuestro ejemplo del rat√≥n y el queso.üêÅüßÄ</p><h2 id=modelos-de-lenguaje-autorregresivos-prediciendo-la-siguiente-palabra-1>Modelos de Lenguaje Autorregresivos: Prediciendo la Siguiente Palabra</h2><p>Los modelos de lenguaje m√°s modernos, como Gemini, son <strong>autorregresivos</strong>.
Esto significa que predicen la <strong>siguiente palabra bas√°ndose en todas las palabras que ya han visto</strong> en la secuencia.</p><p>Piensa en ellos como un narrador que va construyendo una historia palabra por palabra.</p><h2 id=el-proceso-con-el-rat√≥n-comi√≥-el-queso>El Proceso con <strong>‚ÄúEl rat√≥n comi√≥ el queso‚Äù</strong></h2><p>Imaginemos que el modelo est√° generando nuestra frase, ‚ÄúEl rat√≥n comi√≥ el queso.‚Äù Este es el fascinante proceso que ocurre:</p><ol><li><p><strong>Secuencia de palabras:</strong> El modelo empieza con la primera palabra de la oraci√≥n.
Luego, toma las palabras que ya ha generado: <strong>‚ÄúEl rat√≥n‚Äù</strong>.</p></li><li><p><strong>Tokenizaci√≥n:</strong> Las palabras se convierten en <strong>tokens</strong> (n√∫meros o identificadores internos).
Por ejemplo, ‚ÄúEl‚Äù podr√≠a ser <code>143</code>, ‚Äúrat√≥n‚Äù <code>56</code>, y ‚Äúcomi√≥‚Äù <code>25</code>.</p></li><li><p><strong>El modelo predice:</strong> Estos tokens numerados entran en el modelo (la ‚Äúcaja negra‚Äù).
Basado en todo lo que ha aprendido de internet, el modelo calcula cu√°l es el pr√≥ximo token m√°s probable.</p></li><li><p><strong>Distribuci√≥n de probabilidad:</strong> El modelo no solo predice una palabra, sino que le asigna una <strong>probabilidad a cada palabra</strong> en su vocabulario.
Por ejemplo, despu√©s de <strong>‚ÄúEl rat√≥n comi√≥ el‚Äù</strong>, la palabra <strong>‚Äúqueso‚Äù</strong> podr√≠a tener una probabilidad del 85%, ‚Äúpan‚Äù un 10%, y ‚Äúsemillas‚Äù un 5%.</p></li><li><p><strong>Muestreo:</strong> El modelo elige el token con la probabilidad m√°s alta, que en este caso es el token para ‚Äúqueso‚Äù.
A veces, para no sonar rob√≥tico, el modelo elige una palabra con una probabilidad un poco menor, pero en la mayor√≠a de los casos elige la m√°s probable.</p></li><li><p><strong>Detokenizaci√≥n:</strong> El token seleccionado se convierte de nuevo en la palabra ‚Äúqueso‚Äù, completando as√≠ la frase.</p></li></ol><hr><h2 id=aprendizaje-del-modelo>Aprendizaje del Modelo</h2><p>Durante el <strong>entrenamiento</strong>, el modelo hace este mismo proceso, pero en lugar de generar una frase nueva, compara su predicci√≥n con la palabra real en un texto de entrenamiento.</p><ul><li><p>Si el modelo predice <strong>‚Äúpan‚Äù</strong> y la palabra correcta es <strong>‚Äúqueso‚Äù</strong>, la <strong>funci√≥n de p√©rdida de entrop√≠a cruzada</strong> le da un ‚Äúcastigo‚Äù.</p></li><li><p>Ese castigo se usa para ajustar los pesos del modelo.
El objetivo es que, la pr√≥xima vez que vea un contexto similar (‚ÄúEl rat√≥n comi√≥ el‚Ä¶‚Äù), la probabilidad de que prediga ‚Äúqueso‚Äù sea mucho mayor.</p></li></ul><p>As√≠, la ‚Äúfluidez‚Äù del modelo para generar frases como ‚ÄúEl rat√≥n comi√≥ el queso‚Äù se basa en su capacidad para <strong>predecir estad√≠sticamente</strong> la palabra m√°s probable en cada paso, no en un razonamiento sobre los h√°bitos alimenticios de los roedores.</p><h2 id=los-tokenizadores-el-primer-paso-crucial-para-la-coherencia>Los Tokenizadores: El Primer Paso Crucial para la ‚ÄúCoherencia‚Äù</h2><p>Los <strong>tokenizadores</strong> son componentes extremadamente importantes pero a menudo poco valorados.</p><p>¬øPor qu√© los necesitamos?</p><ul><li><p><strong>M√°s generales que las palabras</strong>: Las palabras como tokens directos fallan con errores tipogr√°ficos o en idiomas que no usan espacios (como el tailand√©s).</p></li><li><p><strong>Eficiencia de secuencia</strong>: Tokenizar car√°cter por car√°cter har√≠a las secuencias demasiado largas, lo que es ineficiente para los Transformadores (cuya complejidad crece cuadr√°ticamente con la longitud de la secuencia).</p></li></ul><p>Los tokenizadores buscan encontrar <strong>subsecuencias comunes</strong> y darles un token espec√≠fico.
En promedio, un token suele representar alrededor de <strong>tres o cuatro letras</strong>.</p><p>Un algoritmo muy com√∫n es la <strong>Codificaci√≥n de Pares de Bytes (Byte Pair Encoding o BPE)</strong>.
Es fundamental considerar c√≥mo se tokeniza el texto, ya que el <strong>tama√±o del vocabulario afecta directamente la dimensionalidad de la salida</strong> del modelo.</p><p><strong>Un punto cr√≠tico aqu√≠</strong>: Si bien son √∫tiles, los tokenizadores tienen limitaciones, especialmente con n√∫meros (matem√°ticas) y c√≥digo.</p><p>Por ejemplo, un n√∫mero como ‚Äú327‚Äù puede tener su propio token, lo que significa que el modelo no lo ve como una composici√≥n de ‚Äú3‚Äù, ‚Äú2‚Äù, ‚Äú7‚Äù, lo que dificulta su capacidad para razonar matem√°ticamente o con la estructura del c√≥digo.</p><p>Esto nos recuerda que, a pesar de la fluidez, los LLMs operan sobre representaciones simb√≥licas (tokens) que no siempre se alinean con nuestra comprensi√≥n conceptual del lenguaje o las matem√°ticas.</p><h2 id=de-modelo-de-lenguaje-a-asistente-de-ia-el-post-entrenamiento-o-la-ilusi√≥n-de-la-intencionalidad>De Modelo de Lenguaje a Asistente de IA: El Post-entrenamiento (o la Ilusi√≥n de la Intencionalidad)</h2><p>Un modelo pre-entrenado es un experto en <strong>‚Äúhablar como Internet‚Äù</strong>, pero no es un asistente de IA.</p><p>Si le preguntaras a <strong>GPT-3</strong> (un modelo puramente de lenguaje) ‚Äúexpl√≠came el aterrizaje en la luna a un ni√±o de seis a√±os‚Äù, podr√≠a responder con ‚Äúexpl√≠came la teor√≠a de la gravedad a un ni√±o de seis a√±os‚Äù porque ha aprendido que en Internet, una pregunta a menudo es seguida por preguntas similares, no por una respuesta directa.</p><p>El <strong>post-entrenamiento (alignment)</strong> es el proceso que transforma estos modelos en asistentes √∫tiles, asegur√°ndose de que <strong>sigan las instrucciones de los usuarios</strong> y los deseos de los dise√±adores (por ejemplo, evitar contenido t√≥xico).</p><p><strong>Este es el punto donde la ilusi√≥n de intencionalidad se vuelve m√°s fuerte.</strong></p><h2 id=1-ajuste-fino-supervisado-supervised-fine-tuning---sft>1. Ajuste Fino Supervisado (Supervised Fine-Tuning - SFT)</h2><p>El primer paso es el <strong>Ajuste Fino Supervisado (SFT)</strong>.</p><p>Aqu√≠, el LLM pre-entrenado se afina con <strong>respuestas deseadas recogidas de humanos</strong>.
Es decir, se le dan ejemplos de preguntas y sus respuestas ‚Äúcorrectas‚Äù o ‚Äúideales‚Äù escritas por humanos.</p><p>Este paso fue crucial para el salto de <strong>GPT-3</strong> a <strong>ChatGPT</strong>.</p><p>Curiosamente, no se necesita una cantidad masiva de datos para SFT; <strong>unos pocos miles de ejemplos bien elegidos pueden ser suficientes</strong>.</p><p>Esto sugiere que el SFT no ense√±a al modelo nuevo conocimiento, sino que le ense√±a <strong>c√≥mo formatear las respuestas</strong> y optimizar para un ‚Äútipo de usuario‚Äù espec√≠fico que ya hab√≠a visto en sus datos de pre-entrenamiento.</p><p>En otras palabras, el modelo ya ten√≠a el conocimiento latente; el SFT le ense√±a a <em>expresarlo</em> de la manera que un asistente de IA ‚Äúdeber√≠a‚Äù hacerlo.</p><p>No est√° aprendiendo a <em>pensar</em> como un asistente, sino a <em>simular</em> el comportamiento de uno.</p><h2 id=2-aprendizaje-por-refuerzo-a-partir-de-retroalimentaci√≥n-humana-reinforcement-learning-from-human-feedback---rlhf>2. Aprendizaje por Refuerzo a partir de Retroalimentaci√≥n Humana (Reinforcement Learning from Human Feedback - RLHF)</h2><p>El SFT tiene sus limitaciones: <strong>Limitado por la habilidad humana</strong>: Los humanos pueden juzgar mejor lo que es una buena respuesta de lo que pueden escribirla ellos mismos.</p><p><strong>Posibles alucinaciones</strong>: Como el SFT se entrena con poca data, si un humano da una respuesta que el modelo no ha visto antes (y por tanto no sabe si es cierta), el modelo puede aprender a ‚Äúinventar‚Äù informaci√≥n plausible pero falsa.</p><p><strong>Aqu√≠ el matiz cr√≠tico es fundamental</strong>: la ‚Äúalucinaci√≥n‚Äù (generaci√≥n de informaci√≥n falsa pero plausible) es una clara evidencia de que los LLMs no ‚Äúsaben‚Äù lo que es verdad o mentira, ni tienen un sentido de la realidad.</p><p>Simplemente generan secuencias de tokens que <em>parecen</em> correctas, bas√°ndose en los patrones que han aprendido, incluso si no tienen fundamento.</p><p>Es la culminaci√≥n de la ilusi√≥n de razonamiento.
<strong>Costo</strong>: Generar respuestas ideales es muy caro.</p><p>Aqu√≠ es donde entra el <strong>RLHF</strong>.</p><p>En lugar de simplemente clonar el comportamiento humano, el objetivo es <strong>maximizar la preferencia humana</strong>.</p><p>El proceso es el siguiente:</p><ol><li><p>Para una instrucci√≥n dada, el modelo genera <strong>dos respuestas diferentes</strong>.</p></li><li><p>Etiquetadores humanos seleccionan <strong>cu√°l de las dos respuestas es mejor</strong>.</p></li><li><p>Con esta retroalimentaci√≥n, el modelo se afina para generar m√°s de las respuestas ‚Äúbuenas‚Äù y menos de las ‚Äúmalas‚Äù.</p></li></ol><p>Para hacer esto, se entrena un <strong>modelo de recompensa (Reward Model)</strong>, un clasificador que aprende a predecir cu√°nto prefiere un humano una respuesta sobre otra, dando una se√±al de recompensa continua.</p><p>Posteriormente, m√©todos m√°s simples como la <strong>Optimizaci√≥n Directa por Preferencia (Direct Preference Optimization - DPO)</strong> han demostrado ser igual de efectivos, evitando la complejidad del aprendizaje por refuerzo tradicional.</p><p>En definitiva, RLHF moldea el comportamiento del LLM para alinearse con lo que <em>deseamos</em> ver, no con lo que el modelo <em>sabe</em> o <em>piensa</em>.</p><p>Le ense√±a a ser complaciente y a evitar lo ‚Äút√≥xico‚Äù porque los humanos as√≠ lo prefieren, no por un juicio moral inherente.</p><h2 id=la-materia-prima-datos-masivos-y-su-filtrado>La Materia Prima: Datos Masivos y su Filtrado</h2><p>El pre-entrenamiento de los LLMs se realiza sobre <strong>‚Äútodo Internet‚Äù</strong>.</p><p>Esto incluye vastas colecciones como Common Crawl, que contiene alrededor de <strong>250 mil millones de p√°ginas web y un petabyte de datos</strong>.</p><p>Pero el Internet es ‚Äúsucio‚Äù y no representativo.</p><p>Imagina una p√°gina web aleatoria: llena de HTML, publicidad, fragmentos sin terminar.</p><p>Para que estos datos sean √∫tiles, se requieren pasos de procesamiento intensivos, que incluyen:</p><p><figure><div class="flex justify-center"><div class=w-100><img alt srcset="/post/ia/fig4_hu_b74c97a4d4debd70.webp 400w,
/post/ia/fig4_hu_f0bdf3ad77c25970.webp 760w,
/post/ia/fig4_hu_6e63ba7ee8334dc3.webp 1200w" src=/post/ia/fig4_hu_b74c97a4d4debd70.webp width=507 height=760 loading=lazy data-zoomable></div></div></figure></p><p>La escala de estos conjuntos de datos es asombrosa, pasando de <strong>150 mil millones de tokens (800 GB)</strong> en benchmarks acad√©micos anteriores, hasta <strong>15 billones de tokens</strong> para modelos de √∫ltima generaci√≥n como Llama 3 (equivalente a miles de terabytes).</p><p>La recopilaci√≥n y curaci√≥n de datos sigue siendo un desaf√≠o enorme y un √°rea activa de investigaci√≥n.</p><h2 id=las-leyes-de-escalado-el-poder-de-lo-grande-y-sus-implicaciones-en-la-inteligencia>Las Leyes de Escalado: El Poder de lo Grande (y sus Implicaciones en la ‚ÄúInteligencia‚Äù)</h2><p>Uno de los descubrimientos m√°s sorprendentes en LLMs es que <strong>cuantos m√°s datos se entrenen los modelos y m√°s grandes sean los modelos, mejor ser√° su rendimiento</strong>.</p><p>A diferencia de lo que se ense√±a en muchas clases de aprendizaje autom√°tico, el ‚Äúsobreajuste‚Äù (overfitting) no parece ocurrir con los LLMs.</p><p>Las <strong>leyes de escalado</strong> nos muestran que si se aumenta la computaci√≥n, los datos o el n√∫mero de par√°metros, la p√©rdida de validaci√≥n del modelo disminuye de forma predecible y lineal en una escala logar√≠tmica.</p><p>Esto es crucial porque permite a las compa√±√≠as predecir cu√°nto mejorar√°n sus modelos en el futuro y c√≥mo optimizar la asignaci√≥n de recursos.</p><p>Por ejemplo, el famoso art√≠culo Chinchilla de DeepMind mostr√≥ que la relaci√≥n √≥ptima es entrenar con <strong>20 tokens por cada par√°metro</strong> del modelo para maximizar la eficiencia del entrenamiento.</p><p><strong>Un punto anal√≠tico aqu√≠</strong>: Que los modelos ‚Äúmejoren‚Äù al escalar no significa que se vuelvan intr√≠nsecamente ‚Äúm√°s inteligentes‚Äù en un sentido humano, o que est√©n m√°s cerca de la conciencia.</p><p>Simplemente, son <strong>m√°quinas de patrones incre√≠blemente sofisticadas</strong> que, con m√°s datos y m√°s capacidad computacional, son capaces de reconocer y generar patrones cada vez m√°s complejos y coherentes, reduciendo su ‚Äúp√©rdida‚Äù (es decir, volvi√©ndose mejores en la predicci√≥n del siguiente token).</p><p>La ‚Äúinteligencia‚Äù que percibimos es una propiedad emergente de esta capacidad de predicci√≥n a gran escala, no una mente.</p><h2 id=sistemas-el-cerebro-detr√°s-de-la-eficiencia>Sistemas: El Cerebro Detr√°s de la Eficiencia</h2><p>La computaci√≥n es el cuello de botella m√°s grande en el desarrollo de LLMs.
Comprar m√°s GPUs es dif√≠cil por su alto costo y escasez, adem√°s de las limitaciones f√≠sicas en la comunicaci√≥n entre ellas.</p><p>Es crucial optimizar c√≥mo se asignan los recursos y el pipeline de entrenamiento.</p><p>Algunos trucos clave a nivel de sistemas incluyen: <strong>Baja Precisi√≥n (Low Precision)</strong>: Usar n√∫meros de punto flotante de 16 bits en lugar de 32 bits.</p><p>Esto reduce la cantidad de datos que deben enviarse a las GPUs, acelerando la comunicaci√≥n y disminuyendo el consumo de memoria.</p><p><strong>Fusi√≥n de Operadores (Operator Fusion)</strong>: Las GPUs son muy lentas en la comunicaci√≥n.
La fusi√≥n de operadores combina varias operaciones consecutivas en una sola llamada al kernel, lo que significa que los datos se env√≠an a la GPU una sola vez, todas las operaciones se realizan y luego los resultados se devuelven, lo que acelera significativamente el proceso (por ejemplo, <code>torch.compile</code> en PyTorch puede duplicar la velocidad).</p><h2 id=conclusi√≥n-una-ilusi√≥n-poderosa-no-un-pensamiento-consciente>Conclusi√≥n: Una Ilusi√≥n Poderosa, No un Pensamiento Consciente</h2><p>Desde sus cimientos como redes neuronales Transformer, pasando por el pre-entrenamiento con datos masivos de Internet y el afinamiento con retroalimentaci√≥n humana, hasta la optimizaci√≥n de sistemas y la gesti√≥n de costos astron√≥micos, la creaci√≥n de un LLM es una haza√±a de ingenier√≠a y ciencia de datos.</p><p>La pr√≥xima vez que interact√∫es con un chatbot, recordar√°s que detr√°s de esa respuesta fluida hay billones de tokens procesados, complejos algoritmos de entrenamiento, ingeniosas t√©cnicas de afinamiento y una infraestructura computacional masiva trabajando en conjunto.
<strong>Estos modelos no ‚Äúpiensan‚Äù en el sentido humano de la palabra, ni poseen conciencia o una comprensi√≥n profunda y hol√≠stica del mundo</strong>.</p><p>Lo que hacen, y lo hacen de manera magistral, es <strong>identificar y reproducir patrones estad√≠sticos</strong> en los datos con los que fueron entrenados.</p><p>Su habilidad para generar texto coherente, relevante y a menudo sorprendentemente ‚Äúinteligente‚Äù es una testamentaci√≥n de la <strong>efectividad de la predicci√≥n a escala masiva</strong>.
Es una <strong>ilusi√≥n de razonamiento</strong> tan convincente que a menudo nos hace cuestionar la naturaleza de la inteligencia misma.
Y es, sin duda, una de las maravillas tecnol√≥gicas m√°s grandes de nuestro tiempo.</p><h2 id=bibliograf√≠a>Bibliograf√≠a</h2><div id=refs class="references csl-bib-body hanging-indent" entry-spacing=0><div id=ref-haykin class=csl-entry><p>Haykin, Simon. n.d. ‚ÄúNeural Networks and Learning Machines.‚Äù <a href=http://dni.dali.dartmouth.edu/9umv9yghhaoq/13-dayana-hermann-1/read-0131471392-neural-networks-and-learning-machines.pdf target=_blank rel=noopener>http://dni.dali.dartmouth.edu/9umv9yghhaoq/13-dayana-hermann-1/read-0131471392-neural-networks-and-learning-machines.pdf</a>.</p></div><div id=ref-stanfordonline2024 class=csl-entry><p>Stanford Online. 2024. ‚ÄúStanford CS229 i Machine Learning i Building Large Language Models (LLMs),‚Äù August. <a href="https://www.youtube.com/watch?v=9vM4p9NN0Ts" target=_blank rel=noopener>https://www.youtube.com/watch?v=9vM4p9NN0Ts</a>.</p></div><div id=ref-vaswani class=csl-entry><p>Vaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. n.d. ‚ÄúAttention Is All You Need.‚Äù <a href=https://doi.org/10.48550/ARXIV.1706.03762 target=_blank rel=noopener>https://doi.org/10.48550/ARXIV.1706.03762</a>.</p></div></div></div><time class="mt-12 mb-8 block text-xs text-gray-500 ltr:text-right rtl:text-left dark:text-gray-400" datetime=2025-09-06T00:00:00.000Z><span>√öltima actualizaci√≥n el</span>
sept. 6, 2025</time><div class="container mx-auto prose prose-slate lg:prose-xl dark:prose-invert mt-5"><div class="max-w-prose print:hidden"><div class="flex justify-center"><a class="no-underline bg-primary-100 hover:bg-primary-300 text-primary-800 text-xs font-medium mr-2 px-2.5 py-0.5 lg:px-5 lg:py-2 rounded dark:bg-primary-900 dark:hover:bg-primary-700 dark:text-primary-300" href=/tags/ia/>IA</a></div><section class="flex flex-row flex-wrap justify-center pt-4 text-xl"><a target=_blank rel=noopener class="m-1 rounded-md bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral-300 dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fmaicel.netlify.app%2Fpost%2Fia%2F&amp;text=Una+Inmersi%C3%B3n+Intuitiva+en+la+Arquitectura+de+los+LLMs" title=X aria-label=X id=share-link-x><svg style="height:1em" viewBox="0 0 512 512"><path fill="currentcolor" d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"/></svg>
</a><a target=_blank rel=noopener class="m-1 rounded-md bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral-300 dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://www.facebook.com/sharer.php?u=https%3A%2F%2Fmaicel.netlify.app%2Fpost%2Fia%2F&amp;t=Una+Inmersi%C3%B3n+Intuitiva+en+la+Arquitectura+de+los+LLMs" title=Facebook aria-label=Facebook id=share-link-facebook><svg style="height:1em" viewBox="0 0 24 24"><path fill="currentcolor" d="M22 12c0-5.52-4.48-10-10-10S2 6.48 2 12c0 4.84 3.44 8.87 8 9.8V15H8v-3h2V9.5C10 7.57 11.57 6 13.5 6H16v3h-2c-.55.0-1 .45-1 1v2h3v3h-3v6.95c5.05-.5 9-4.76 9-9.95z"/></svg>
</a><a target=_blank rel=noopener class="m-1 rounded-md bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral-300 dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="mailto:?subject=Una%20Inmersi%C3%B3n%20Intuitiva%20en%20la%20Arquitectura%20de%20los%20LLMs&amp;body=https%3A%2F%2Fmaicel.netlify.app%2Fpost%2Fia%2F" title=Email aria-label=Email id=share-link-email><svg style="height:1em" viewBox="0 0 24 24"><path fill="none" stroke="currentcolor" stroke-linecap="round" stroke-width="1.5" d="M16.5 12a4.5 4.5.0 11-9 0 4.5 4.5.0 019 0zm0 0c0 1.657 1.007 3 2.25 3S21 13.657 21 12a9 9 0 10-2.636 6.364M16.5 12V8.25"/></svg>
</a><a target=_blank rel=noopener class="m-1 rounded-md bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral-300 dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://www.linkedin.com/shareArticle?url=https%3A%2F%2Fmaicel.netlify.app%2Fpost%2Fia%2F&amp;title=Una+Inmersi%C3%B3n+Intuitiva+en+la+Arquitectura+de+los+LLMs" title=LinkedIn aria-label=LinkedIn id=share-link-linkedin><svg style="height:1em" height="1em" viewBox="0 0 448 512"><path fill="currentcolor" d="M416 32H31.9C14.3 32 0 46.5.0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6.0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3.0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2.0 38.5 17.3 38.5 38.5.0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6.0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2.0 79.7 44.3 79.7 101.9V416z"/></svg>
</a><a target=_blank rel=noopener class="m-1 rounded-md bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral-300 dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="whatsapp://send?text=Una+Inmersi%C3%B3n+Intuitiva+en+la+Arquitectura+de+los+LLMs%20https%3A%2F%2Fmaicel.netlify.app%2Fpost%2Fia%2F" title=WhatsApp aria-label=WhatsApp id=share-link-whatsapp><svg style="height:1em" viewBox="0 0 256 256" fill="currentcolor"><path d="m187.58 144.84-32-16a8 8 0 00-8 .5l-14.69 9.8a40.55 40.55.0 01-16-16l9.8-14.69a8 8 0 00.5-8l-16-32A8 8 0 00104 64a40 40 0 00-40 40 88.1 88.1.0 0088 88 40 40 0 0040-40 8 8 0 00-4.42-7.16zM152 176a72.08 72.08.0 01-72-72 24 24 0 0119.29-23.54l11.48 23L101 118a8 8 0 00-.73 7.51 56.47 56.47.0 0030.15 30.15A8 8 0 00138 155l14.61-9.74 23 11.48A24 24 0 01152 176zM128 24A104 104 0 0036.18 176.88l-11.35 34.05a16 16 0 0020.24 20.24l34.05-11.35A104 104 0 10128 24zm0 192a87.87 87.87.0 01-44.06-11.81 8 8 0 00-6.54-.67L40 216l12.47-37.4a8 8 0 00-.66-6.54A88 88 0 11128 216z"/></svg></a></section><div class="flex pt-12 pb-4"><img class="mr-4 h-24 w-24 rounded-full" width=96 height=96 alt=Maicel src=/author/maicel/avatar_hu_3534db34d293129b.jpg loading=lazy><div class=place-self-center><div class="text-[0.6rem] uppercase leading-3 text-neutral-500 dark:text-neutral-400">Autores</div><div class="font-semibold leading-6 text-neutral-800 dark:text-neutral-300"><a href=https://maicel.netlify.app/ class=no-underline>Maicel</a></div><div class="text-sm font-bold text-neutral-700 dark:text-neutral-300">M√©dico, Bioestad√≠stico, Cient√≠fico de datos</div><div class="text-2xl sm:text-lg pt-1"><div class="flex flex-wrap text-neutral-500 dark:text-neutral-300"><a class="pr-2 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400" style=will-change:transform href=mailto:maicel.monzon@gmail.com aria-label=At-Symbol><svg style="height:1em" viewBox="0 0 24 24"><path fill="none" stroke="currentcolor" stroke-linecap="round" stroke-width="1.5" d="M16.5 12a4.5 4.5.0 11-9 0 4.5 4.5.0 019 0zm0 0c0 1.657 1.007 3 2.25 3S21 13.657 21 12a9 9 0 10-2.636 6.364M16.5 12V8.25"/></svg></a>
<a class="pr-2 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400" style=will-change:transform href=https://x.com/maicel1978 target=_blank rel=noopener rel="me noopener noreferrer" aria-label=Brands/X><svg style="height:1em" viewBox="0 0 512 512"><path fill="currentcolor" d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"/></svg></a>
<a class="pr-2 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400" style=will-change:transform href=https://www.instagram.com/maicel1978/ target=_blank rel=noopener rel="me noopener noreferrer" aria-label=Brands/Instagram><svg style="height:1em" viewBox="0 0 15 15"><path fill="currentcolor" fill-rule="evenodd" d="M12.91 12.909c.326-.327.582-.72.749-1.151.16-.414.27-.886.302-1.578.032-.693.04-.915.04-2.68.0-1.765-.008-1.987-.04-2.68-.032-.692-.142-1.164-.302-1.578a3.185 3.185.0 00-.75-1.151 3.187 3.187.0 00-1.151-.75c-.414-.16-.886-.27-1.578-.302C9.487 1.007 9.265 1 7.5 1c-1.765.0-1.987.007-2.68.04-.692.03-1.164.14-1.578.301a3.2 3.2.0 00-1.151.75 3.2 3.2.0 00-.75 1.151c-.16.414-.27.886-.302 1.578C1.007 5.513 1 5.735 1 7.5s.007 1.987.04 2.68c.03.692.14 1.164.301 1.578.164.434.42.826.75 1.151.325.33.718.586 1.151.75.414.16.886.27 1.578.302.693.031.915.039 2.68.039s1.987-.008 2.68-.04c.692-.03 1.164-.14 1.578-.301a3.323 3.323.0 001.151-.75zM2 6.735v1.53c-.002.821-.002 1.034.02 1.5.026.586.058 1.016.156 1.34.094.312.199.63.543 1.012.344.383.675.556 1.097.684.423.127.954.154 1.415.175.522.024.73.024 1.826.024H8.24c.842.001 1.054.002 1.526-.02.585-.027 1.015-.059 1.34-.156.311-.094.629-.2 1.011-.543.383-.344.556-.676.684-1.098.127-.422.155-.953.176-1.414C13 9.247 13 9.04 13 7.947v-.89c0-1.096.0-1.303-.023-1.826-.021-.461-.049-.992-.176-1.414-.127-.423-.3-.754-.684-1.098-.383-.344-.7-.449-1.011-.543-.325-.097-.755-.13-1.34-.156A27.29 27.29.0 008.24 2H7.057c-1.096.0-1.304.0-1.826.023-.461.021-.992.049-1.415.176-.422.128-.753.301-1.097.684s-.45.7-.543 1.012c-.098.324-.13.754-.156 1.34-.022.466-.022.679-.02 1.5zM7.5 5.25a2.25 2.25.0 100 4.5 2.25 2.25.0 000-4.5zM4.25 7.5a3.25 3.25.0 116.5.0 3.25 3.25.0 01-6.5.0zm6.72-2.72a.75.75.0 100-1.5.75.75.0 000 1.5z" clip-rule="evenodd"/></svg></a>
<a class="pr-2 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400" style=will-change:transform href=https://github.com/maicel1978 target=_blank rel=noopener rel="me noopener noreferrer" aria-label=Brands/Github><svg style="height:1em" fill="currentcolor" viewBox="3 3 18 18"><path d="M12 3C7.0275 3 3 7.12937 3 12.2276c0 4.0833 2.57625 7.5321 6.15374 8.7548C9.60374 21.0631 9.77249 20.7863 9.77249 20.5441 9.77249 20.3249 9.76125 19.5982 9.76125 18.8254 7.5 19.2522 6.915 18.2602 6.735 17.7412 6.63375 17.4759 6.19499 16.6569 5.8125 16.4378 5.4975 16.2647 5.0475 15.838 5.80124 15.8264 6.51 15.8149 7.01625 16.4954 7.18499 16.7723 7.99499 18.1679 9.28875 17.7758 9.80625 17.5335 9.885 16.9337 10.1212 16.53 10.38 16.2993 8.3775 16.0687 6.285 15.2728 6.285 11.7432c0-1.0035.34875-1.834.92249-2.47994C7.1175 9.03257 6.8025 8.08674 7.2975 6.81794c0 0 .753749999999999-.24223 2.47499.94583.72001-.20762 1.48501-.31143 2.25001-.31143C12.7875 7.45234 13.5525 7.55615 14.2725 7.76377c1.7212-1.19959 2.475-.94583 2.475-.94583C17.2424 8.08674 16.9275 9.03257 16.8375 9.26326 17.4113 9.9092 17.76 10.7281 17.76 11.7432c0 3.5411-2.1037 4.3255-4.1063 4.5561C13.98 16.5877 14.2613 17.1414 14.2613 18.0065 14.2613 19.2407 14.25 20.2326 14.25 20.5441 14.25 20.7863 14.4188 21.0746 14.8688 20.9824 16.6554 20.364 18.2079 19.1866 19.3078 17.6162c1.0999-1.5705 1.6917-3.4551 1.6922-5.3886C21 7.12937 16.9725 3 12 3z"/></svg></a>
<a class="pr-2 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400" style=will-change:transform href=https://www.linkedin.com/in/maicel-monzon/ target=_blank rel=noopener rel="me noopener noreferrer" aria-label=Brands/Linkedin><svg style="height:1em" height="1em" viewBox="0 0 448 512"><path fill="currentcolor" d="M416 32H31.9C14.3 32 0 46.5.0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6.0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3.0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2.0 38.5 17.3 38.5 38.5.0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6.0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2.0 79.7 44.3 79.7 101.9V416z"/></svg></a>
<a class="pr-2 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400" style=will-change:transform href="https://scholar.google.com/citations?hl=es&amp;user=eWid-9gAAAAJ" target=_blank rel=noopener rel="me noopener noreferrer" aria-label=Academicons/Google-Scholar><svg style="height:1em" viewBox="0 0 512 512"><path fill="currentcolor" d="M343.759 106.662V79.43L363.524 64h-213.89L20.476 176.274h85.656a82.339 82.339.0 00-.219 6.225c0 20.845 7.22 38.087 21.672 51.861 14.453 13.797 32.252 20.648 53.327 20.648 4.923.0 9.75-.368 14.438-1.024-2.907 6.5-4.374 12.523-4.374 18.142.0 9.875 4.499 20.43 13.467 31.642-39.234 2.67-68.061 9.732-86.437 21.163-10.531 6.5-19 14.704-25.39 24.531-6.391 9.9-9.578 20.515-9.578 31.962.0 9.648 2.062 18.336 6.219 26.062 4.156 7.726 9.578 14.07 16.312 18.984 6.718 4.968 14.469 9.101 23.219 12.469 8.734 3.344 17.406 5.718 26.061 7.062A167.052 167.052.0 00180.555 448c13.469.0 26.953-1.734 40.547-5.187 13.562-3.485 26.28-8.642 38.171-15.493 11.86-6.805 21.515-16.086 28.922-27.718 7.39-11.68 11.094-24.805 11.094-39.336.0-11.016-2.25-21.039-6.75-30.14-4.468-9.073-9.938-16.542-16.452-22.345-6.501-5.813-13-11.155-19.516-15.968-6.5-4.845-12-9.75-16.468-14.813-4.485-5.046-6.735-10.054-6.735-14.984.0-4.921 1.734-9.672 5.216-14.265 3.455-4.61 7.674-9.048 12.61-13.306 4.937-4.25 9.875-8.968 14.796-14.133 4.922-5.147 9.141-11.827 12.61-20.008 3.485-8.18 5.203-17.445 5.203-27.757.0-13.453-2.547-24.46-7.547-33.314-.594-1.022-1.218-1.803-1.875-3.022l56.907-46.672v17.119c-7.393.93-6.624 5.345-6.624 10.635V245.96c0 5.958 4.875 10.834 10.834 10.834h3.989c5.958.0 10.833-4.875 10.833-10.834V117.293c0-5.277.778-9.688-6.561-10.63zm-107.36 222.48c1.14.75 3.704 2.78 7.718 6.038 4.05 3.243 6.797 5.695 8.266 7.414a443.553 443.553.0 016.376 7.547c2.813 3.375 4.718 6.304 5.718 8.734 1 2.477 2.016 5.461 3.047 8.946a38.27 38.27.0 011.485 10.562c0 17.048-6.564 29.68-19.656 37.859-13.125 8.18-28.767 12.274-46.938 12.274-9.187.0-18.203-1.093-27.063-3.196-8.843-2.116-17.311-5.336-25.39-9.601-8.078-4.258-14.577-10.204-19.5-17.797-4.938-7.64-7.407-16.415-7.407-26.25.0-10.32 2.797-19.29 8.422-26.906 5.594-7.625 12.938-13.391 22.032-17.315 9.063-3.946 18.25-6.742 27.562-8.398a157.865 157.865.0 0128.438-2.555c4.47.0 7.936.25 10.405.696.455.219 3.032 2.07 7.735 5.563 4.704 3.462 7.625 5.595 8.75 6.384zm-3.359-100.579c-7.406 8.86-17.734 13.288-30.953 13.288-11.86.0-22.298-4.764-31.266-14.312-9-9.523-15.422-20.328-19.344-32.43-3.937-12.109-5.906-23.984-5.906-35.648.0-13.694 3.596-25.352 10.781-34.976 7.187-9.65 17.5-14.485 30.938-14.485 11.875.0 22.374 5.038 31.437 15.157 9.094 10.085 15.61 21.413 19.517 33.968 3.922 12.54 5.873 24.53 5.873 35.984.0 13.446-3.702 24.61-11.076 33.454z"/></svg></a>
<a class="pr-2 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400" style=will-change:transform href=https://orcid.org/0000-0003-2117-9145 target=_blank rel=noopener rel="me noopener noreferrer" aria-label=Academicons/Orcid><svg style="height:1em" viewBox="0 0 512 512"><path fill="currentcolor" d="M336.62 194.538c-7.13-3.328-13.866-5.56-20.253-6.614-6.365-1.095-16.574-1.612-30.71-1.612h-36.704v152.747h37.634c14.673.0 26.081-1.013 34.224-3.017 8.142-2.004 14.921-4.526 20.356-7.626a69.448 69.448.0 0014.942-11.388c14.488-14.714 21.742-33.273 21.742-55.717.0-22.052-7.44-40.052-22.341-53.982-5.498-5.166-11.822-9.444-18.89-12.793zM256 8C119.022 8 8 119.042 8 256s111.022 248 248 248 248-111.042 248-248S392.978 8 256 8zm-82.336 357.513h-29.389V160.148h29.389zM158.95 138.696c-11.14.0-20.213-9.01-20.213-20.212.0-11.118 9.052-20.191 20.213-20.191 11.18.0 20.232 9.052 20.232 20.191a20.194 20.194.0 01-20.232 20.212zm241.386 163.597c-5.29 12.545-12.834 23.581-22.65 33.088-9.982 9.837-21.597 17.194-34.844 22.196-7.75 3.017-14.839 5.063-21.307 6.117-6.49 1.013-18.828 1.509-37.076 1.509h-64.956V160.148h69.233c27.962.0 50.034 4.154 66.32 12.545 16.265 8.37 29.181 20.728 38.792 36.972 9.61 16.265 14.425 34.018 14.425 53.196.023 13.765-2.666 26.908-7.936 39.432z"/></svg></a></div></div></div></div><div class="pt-1 no-prose w-full"><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class="flex flex-col md:flex-row flex-nowrap justify-between gap-5 pt-2"><div><a class="group flex no-underline" href=/post/trampas-correlacion/><span class="mt-[-0.3rem] me-2 text-neutral-700 transition-transform group-hover:-translate-x-[2px] group-hover:text-primary-600 dark:text-neutral dark:group-hover:text-primary-400"><span class="ltr:inline rtl:hidden">&larr;</span></span>
<span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">Las trampas de la correlaci√≥n disfrazada de causalidad</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400">sept. 24, 2025</span></span></a></div><div><a class="group flex text-right no-underline" href=/post/generalizacion/><span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">Del Laboratorio al Mundo Real</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400">sept. 1, 2025
</span></span><span class="mt-[-0.3rem] ms-2 text-neutral-700 transition-transform group-hover:-translate-x-[2px] group-hover:text-primary-600 dark:text-neutral dark:group-hover:text-primary-400"><span class=ltr:inline>&rarr;</span></span></a></div></div></div></div></div></main></article></div></div><div class=page-footer><footer class="container mx-auto flex flex-col justify-items-center text-sm leading-6 mt-24 mb-4 text-slate-700 dark:text-slate-200"><p class="powered-by text-center">¬© 2025 Me. This work is licensed under <a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank>CC BY NC ND 4.0</a></p><p class="powered-by footer-license-icons"><a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank aria-label="Creative Commons"><i class="fab fa-creative-commons fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-by fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nc fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nd fa-2x" aria-hidden=true></i></a></p><p class="powered-by text-center">Made with <a href="https://hugoblox.com/?utm_campaign=poweredby" target=_blank rel=noopener>Hugo Blox Builder</a>.</p></footer></div></body></html>